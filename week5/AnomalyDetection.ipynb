{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad3e04a-3b9d-4f2b-81f5-d73ae3d38adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/25 22:33:39] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/25 22:33:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=189708;file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=377668;file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/pengzhao/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "# Please fill in the following for enabling data capture\n",
    "s3_capture_upload_path = f\"s3://sagemaker-us-west-1-798223350085/monitoring/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "654fd764-21c6-4fe1-bc7a-14eca568efac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/25 22:34:35] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/25 22:34:35]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=569673;file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=902175;file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/25 22:34:36] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/25 22:34:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=538152;file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=755350;file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=157715;file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=596416;file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "# SageMaker session\n",
    "sess = sagemaker.Session()\n",
    "# get session bucket name\n",
    "bucket = sess.default_bucket()\n",
    "# bucket prefix or the subfolder for everything we produce\n",
    "prefix = \"mlops\"\n",
    "# get sagemaker role\n",
    "#sagemaker_role = sagemaker.get_execution_role()\n",
    "sagemaker_role = \"arn:aws:iam::798223350085:role/FULLSTACKDS_ROLE1\"\n",
    "# s3 client\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "\n",
    "sagemaker_client = boto_session.client(service_name=\"sagemaker\", region_name=region)\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session, sagemaker_client=sagemaker_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f55ea8-af32-462f-a3c2-c92cccf20be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/25 22:34:51] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/sagemaker/session.py#4593\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4593</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         CustomerChurn-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-02-01-06-34-51-791                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/25 22:34:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=775447;file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=833376;file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/sagemaker/session.py#4593\u001b\\\u001b[2m4593\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         CustomerChurn-\u001b[1;36m2025\u001b[0m-02-01-06-34-51-791                                  \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!!CPU times: user 313 ms, sys: 225 ms, total: 538 ms\n",
      "Wall time: 4min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'EndpointName': 'CustomerChurn',\n",
       " 'EndpointArn': 'arn:aws:sagemaker:us-west-1:798223350085:endpoint/CustomerChurn',\n",
       " 'EndpointConfigName': 'CustomerChurn-2025-02-01-06-34-51-791',\n",
       " 'ProductionVariants': [{'VariantName': 'AllTraffic',\n",
       "   'DeployedImages': [{'SpecifiedImage': '632365934929.dkr.ecr.us-west-1.amazonaws.com/xgboost:latest',\n",
       "     'ResolvedImage': '632365934929.dkr.ecr.us-west-1.amazonaws.com/xgboost@sha256:0c8f830ac408e6dee08445fb60392e9c3f05f790a4b3c07ec22327c08f75bcbf',\n",
       "     'ResolutionTime': datetime.datetime(2025, 1, 31, 22, 34, 53, 162000, tzinfo=tzlocal())}],\n",
       "   'CurrentWeight': 1.0,\n",
       "   'DesiredWeight': 1.0,\n",
       "   'CurrentInstanceCount': 1,\n",
       "   'DesiredInstanceCount': 1}],\n",
       " 'DataCaptureConfig': {'EnableCapture': True,\n",
       "  'CaptureStatus': 'Started',\n",
       "  'CurrentSamplingPercentage': 100,\n",
       "  'DestinationS3Uri': 's3://sagemaker-us-west-1-798223350085/monitoring/'},\n",
       " 'EndpointStatus': 'InService',\n",
       " 'CreationTime': datetime.datetime(2025, 1, 31, 21, 25, 8, 607000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2025, 1, 31, 22, 38, 28, 862000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '1c9fc898-5098-4432-900a-fdc71f61302e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '1c9fc898-5098-4432-900a-fdc71f61302e',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '861',\n",
       "   'date': 'Sat, 01 Feb 2025 06:39:24 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "endpoint_name = \"CustomerChurn\"\n",
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name, sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Change parameters as you would like - adjust sampling percentage,\n",
    "#  chose to capture request or response or both\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=s3_capture_upload_path,\n",
    "    kms_key_id=None,\n",
    "    capture_options=[\"REQUEST\", \"RESPONSE\"],\n",
    "    csv_content_types=[\"text/csv\"],\n",
    "    json_content_types=[\"application/json\"],\n",
    ")\n",
    "\n",
    "# Now it is time to apply the new configuration and wait for it to be applied\n",
    "predictor.update_data_capture_config(data_capture_config=data_capture_config)\n",
    "sess.wait_for_endpoint(endpoint=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c054fa-1e28-4ec9-9b09-3a1c47e70c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline data uri: s3://sagemaker-us-west-1-798223350085/ml_deploy/validation/\n",
      "Baseline results uri: s3://sagemaker-us-west-1-798223350085/monitoring/baseline/results\n"
     ]
    }
   ],
   "source": [
    "##'s3://bucketname/path/to/baseline/data' - Where your validation data is\n",
    "baseline_data_uri = f\"s3://sagemaker-us-west-1-798223350085/ml_deploy/validation/\"\n",
    "##'s3://bucketname/path/to/baseline/data' - Where the results are to be stored in\n",
    "baseline_results_uri = f\"s3://sagemaker-us-west-1-798223350085/monitoring/baseline/results\"\n",
    "\n",
    "print(\"Baseline data uri: {}\".format(baseline_data_uri))\n",
    "print(\"Baseline results uri: {}\".format(baseline_results_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5936d665-9a78-4cbf-b48d-2390d2c016bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/25 22:49:29] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Ignoring unnecessary instance type: <span style=\"color: #e100e1; text-decoration-color: #e100e1; font-style: italic\">None</span>.                            <a href=\"file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/sagemaker/image_uris.py#524\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">524</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/25 22:49:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Ignoring unnecessary instance type: \u001b[3;38;2;225;0;225mNone\u001b[0m.                            \u001b]8;id=422127;file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=733580;file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/sagemaker/image_uris.py#524\u001b\\\u001b[2m524\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker import get_execution_role\n",
    "import datetime\n",
    "\n",
    "#role = get_execution_role(sagemaker_session=sess)\n",
    "role = sagemaker_role\n",
    "prefix = \"customerchurn\"\n",
    "\n",
    "datetime_stamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "\n",
    "my_default_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    base_job_name=f\"{prefix}-monitor-{datetime_stamp}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "917f04dc-3ed9-4b64-b5d5-c404e74e11da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/25 22:49:42] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating processing-job with name                                      <a href=\"file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/sagemaker/session.py#1575\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1575</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         customerchurn-monitor-baseline-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224929</span>                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/25 22:49:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating processing-job with name                                      \u001b]8;id=618688;file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=568133;file:///Users/pengzhao/opt/anaconda3/envs/mlops/lib/python3.10/site-packages/sagemaker/session.py#1575\u001b\\\u001b[2m1575\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         customerchurn-monitor-baseline-\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m-\u001b[1;36m224929\u001b[0m                       \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............2025-02-01 06:51:49.234927: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-02-01 06:51:49.234959: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-02-01 06:51:50.853795: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2025-02-01 06:51:50.853827: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-02-01 06:51:50.853851: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-119-186.us-west-1.compute.internal): /proc/driver/nvidia/version does not exist\n",
      "2025-02-01 06:51:50.854129: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-01 06:51:52,412 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:us-west-1:798223350085:processing-job/customerchurn-monitor-baseline-2025-01-31-224929', 'ProcessingJobName': 'customerchurn-monitor-baseline-2025-01-31-224929', 'Environment': {'dataset_format': '{\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '890145073186.dkr.ecr.us-west-1.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://sagemaker-us-west-1-798223350085/ml_deploy/validation/', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinitionInput': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://sagemaker-us-west-1-798223350085/monitoring/baseline/results', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.large', 'VolumeSizeInGB': 20, 'VolumeKmsKeyId': None}}, 'NetworkConfig': {'VpcConfig': None, 'EnableNetworkIsolation': False, 'EnableInterContainerTrafficEncryption': False}, 'RoleArn': 'arn:aws:iam::798223350085:role/FULLSTACKDS_ROLE1', 'StoppingCondition': {'MaxRuntimeInSeconds': 1800}}\n",
      "2025-02-01 06:51:52,413 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\n",
      "2025-02-01 06:51:52,413 - __main__ - INFO - categorical_drift_method:None\n",
      "2025-02-01 06:51:52,413 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}, \"output_path\": \"/opt/ml/processing/output\", \"monitoring_input_type\": null, \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"exclude_features_attribute\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"data_quality_monitoring_config\": {\"evaluate_constraints\": \"Enabled\", \"emit_metrics\": \"Enabled\", \"datatype_check_threshold\": 1.0, \"domain_content_threshold\": 1.0, \"distribution_constraints\": {\"perform_comparison\": \"Enabled\", \"comparison_threshold\": 0.1, \"comparison_method\": \"Robust\", \"categorical_comparison_threshold\": 0.1, \"categorical_drift_method\": \"LInfinity\"}}, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\n",
      "2025-02-01 06:51:52,413 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\n",
      "2025-02-01 06:51:52,413 - bootstrap - INFO - Copy aws jars\n",
      "2025-02-01 06:51:52,460 - bootstrap - INFO - Copy cluster config\n",
      "2025-02-01 06:51:52,461 - bootstrap - INFO - Write runtime cluster config\n",
      "2025-02-01 06:51:52,461 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'current_instance_type': 'ml.m5.large', 'current_group_name': 'homogeneousCluster', 'hosts': ['algo-1'], 'instance_groups': [{'instance_group_name': 'homogeneousCluster', 'instance_type': 'ml.m5.large', 'hosts': ['algo-1']}], 'network_interface_name': 'eth0'}\n",
      "2025-02-01 06:51:52,471 - bootstrap - INFO - Finished Yarn configuration files setup.\n",
      "2025-02-01 06:51:52,471 - bootstrap - INFO - Starting spark process for master node algo-1\n",
      "2025-02-01 06:51:52,472 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\n",
      "WARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\n",
      "2025-02-01 06:51:53,065 INFO namenode.NameNode: STARTUP_MSG: \n",
      "/************************************************************\n",
      "STARTUP_MSG: Starting NameNode\n",
      "STARTUP_MSG:   host = algo-1/10.0.119.186\n",
      "STARTUP_MSG:   args = [-format, -force]\n",
      "STARTUP_MSG:   version = 3.0.0\n",
      "STARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-\n",
      "nodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar\n",
      "STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\n",
      "STARTUP_MSG:   java = 1.8.0_392\n",
      "************************************************************/\n",
      "2025-02-01 06:51:53,082 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\n",
      "2025-02-01 06:51:53,087 INFO namenode.NameNode: createNameNode [-format, -force]\n",
      "Formatting using clusterid: CID-ff19ed20-a676-40fc-b827-664993795020\n",
      "2025-02-01 06:51:53,819 INFO namenode.FSEditLog: Edit logging is async:true\n",
      "2025-02-01 06:51:53,834 INFO namenode.FSNamesystem: KeyProvider: null\n",
      "2025-02-01 06:51:53,836 INFO namenode.FSNamesystem: fsLock is fair: true\n",
      "2025-02-01 06:51:53,840 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\n",
      "2025-02-01 06:51:53,847 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\n",
      "2025-02-01 06:51:53,847 INFO namenode.FSNamesystem: supergroup          = supergroup\n",
      "2025-02-01 06:51:53,847 INFO namenode.FSNamesystem: isPermissionEnabled = true\n",
      "2025-02-01 06:51:53,848 INFO namenode.FSNamesystem: HA Enabled: false\n",
      "2025-02-01 06:51:53,888 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\n",
      "2025-02-01 06:51:53,900 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\n",
      "2025-02-01 06:51:53,900 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\n",
      "2025-02-01 06:51:53,906 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\n",
      "2025-02-01 06:51:53,910 INFO blockmanagement.BlockManager: The block deletion will start around 2025 Feb 01 06:51:53\n",
      "2025-02-01 06:51:53,912 INFO util.GSet: Computing capacity for map BlocksMap\n",
      "2025-02-01 06:51:53,912 INFO util.GSet: VM type       = 64-bit\n",
      "2025-02-01 06:51:53,914 INFO util.GSet: 2.0% max memory 1.3 GB = 27.1 MB\n",
      "2025-02-01 06:51:53,914 INFO util.GSet: capacity      = 2^22 = 4194304 entries\n",
      "2025-02-01 06:51:53,988 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\n",
      "2025-02-01 06:51:53,993 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\n",
      "2025-02-01 06:51:53,993 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\n",
      "2025-02-01 06:51:53,993 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\n",
      "2025-02-01 06:51:53,993 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\n",
      "2025-02-01 06:51:53,993 INFO blockmanagement.BlockManager: defaultReplication         = 3\n",
      "2025-02-01 06:51:53,993 INFO blockmanagement.BlockManager: maxReplication             = 512\n",
      "2025-02-01 06:51:53,993 INFO blockmanagement.BlockManager: minReplication             = 1\n",
      "2025-02-01 06:51:53,993 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\n",
      "2025-02-01 06:51:53,994 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\n",
      "2025-02-01 06:51:53,994 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\n",
      "2025-02-01 06:51:53,994 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\n",
      "2025-02-01 06:51:54,020 INFO util.GSet: Computing capacity for map INodeMap\n",
      "2025-02-01 06:51:54,020 INFO util.GSet: VM type       = 64-bit\n",
      "2025-02-01 06:51:54,021 INFO util.GSet: 1.0% max memory 1.3 GB = 13.5 MB\n",
      "2025-02-01 06:51:54,021 INFO util.GSet: capacity      = 2^21 = 2097152 entries\n",
      "2025-02-01 06:51:54,022 INFO namenode.FSDirectory: ACLs enabled? false\n",
      "2025-02-01 06:51:54,022 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\n",
      "2025-02-01 06:51:54,022 INFO namenode.FSDirectory: XAttrs enabled? true\n",
      "2025-02-01 06:51:54,023 INFO namenode.NameNode: Caching file names occurring more than 10 times\n",
      "2025-02-01 06:51:54,027 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\n",
      "2025-02-01 06:51:54,030 INFO util.GSet: Computing capacity for map cachedBlocks\n",
      "2025-02-01 06:51:54,031 INFO util.GSet: VM type       = 64-bit\n",
      "2025-02-01 06:51:54,031 INFO util.GSet: 0.25% max memory 1.3 GB = 3.4 MB\n",
      "2025-02-01 06:51:54,031 INFO util.GSet: capacity      = 2^19 = 524288 entries\n",
      "2025-02-01 06:51:54,038 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\n",
      "2025-02-01 06:51:54,038 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\n",
      "2025-02-01 06:51:54,038 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\n",
      "2025-02-01 06:51:54,042 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\n",
      "2025-02-01 06:51:54,042 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\n",
      "2025-02-01 06:51:54,044 INFO util.GSet: Computing capacity for map NameNodeRetryCache\n",
      "2025-02-01 06:51:54,044 INFO util.GSet: VM type       = 64-bit\n",
      "2025-02-01 06:51:54,044 INFO util.GSet: 0.029999999329447746% max memory 1.3 GB = 415.6 KB\n",
      "2025-02-01 06:51:54,044 INFO util.GSet: capacity      = 2^16 = 65536 entries\n",
      "2025-02-01 06:51:54,068 INFO namenode.FSImage: Allocated new BlockPoolId: BP-464714625-10.0.119.186-1738392714061\n",
      "2025-02-01 06:51:54,079 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\n",
      "2025-02-01 06:51:54,086 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\n",
      "2025-02-01 06:51:54,165 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\n",
      "2025-02-01 06:51:54,177 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\n",
      "2025-02-01 06:51:54,181 INFO namenode.NameNode: SHUTDOWN_MSG: \n",
      "/************************************************************\n",
      "SHUTDOWN_MSG: Shutting down NameNode at algo-1/10.0.119.186\n",
      "************************************************************/\n",
      "2025-02-01 06:51:54,189 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\n",
      "2025-02-01 06:51:56,249 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\n",
      "2025-02-01 06:51:56,250 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\n",
      "2025-02-01 06:51:58,372 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\n",
      "2025-02-01 06:51:58,373 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\n",
      "WARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\n",
      "WARNING: /var/log/yarn/ does not exist. Creating.\n",
      "2025-02-01 06:52:00,670 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\n",
      "2025-02-01 06:52:00,671 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\n",
      "WARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\n",
      "2025-02-01 06:52:03,186 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\n",
      "2025-02-01 06:52:03,186 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\n",
      "WARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\n",
      "2025-02-01 06:52:05,489 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\n",
      "2025-02-01 06:52:05,499 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\n",
      "2025-02-01 06:52:15,507 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\n",
      "2025-02-01 06:52:18,030 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2025-02-01 06:52:18,563 INFO Main: Start analyzing with args: --analytics_input /tmp/spark_job_config.json\n",
      "2025-02-01 06:52:18,604 INFO Main: Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\n",
      "2025-02-01 06:52:18,622 INFO FileUtil: Read file from path /tmp/spark_job_config.json.\n",
      "2025-02-01 06:52:19,368 INFO spark.SparkContext: Running Spark version 3.3.0\n",
      "2025-02-01 06:52:19,398 INFO resource.ResourceUtils: ==============================================================\n",
      "2025-02-01 06:52:19,399 INFO resource.ResourceUtils: No custom resources configured for spark.driver.\n",
      "2025-02-01 06:52:19,400 INFO resource.ResourceUtils: ==============================================================\n",
      "2025-02-01 06:52:19,400 INFO spark.SparkContext: Submitted application: SageMakerDataAnalyzer\n",
      "2025-02-01 06:52:19,436 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 5602, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "2025-02-01 06:52:19,457 INFO resource.ResourceProfile: Limiting resource is cpus at 1 tasks per executor\n",
      "2025-02-01 06:52:19,460 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0\n",
      "2025-02-01 06:52:19,535 INFO spark.SecurityManager: Changing view acls to: root\n",
      "2025-02-01 06:52:19,535 INFO spark.SecurityManager: Changing modify acls to: root\n",
      "2025-02-01 06:52:19,536 INFO spark.SecurityManager: Changing view acls groups to: \n",
      "2025-02-01 06:52:19,536 INFO spark.SecurityManager: Changing modify acls groups to: \n",
      "2025-02-01 06:52:19,536 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n",
      "2025-02-01 06:52:20,121 INFO util.Utils: Successfully started service 'sparkDriver' on port 34751.\n",
      "2025-02-01 06:52:20,185 INFO spark.SparkEnv: Registering MapOutputTracker\n",
      "2025-02-01 06:52:20,259 INFO spark.SparkEnv: Registering BlockManagerMaster\n",
      "2025-02-01 06:52:20,294 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "2025-02-01 06:52:20,297 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "2025-02-01 06:52:20,377 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "2025-02-01 06:52:20,434 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-291bbee2-ffad-44cb-b8a9-1e4516934226\n",
      "2025-02-01 06:52:20,476 INFO memory.MemoryStore: MemoryStore started with capacity 1458.6 MiB\n",
      "2025-02-01 06:52:20,558 INFO spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "2025-02-01 06:52:20,641 INFO spark.SparkContext: Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.0.119.186:34751/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1738392739363\n",
      "2025-02-01 06:52:21,561 INFO client.RMProxy: Connecting to ResourceManager at /10.0.119.186:8032\n",
      "2025-02-01 06:52:22,492 INFO conf.Configuration: resource-types.xml not found\n",
      "2025-02-01 06:52:22,493 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2025-02-01 06:52:22,502 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (7640 MB per container)\n",
      "2025-02-01 06:52:22,504 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\n",
      "2025-02-01 06:52:22,505 INFO yarn.Client: Setting up container launch context for our AM\n",
      "2025-02-01 06:52:22,505 INFO yarn.Client: Setting up the launch environment for our AM container\n",
      "2025-02-01 06:52:22,515 INFO yarn.Client: Preparing resources for our AM container\n",
      "2025-02-01 06:52:22,699 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "2025-02-01 06:52:25,284 INFO yarn.Client: Uploading resource file:/tmp/spark-fceccba1-e7d4-42c1-856d-250590d5aaca/__spark_libs__4131666250545597700.zip -> hdfs://10.0.119.186/user/root/.sparkStaging/application_1738392721395_0001/__spark_libs__4131666250545597700.zip\n",
      "2025-02-01 06:52:27,372 INFO yarn.Client: Uploading resource file:/tmp/spark-fceccba1-e7d4-42c1-856d-250590d5aaca/__spark_conf__5913927443102763779.zip -> hdfs://10.0.119.186/user/root/.sparkStaging/application_1738392721395_0001/__spark_conf__.zip\n",
      "2025-02-01 06:52:27,437 INFO spark.SecurityManager: Changing view acls to: root\n",
      "2025-02-01 06:52:27,439 INFO spark.SecurityManager: Changing modify acls to: root\n",
      "2025-02-01 06:52:27,439 INFO spark.SecurityManager: Changing view acls groups to: \n",
      "2025-02-01 06:52:27,439 INFO spark.SecurityManager: Changing modify acls groups to: \n",
      "2025-02-01 06:52:27,439 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n",
      "2025-02-01 06:52:27,477 INFO yarn.Client: Submitting application application_1738392721395_0001 to ResourceManager\n",
      "2025-02-01 06:52:27,907 INFO impl.YarnClientImpl: Submitted application application_1738392721395_0001\n",
      "2025-02-01 06:52:28,913 INFO yarn.Client: Application report for application_1738392721395_0001 (state: ACCEPTED)\n",
      "2025-02-01 06:52:28,918 INFO yarn.Client: \n",
      "#011 client token: N/A\n",
      "#011 diagnostics: AM container is launched, waiting for AM container to Register with RM\n",
      "#011 ApplicationMaster host: N/A\n",
      "#011 ApplicationMaster RPC port: -1\n",
      "#011 queue: default\n",
      "#011 start time: 1738392747606\n",
      "#011 final status: UNDEFINED\n",
      "#011 tracking URL: http://algo-1:8088/proxy/application_1738392721395_0001/\n",
      "#011 user: root\n",
      "2025-02-01 06:52:29,922 INFO yarn.Client: Application report for application_1738392721395_0001 (state: ACCEPTED)\n",
      "2025-02-01 06:52:30,926 INFO yarn.Client: Application report for application_1738392721395_0001 (state: ACCEPTED)\n",
      "2025-02-01 06:52:31,932 INFO yarn.Client: Application report for application_1738392721395_0001 (state: ACCEPTED)\n",
      "2025-02-01 06:52:32,936 INFO yarn.Client: Application report for application_1738392721395_0001 (state: ACCEPTED)\n",
      "2025-02-01 06:52:33,941 INFO yarn.Client: Application report for application_1738392721395_0001 (state: ACCEPTED)\n",
      "2025-02-01 06:52:34,945 INFO yarn.Client: Application report for application_1738392721395_0001 (state: RUNNING)\n",
      "2025-02-01 06:52:34,947 INFO yarn.Client: \n",
      "#011 client token: N/A\n",
      "#011 diagnostics: N/A\n",
      "#011 ApplicationMaster host: 10.0.119.186\n",
      "#011 ApplicationMaster RPC port: -1\n",
      "#011 queue: default\n",
      "#011 start time: 1738392747606\n",
      "#011 final status: UNDEFINED\n",
      "#011 tracking URL: http://algo-1:8088/proxy/application_1738392721395_0001/\n",
      "#011 user: root\n",
      "2025-02-01 06:52:34,951 INFO cluster.YarnClientSchedulerBackend: Application application_1738392721395_0001 has started running.\n",
      "2025-02-01 06:52:34,996 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40697.\n",
      "2025-02-01 06:52:34,996 INFO netty.NettyBlockTransferService: Server created on 10.0.119.186:40697\n",
      "2025-02-01 06:52:34,999 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "2025-02-01 06:52:35,021 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.119.186, 40697, None)\n",
      "2025-02-01 06:52:35,029 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.119.186:40697 with 1458.6 MiB RAM, BlockManagerId(driver, 10.0.119.186, 40697, None)\n",
      "2025-02-01 06:52:35,042 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.119.186, 40697, None)\n",
      "2025-02-01 06:52:35,045 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.119.186, 40697, None)\n",
      "2025-02-01 06:52:35,241 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1738392721395_0001), /proxy/application_1738392721395_0001\n",
      "2025-02-01 06:52:35,279 INFO util.log: Logging initialized @19474ms to org.sparkproject.jetty.util.log.Slf4jLog\n",
      "2025-02-01 06:52:37,255 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\n",
      "2025-02-01 06:52:42,317 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.119.186:36018) with ID 1,  ResourceProfileId 0\n",
      "2025-02-01 06:52:42,596 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-1:34585 with 2.7 GiB RAM, BlockManagerId(1, algo-1, 34585, None)\n",
      "2025-02-01 06:52:51,316 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)\n",
      "2025-02-01 06:52:51,728 WARN spark.SparkContext: Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\n",
      "2025-02-01 06:52:51,836 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "2025-02-01 06:52:51,848 INFO internal.SharedState: Warehouse path is 'file:/usr/spark-3.3.0/spark-warehouse'.\n",
      "2025-02-01 06:52:53,705 INFO datasources.InMemoryFileIndex: It took 61 ms to list leaf files for 1 paths.\n",
      "2025-02-01 06:52:53,956 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 417.0 KiB, free 1458.2 MiB)\n",
      "2025-02-01 06:52:54,418 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.2 KiB, free 1458.2 MiB)\n",
      "2025-02-01 06:52:54,422 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.119.186:40697 (size: 39.2 KiB, free: 1458.6 MiB)\n",
      "2025-02-01 06:52:54,435 INFO spark.SparkContext: Created broadcast 0 from csv at DatasetReader.scala:99\n",
      "2025-02-01 06:52:55,031 INFO input.FileInputFormat: Total input files to process : 1\n",
      "2025-02-01 06:52:55,039 INFO input.FileInputFormat: Total input files to process : 1\n",
      "2025-02-01 06:52:55,043 INFO input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 789285\n",
      "2025-02-01 06:52:55,148 INFO spark.SparkContext: Starting job: csv at DatasetReader.scala:99\n",
      "2025-02-01 06:52:55,169 INFO scheduler.DAGScheduler: Got job 0 (csv at DatasetReader.scala:99) with 1 output partitions\n",
      "2025-02-01 06:52:55,169 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at DatasetReader.scala:99)\n",
      "2025-02-01 06:52:55,170 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:52:55,172 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:52:55,190 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99), which has no missing parents\n",
      "2025-02-01 06:52:55,285 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.3 KiB, free 1458.1 MiB)\n",
      "2025-02-01 06:52:55,293 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 1458.1 MiB)\n",
      "2025-02-01 06:52:55,294 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.119.186:40697 (size: 4.2 KiB, free: 1458.6 MiB)\n",
      "2025-02-01 06:52:55,297 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:52:55,319 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:52:55,320 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:52:55,372 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4668 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:52:55,749 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on algo-1:34585 (size: 4.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:52:56,814 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on algo-1:34585 (size: 39.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:52:57,294 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1937 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:52:57,297 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:52:57,314 INFO scheduler.DAGScheduler: ResultStage 0 (csv at DatasetReader.scala:99) finished in 2.072 s\n",
      "2025-02-01 06:52:57,323 INFO scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:52:57,323 INFO cluster.YarnScheduler: Killing all running tasks in stage 0: Stage finished\n",
      "2025-02-01 06:52:57,325 INFO scheduler.DAGScheduler: Job 0 finished: csv at DatasetReader.scala:99, took 2.176589 s\n",
      "2025-02-01 06:52:57,580 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.119.186:40697 in memory (size: 4.2 KiB, free: 1458.6 MiB)\n",
      "2025-02-01 06:52:57,595 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on algo-1:34585 in memory (size: 4.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:52:57,616 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 10.0.119.186:40697 in memory (size: 39.2 KiB, free: 1458.6 MiB)\n",
      "2025-02-01 06:52:57,621 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on algo-1:34585 in memory (size: 39.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:01,438 INFO datasources.FileSourceStrategy: Pushed Filters: \n",
      "2025-02-01 06:53:01,440 INFO datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "2025-02-01 06:53:01,445 INFO datasources.FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 98 more fields>\n",
      "2025-02-01 06:53:01,503 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "2025-02-01 06:53:01,796 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 416.5 KiB, free 1458.2 MiB)\n",
      "2025-02-01 06:53:01,819 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 39.1 KiB, free 1458.2 MiB)\n",
      "2025-02-01 06:53:01,821 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.119.186:40697 (size: 39.1 KiB, free: 1458.6 MiB)\n",
      "2025-02-01 06:53:01,823 INFO spark.SparkContext: Created broadcast 2 from head at DataAnalyzer.scala:124\n",
      "2025-02-01 06:53:01,843 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "2025-02-01 06:53:01,897 INFO spark.SparkContext: Starting job: head at DataAnalyzer.scala:124\n",
      "2025-02-01 06:53:01,899 INFO scheduler.DAGScheduler: Got job 1 (head at DataAnalyzer.scala:124) with 1 output partitions\n",
      "2025-02-01 06:53:01,899 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (head at DataAnalyzer.scala:124)\n",
      "2025-02-01 06:53:01,899 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:01,902 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:01,906 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124), which has no missing parents\n",
      "2025-02-01 06:53:01,979 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 35.7 KiB, free 1458.1 MiB)\n",
      "2025-02-01 06:53:01,982 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 1458.1 MiB)\n",
      "2025-02-01 06:53:01,983 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.119.186:40697 (size: 13.4 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:01,983 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:01,984 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:01,985 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:01,988 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:02,068 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-1:34585 (size: 13.4 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:03,329 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on algo-1:34585 (size: 39.1 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:04,008 INFO storage.BlockManagerInfo: Added rdd_7_0 in memory on algo-1:34585 (size: 274.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:04,329 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2343 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:04,339 INFO scheduler.DAGScheduler: ResultStage 1 (head at DataAnalyzer.scala:124) finished in 2.425 s\n",
      "2025-02-01 06:53:04,339 INFO scheduler.DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:04,343 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:04,343 INFO cluster.YarnScheduler: Killing all running tasks in stage 1: Stage finished\n",
      "2025-02-01 06:53:04,344 INFO scheduler.DAGScheduler: Job 1 finished: head at DataAnalyzer.scala:124, took 2.446539 s\n",
      "2025-02-01 06:53:04,981 INFO codegen.CodeGenerator: Code generated in 431.455472 ms\n",
      "2025-02-01 06:53:05,801 INFO scheduler.DAGScheduler: Registering RDD 16 (collect at AnalysisRunner.scala:326) as input to shuffle 0\n",
      "2025-02-01 06:53:05,811 INFO scheduler.DAGScheduler: Got map stage job 2 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:05,812 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:05,812 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:05,814 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:05,821 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:05,860 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 131.0 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:05,864 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 39.9 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:05,865 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.119.186:40697 (size: 39.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:05,868 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:05,871 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:05,871 INFO cluster.YarnScheduler: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:05,881 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:05,919 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-1:34585 (size: 39.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:07,441 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1562 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:07,442 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:07,448 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326) finished in 1.624 s\n",
      "2025-02-01 06:53:07,451 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:07,451 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:07,452 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:07,452 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:07,639 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:07,642 INFO scheduler.DAGScheduler: Got job 3 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:07,642 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:07,643 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)\n",
      "2025-02-01 06:53:07,643 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:07,645 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:07,680 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 183.5 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:07,682 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1457.7 MiB)\n",
      "2025-02-01 06:53:07,687 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.119.186:40697 (size: 50.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:07,691 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:07,694 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:07,694 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:07,698 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:07,738 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on algo-1:34585 (size: 50.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:07,881 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:08,383 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 687 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:08,385 INFO scheduler.DAGScheduler: ResultStage 4 (collect at AnalysisRunner.scala:326) finished in 0.729 s\n",
      "2025-02-01 06:53:08,386 INFO scheduler.DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:08,389 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:08,389 INFO cluster.YarnScheduler: Killing all running tasks in stage 4: Stage finished\n",
      "2025-02-01 06:53:08,390 INFO scheduler.DAGScheduler: Job 3 finished: collect at AnalysisRunner.scala:326, took 0.750038 s\n",
      "2025-02-01 06:53:08,424 INFO codegen.CodeGenerator: Code generated in 20.360747 ms\n",
      "2025-02-01 06:53:08,680 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.119.186:40697 in memory (size: 13.4 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:08,684 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on algo-1:34585 in memory (size: 13.4 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:08,741 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.119.186:40697 in memory (size: 50.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:08,744 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on algo-1:34585 in memory (size: 50.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:08,787 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.119.186:40697 in memory (size: 39.9 KiB, free: 1458.6 MiB)\n",
      "2025-02-01 06:53:08,789 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-1:34585 in memory (size: 39.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:08,933 INFO codegen.CodeGenerator: Code generated in 29.995949 ms\n",
      "2025-02-01 06:53:09,022 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:09,023 INFO scheduler.DAGScheduler: Got job 4 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:09,023 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:09,023 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:09,024 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:09,025 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:09,064 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 54.9 KiB, free 1458.1 MiB)\n",
      "2025-02-01 06:53:09,067 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.8 KiB, free 1458.1 MiB)\n",
      "2025-02-01 06:53:09,068 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.119.186:40697 (size: 20.8 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:09,069 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:09,071 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:09,071 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:09,073 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:09,089 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-1:34585 (size: 20.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:09,517 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 444 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:09,518 INFO scheduler.DAGScheduler: ResultStage 5 (treeReduce at KLLRunner.scala:107) finished in 0.488 s\n",
      "2025-02-01 06:53:09,519 INFO scheduler.DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:09,520 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:09,520 INFO cluster.YarnScheduler: Killing all running tasks in stage 5: Stage finished\n",
      "2025-02-01 06:53:09,521 INFO scheduler.DAGScheduler: Job 4 finished: treeReduce at KLLRunner.scala:107, took 0.498895 s\n",
      "2025-02-01 06:53:10,201 INFO codegen.CodeGenerator: Code generated in 135.834377 ms\n",
      "2025-02-01 06:53:10,209 INFO scheduler.DAGScheduler: Registering RDD 34 (collect at AnalysisRunner.scala:326) as input to shuffle 1\n",
      "2025-02-01 06:53:10,209 INFO scheduler.DAGScheduler: Got map stage job 5 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:10,209 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:10,209 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:10,210 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:10,211 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:10,234 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 90.7 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:10,237 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:10,238 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.119.186:40697 (size: 28.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:10,239 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:10,243 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:10,243 INFO cluster.YarnScheduler: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:10,246 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:10,286 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-1:34585 (size: 28.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:10,489 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 244 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:10,490 INFO scheduler.DAGScheduler: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326) finished in 0.278 s\n",
      "2025-02-01 06:53:10,491 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:10,492 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:10,492 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:10,492 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:10,492 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:10,856 INFO codegen.CodeGenerator: Code generated in 236.334872 ms\n",
      "2025-02-01 06:53:10,889 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:10,891 INFO scheduler.DAGScheduler: Got job 6 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:10,892 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:10,892 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)\n",
      "2025-02-01 06:53:10,892 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:10,893 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:10,903 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 66.2 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:10,905 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:10,909 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:10,909 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:10,913 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:10,913 INFO cluster.YarnScheduler: Adding task set 8.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:10,915 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:10,941 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:10,956 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:11,087 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 172 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:11,087 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:11,088 INFO scheduler.DAGScheduler: ResultStage 8 (collect at AnalysisRunner.scala:326) finished in 0.190 s\n",
      "2025-02-01 06:53:11,089 INFO scheduler.DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:11,090 INFO cluster.YarnScheduler: Killing all running tasks in stage 8: Stage finished\n",
      "2025-02-01 06:53:11,090 INFO scheduler.DAGScheduler: Job 6 finished: collect at AnalysisRunner.scala:326, took 0.201138 s\n",
      "2025-02-01 06:53:11,221 INFO codegen.CodeGenerator: Code generated in 84.336732 ms\n",
      "2025-02-01 06:53:11,512 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:11,527 INFO scheduler.DAGScheduler: Registering RDD 45 (countByKey at ColumnProfiler.scala:592) as input to shuffle 2\n",
      "2025-02-01 06:53:11,528 INFO scheduler.DAGScheduler: Got job 7 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:11,528 INFO scheduler.DAGScheduler: Final stage: ResultStage 10 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:11,528 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)\n",
      "2025-02-01 06:53:11,528 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 9)\n",
      "2025-02-01 06:53:11,532 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:11,549 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 47.1 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:11,554 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:11,561 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:11,561 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:11,564 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:11,565 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:11,566 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:11,583 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:13,466 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 1900 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:13,467 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:13,468 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (countByKey at ColumnProfiler.scala:592) finished in 1.935 s\n",
      "2025-02-01 06:53:13,469 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:13,470 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:13,470 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 10)\n",
      "2025-02-01 06:53:13,470 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:13,471 INFO scheduler.DAGScheduler: Submitting ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:13,473 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 5.1 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:13,476 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:13,476 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:13,479 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:13,483 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:13,483 INFO cluster.YarnScheduler: Adding task set 10.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:13,485 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 8) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:13,504 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:13,513 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:13,544 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 8) in 59 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:13,545 INFO cluster.YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:13,546 INFO scheduler.DAGScheduler: ResultStage 10 (countByKey at ColumnProfiler.scala:592) finished in 0.074 s\n",
      "2025-02-01 06:53:13,546 INFO scheduler.DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:13,546 INFO cluster.YarnScheduler: Killing all running tasks in stage 10: Stage finished\n",
      "2025-02-01 06:53:13,546 INFO scheduler.DAGScheduler: Job 7 finished: countByKey at ColumnProfiler.scala:592, took 2.026567 s\n",
      "2025-02-01 06:53:13,899 INFO scheduler.DAGScheduler: Registering RDD 51 (collect at AnalysisRunner.scala:326) as input to shuffle 3\n",
      "2025-02-01 06:53:13,899 INFO scheduler.DAGScheduler: Got map stage job 8 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:13,899 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:13,899 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:13,900 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:13,900 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:13,913 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 100.0 KiB, free 1457.7 MiB)\n",
      "2025-02-01 06:53:13,920 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.7 MiB)\n",
      "2025-02-01 06:53:13,923 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.119.186:40697 (size: 32.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:13,924 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:13,926 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:13,926 INFO cluster.YarnScheduler: Adding task set 11.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:13,932 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 9) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:13,962 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on algo-1:34585 (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:14,338 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 9) in 407 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:14,338 INFO cluster.YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:14,339 INFO scheduler.DAGScheduler: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326) finished in 0.436 s\n",
      "2025-02-01 06:53:14,342 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:14,342 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:14,342 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:14,342 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:14,411 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:14,414 INFO scheduler.DAGScheduler: Got job 9 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:14,414 INFO scheduler.DAGScheduler: Final stage: ResultStage 13 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:14,415 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)\n",
      "2025-02-01 06:53:14,415 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:14,416 INFO scheduler.DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:14,430 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 184.6 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:14,438 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:14,439 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.119.186:40697 (size: 50.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:14,439 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:14,440 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:14,440 INFO cluster.YarnScheduler: Adding task set 13.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:14,442 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:14,454 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on algo-1:34585 (size: 50.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:14,488 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:14,710 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 269 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:14,711 INFO cluster.YarnScheduler: Removed TaskSet 13.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:14,712 INFO scheduler.DAGScheduler: ResultStage 13 (collect at AnalysisRunner.scala:326) finished in 0.294 s\n",
      "2025-02-01 06:53:14,713 INFO scheduler.DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:14,714 INFO cluster.YarnScheduler: Killing all running tasks in stage 13: Stage finished\n",
      "2025-02-01 06:53:14,715 INFO scheduler.DAGScheduler: Job 9 finished: collect at AnalysisRunner.scala:326, took 0.304283 s\n",
      "2025-02-01 06:53:14,996 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:15,000 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:15,072 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on algo-1:34585 in memory (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:15,079 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 10.0.119.186:40697 in memory (size: 32.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:15,134 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:15,136 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:15,211 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on algo-1:34585 in memory (size: 28.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:15,232 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.0.119.186:40697 in memory (size: 28.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:15,282 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:15,289 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:15,300 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:15,301 INFO scheduler.DAGScheduler: Got job 10 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:15,302 INFO scheduler.DAGScheduler: Final stage: ResultStage 14 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:15,302 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:15,303 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:15,310 INFO scheduler.DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:15,319 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 54.8 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:15,322 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:15,324 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:15,326 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:15,326 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:15,326 INFO cluster.YarnScheduler: Adding task set 14.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:15,328 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 11) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:15,334 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.0.119.186:40697 in memory (size: 20.8 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:15,345 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on algo-1:34585 in memory (size: 20.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:15,347 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:15,399 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 10.0.119.186:40697 in memory (size: 50.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:15,407 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on algo-1:34585 in memory (size: 50.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:15,463 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 11) in 136 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:15,464 INFO cluster.YarnScheduler: Removed TaskSet 14.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:15,465 INFO scheduler.DAGScheduler: ResultStage 14 (treeReduce at KLLRunner.scala:107) finished in 0.154 s\n",
      "2025-02-01 06:53:15,466 INFO scheduler.DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:15,466 INFO cluster.YarnScheduler: Killing all running tasks in stage 14: Stage finished\n",
      "2025-02-01 06:53:15,467 INFO scheduler.DAGScheduler: Job 10 finished: treeReduce at KLLRunner.scala:107, took 0.166875 s\n",
      "2025-02-01 06:53:15,825 INFO scheduler.DAGScheduler: Registering RDD 69 (collect at AnalysisRunner.scala:326) as input to shuffle 4\n",
      "2025-02-01 06:53:15,825 INFO scheduler.DAGScheduler: Got map stage job 11 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:15,825 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:15,826 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:15,826 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:15,827 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:15,837 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 90.7 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:15,839 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:15,841 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.119.186:40697 (size: 27.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:15,842 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:15,842 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:15,842 INFO cluster.YarnScheduler: Adding task set 15.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:15,844 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:15,859 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on algo-1:34585 (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:15,898 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 54 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:15,899 INFO cluster.YarnScheduler: Removed TaskSet 15.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:15,900 INFO scheduler.DAGScheduler: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326) finished in 0.071 s\n",
      "2025-02-01 06:53:15,900 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:15,902 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:15,903 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:15,903 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:16,058 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:16,062 INFO scheduler.DAGScheduler: Got job 12 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:16,062 INFO scheduler.DAGScheduler: Final stage: ResultStage 17 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:16,063 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)\n",
      "2025-02-01 06:53:16,063 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:16,063 INFO scheduler.DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:16,066 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 66.2 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:16,068 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:16,068 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:16,069 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:16,069 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:16,070 INFO cluster.YarnScheduler: Adding task set 17.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:16,073 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 13) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:16,092 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:16,096 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:16,108 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 13) in 36 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:16,108 INFO cluster.YarnScheduler: Removed TaskSet 17.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:16,110 INFO scheduler.DAGScheduler: ResultStage 17 (collect at AnalysisRunner.scala:326) finished in 0.046 s\n",
      "2025-02-01 06:53:16,110 INFO scheduler.DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:16,110 INFO cluster.YarnScheduler: Killing all running tasks in stage 17: Stage finished\n",
      "2025-02-01 06:53:16,113 INFO scheduler.DAGScheduler: Job 12 finished: collect at AnalysisRunner.scala:326, took 0.051583 s\n",
      "2025-02-01 06:53:16,198 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:16,200 INFO scheduler.DAGScheduler: Registering RDD 80 (countByKey at ColumnProfiler.scala:592) as input to shuffle 5\n",
      "2025-02-01 06:53:16,201 INFO scheduler.DAGScheduler: Got job 13 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:16,201 INFO scheduler.DAGScheduler: Final stage: ResultStage 19 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:16,201 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)\n",
      "2025-02-01 06:53:16,202 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 18)\n",
      "2025-02-01 06:53:16,204 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:16,212 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 47.1 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:16,214 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:16,216 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:16,217 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:16,218 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:16,218 INFO cluster.YarnScheduler: Adding task set 18.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:16,220 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 14) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:16,234 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:16,332 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 14) in 112 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:16,335 INFO cluster.YarnScheduler: Removed TaskSet 18.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:16,336 INFO scheduler.DAGScheduler: ShuffleMapStage 18 (countByKey at ColumnProfiler.scala:592) finished in 0.130 s\n",
      "2025-02-01 06:53:16,337 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:16,338 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:16,338 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 19)\n",
      "2025-02-01 06:53:16,338 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:16,340 INFO scheduler.DAGScheduler: Submitting ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:16,344 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 5.1 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:16,345 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:16,346 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:16,347 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:16,351 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:16,352 INFO cluster.YarnScheduler: Adding task set 19.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:16,355 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 15) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:16,365 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:16,370 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:16,394 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 15) in 40 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:16,395 INFO cluster.YarnScheduler: Removed TaskSet 19.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:16,396 INFO scheduler.DAGScheduler: ResultStage 19 (countByKey at ColumnProfiler.scala:592) finished in 0.055 s\n",
      "2025-02-01 06:53:16,397 INFO scheduler.DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:16,397 INFO cluster.YarnScheduler: Killing all running tasks in stage 19: Stage finished\n",
      "2025-02-01 06:53:16,398 INFO scheduler.DAGScheduler: Job 13 finished: countByKey at ColumnProfiler.scala:592, took 0.199263 s\n",
      "2025-02-01 06:53:16,617 INFO scheduler.DAGScheduler: Registering RDD 86 (collect at AnalysisRunner.scala:326) as input to shuffle 6\n",
      "2025-02-01 06:53:16,618 INFO scheduler.DAGScheduler: Got map stage job 14 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:16,618 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:16,618 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:16,619 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:16,620 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:16,624 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 100.0 KiB, free 1457.7 MiB)\n",
      "2025-02-01 06:53:16,627 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.7 MiB)\n",
      "2025-02-01 06:53:16,629 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.119.186:40697 (size: 32.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:16,630 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:16,630 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:16,631 INFO cluster.YarnScheduler: Adding task set 20.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:16,632 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 20.0 (TID 16) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:16,646 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on algo-1:34585 (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:16,867 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 20.0 (TID 16) in 235 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:16,867 INFO cluster.YarnScheduler: Removed TaskSet 20.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:16,868 INFO scheduler.DAGScheduler: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326) finished in 0.247 s\n",
      "2025-02-01 06:53:16,869 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:16,869 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:16,869 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:16,869 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:16,945 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:16,947 INFO scheduler.DAGScheduler: Got job 15 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:16,948 INFO scheduler.DAGScheduler: Final stage: ResultStage 22 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:16,948 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)\n",
      "2025-02-01 06:53:16,948 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:16,949 INFO scheduler.DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:16,957 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 184.6 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:16,959 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 50.4 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:16,959 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.119.186:40697 (size: 50.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:16,960 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:16,960 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:16,960 INFO cluster.YarnScheduler: Adding task set 22.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:16,962 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 22.0 (TID 17) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:16,974 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on algo-1:34585 (size: 50.4 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:16,986 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:17,163 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 22.0 (TID 17) in 201 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:17,163 INFO cluster.YarnScheduler: Removed TaskSet 22.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:17,164 INFO scheduler.DAGScheduler: ResultStage 22 (collect at AnalysisRunner.scala:326) finished in 0.213 s\n",
      "2025-02-01 06:53:17,165 INFO scheduler.DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:17,165 INFO cluster.YarnScheduler: Killing all running tasks in stage 22: Stage finished\n",
      "2025-02-01 06:53:17,166 INFO scheduler.DAGScheduler: Job 15 finished: collect at AnalysisRunner.scala:326, took 0.220035 s\n",
      "2025-02-01 06:53:17,397 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:17,399 INFO scheduler.DAGScheduler: Got job 16 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:17,399 INFO scheduler.DAGScheduler: Final stage: ResultStage 23 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:17,399 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:17,399 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:17,401 INFO scheduler.DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:17,408 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 54.8 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:17,410 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:17,411 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:17,411 INFO spark.SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:17,412 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:17,412 INFO cluster.YarnScheduler: Adding task set 23.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:17,415 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 23.0 (TID 18) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:17,427 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:17,473 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 23.0 (TID 18) in 58 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:17,474 INFO cluster.YarnScheduler: Removed TaskSet 23.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:17,475 INFO scheduler.DAGScheduler: ResultStage 23 (treeReduce at KLLRunner.scala:107) finished in 0.073 s\n",
      "2025-02-01 06:53:17,475 INFO scheduler.DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:17,476 INFO cluster.YarnScheduler: Killing all running tasks in stage 23: Stage finished\n",
      "2025-02-01 06:53:17,476 INFO scheduler.DAGScheduler: Job 16 finished: treeReduce at KLLRunner.scala:107, took 0.078362 s\n",
      "2025-02-01 06:53:17,652 INFO scheduler.DAGScheduler: Registering RDD 104 (collect at AnalysisRunner.scala:326) as input to shuffle 7\n",
      "2025-02-01 06:53:17,652 INFO scheduler.DAGScheduler: Got map stage job 17 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:17,653 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:17,653 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:17,654 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:17,654 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:17,664 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 90.7 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:17,666 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:17,667 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.119.186:40697 (size: 27.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:17,667 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:17,671 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:17,671 INFO cluster.YarnScheduler: Adding task set 24.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:17,673 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 24.0 (TID 19) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:17,686 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on algo-1:34585 (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:17,723 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 24.0 (TID 19) in 51 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:17,724 INFO cluster.YarnScheduler: Removed TaskSet 24.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:17,725 INFO scheduler.DAGScheduler: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326) finished in 0.068 s\n",
      "2025-02-01 06:53:17,725 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:17,726 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:17,726 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:17,726 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:17,831 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on 10.0.119.186:40697 in memory (size: 27.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:17,833 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on algo-1:34585 in memory (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:17,839 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:17,840 INFO scheduler.DAGScheduler: Got job 18 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:17,840 INFO scheduler.DAGScheduler: Final stage: ResultStage 26 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:17,840 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)\n",
      "2025-02-01 06:53:17,841 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:17,842 INFO scheduler.DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:17,844 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 66.2 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:17,846 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:17,846 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:17,851 INFO spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:17,851 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:17,851 INFO cluster.YarnScheduler: Adding task set 26.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:17,853 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 26.0 (TID 20) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:17,869 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:17,874 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:17,877 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:17,879 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:17,887 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 26.0 (TID 20) in 35 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:17,887 INFO scheduler.DAGScheduler: ResultStage 26 (collect at AnalysisRunner.scala:326) finished in 0.044 s\n",
      "2025-02-01 06:53:17,888 INFO scheduler.DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:17,889 INFO cluster.YarnScheduler: Removed TaskSet 26.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:17,889 INFO cluster.YarnScheduler: Killing all running tasks in stage 26: Stage finished\n",
      "2025-02-01 06:53:17,890 INFO scheduler.DAGScheduler: Job 18 finished: collect at AnalysisRunner.scala:326, took 0.049938 s\n",
      "2025-02-01 06:53:17,907 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on algo-1:34585 in memory (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:17,909 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 10.0.119.186:40697 in memory (size: 27.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:17,947 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:17,954 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:17,986 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:17,988 INFO scheduler.DAGScheduler: Registering RDD 115 (countByKey at ColumnProfiler.scala:592) as input to shuffle 8\n",
      "2025-02-01 06:53:17,988 INFO scheduler.DAGScheduler: Got job 19 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:17,988 INFO scheduler.DAGScheduler: Final stage: ResultStage 28 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:17,988 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)\n",
      "2025-02-01 06:53:17,989 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 27)\n",
      "2025-02-01 06:53:17,992 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:17,996 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:18,008 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 47.1 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:18,013 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:18,013 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:18,014 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.119.186:40697 (size: 18.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:18,015 INFO spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:18,016 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:18,016 INFO cluster.YarnScheduler: Adding task set 27.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:18,017 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 21) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:18,045 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on algo-1:34585 (size: 18.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:18,124 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on 10.0.119.186:40697 in memory (size: 50.4 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:18,132 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on algo-1:34585 in memory (size: 50.4 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:18,184 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:18,201 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:18,250 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 21) in 233 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:18,250 INFO cluster.YarnScheduler: Removed TaskSet 27.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:18,251 INFO scheduler.DAGScheduler: ShuffleMapStage 27 (countByKey at ColumnProfiler.scala:592) finished in 0.258 s\n",
      "2025-02-01 06:53:18,254 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:18,254 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:18,254 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 28)\n",
      "2025-02-01 06:53:18,254 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:18,257 INFO scheduler.DAGScheduler: Submitting ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:18,259 INFO memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 5.1 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:18,268 INFO memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:18,268 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:18,269 INFO spark.SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:18,269 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:18,270 INFO cluster.YarnScheduler: Adding task set 28.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:18,273 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 28.0 (TID 22) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:18,292 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:18,295 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:18,329 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:18,334 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:18,375 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 28.0 (TID 22) in 103 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:18,376 INFO cluster.YarnScheduler: Removed TaskSet 28.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:18,377 INFO scheduler.DAGScheduler: ResultStage 28 (countByKey at ColumnProfiler.scala:592) finished in 0.118 s\n",
      "2025-02-01 06:53:18,378 INFO scheduler.DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:18,379 INFO cluster.YarnScheduler: Killing all running tasks in stage 28: Stage finished\n",
      "2025-02-01 06:53:18,380 INFO scheduler.DAGScheduler: Job 19 finished: countByKey at ColumnProfiler.scala:592, took 0.392423 s\n",
      "2025-02-01 06:53:18,423 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on 10.0.119.186:40697 in memory (size: 32.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:18,434 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on algo-1:34585 in memory (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:18,957 INFO scheduler.DAGScheduler: Registering RDD 121 (collect at AnalysisRunner.scala:326) as input to shuffle 9\n",
      "2025-02-01 06:53:18,958 INFO scheduler.DAGScheduler: Got map stage job 20 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:18,958 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 29 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:18,959 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:18,960 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:18,965 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:18,970 INFO memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 100.0 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:18,979 INFO memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:18,980 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.119.186:40697 (size: 32.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:18,981 INFO spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:18,982 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:18,983 INFO cluster.YarnScheduler: Adding task set 29.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:18,985 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 29.0 (TID 23) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:19,008 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on algo-1:34585 (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:19,374 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 29.0 (TID 23) in 390 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:19,375 INFO cluster.YarnScheduler: Removed TaskSet 29.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:19,377 INFO scheduler.DAGScheduler: ShuffleMapStage 29 (collect at AnalysisRunner.scala:326) finished in 0.411 s\n",
      "2025-02-01 06:53:19,378 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:19,378 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:19,378 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:19,379 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:19,453 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:19,455 INFO scheduler.DAGScheduler: Got job 21 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:19,455 INFO scheduler.DAGScheduler: Final stage: ResultStage 31 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:19,455 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)\n",
      "2025-02-01 06:53:19,455 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:19,456 INFO scheduler.DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:19,465 INFO memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 184.6 KiB, free 1457.7 MiB)\n",
      "2025-02-01 06:53:19,468 INFO memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.6 MiB)\n",
      "2025-02-01 06:53:19,468 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.119.186:40697 (size: 50.3 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:19,469 INFO spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:19,469 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:19,470 INFO cluster.YarnScheduler: Adding task set 31.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:19,471 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 31.0 (TID 24) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:19,489 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on algo-1:34585 (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:19,505 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:19,670 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 31.0 (TID 24) in 199 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:19,672 INFO cluster.YarnScheduler: Removed TaskSet 31.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:19,673 INFO scheduler.DAGScheduler: ResultStage 31 (collect at AnalysisRunner.scala:326) finished in 0.215 s\n",
      "2025-02-01 06:53:19,674 INFO scheduler.DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:19,674 INFO cluster.YarnScheduler: Killing all running tasks in stage 31: Stage finished\n",
      "2025-02-01 06:53:19,674 INFO scheduler.DAGScheduler: Job 21 finished: collect at AnalysisRunner.scala:326, took 0.220799 s\n",
      "2025-02-01 06:53:19,864 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:19,865 INFO scheduler.DAGScheduler: Got job 22 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:19,866 INFO scheduler.DAGScheduler: Final stage: ResultStage 32 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:19,866 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:19,867 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:19,867 INFO scheduler.DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[134] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:19,883 INFO memory.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 54.8 KiB, free 1457.6 MiB)\n",
      "2025-02-01 06:53:19,885 INFO memory.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.6 MiB)\n",
      "2025-02-01 06:53:19,892 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:19,892 INFO spark.SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:19,893 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[134] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:19,893 INFO cluster.YarnScheduler: Adding task set 32.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:19,894 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 32.0 (TID 25) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:19,918 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:19,980 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 32.0 (TID 25) in 86 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:19,980 INFO cluster.YarnScheduler: Removed TaskSet 32.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:19,981 INFO scheduler.DAGScheduler: ResultStage 32 (treeReduce at KLLRunner.scala:107) finished in 0.113 s\n",
      "2025-02-01 06:53:19,982 INFO scheduler.DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:19,982 INFO cluster.YarnScheduler: Killing all running tasks in stage 32: Stage finished\n",
      "2025-02-01 06:53:19,982 INFO scheduler.DAGScheduler: Job 22 finished: treeReduce at KLLRunner.scala:107, took 0.118644 s\n",
      "2025-02-01 06:53:20,133 INFO scheduler.DAGScheduler: Registering RDD 139 (collect at AnalysisRunner.scala:326) as input to shuffle 10\n",
      "2025-02-01 06:53:20,134 INFO scheduler.DAGScheduler: Got map stage job 23 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:20,134 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 33 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:20,134 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:20,135 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:20,135 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[139] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:20,141 INFO memory.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 90.7 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:20,143 INFO memory.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:20,144 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.0.119.186:40697 (size: 28.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:20,144 INFO spark.SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:20,145 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[139] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:20,145 INFO cluster.YarnScheduler: Adding task set 33.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:20,146 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 33.0 (TID 26) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:20,164 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on algo-1:34585 (size: 28.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:20,220 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 33.0 (TID 26) in 74 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:20,221 INFO cluster.YarnScheduler: Removed TaskSet 33.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:20,222 INFO scheduler.DAGScheduler: ShuffleMapStage 33 (collect at AnalysisRunner.scala:326) finished in 0.086 s\n",
      "2025-02-01 06:53:20,223 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:20,223 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:20,224 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:20,224 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:20,304 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:20,305 INFO scheduler.DAGScheduler: Got job 24 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:20,305 INFO scheduler.DAGScheduler: Final stage: ResultStage 35 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:20,306 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)\n",
      "2025-02-01 06:53:20,307 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:20,307 INFO scheduler.DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[142] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:20,309 INFO memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 66.2 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:20,311 INFO memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:20,311 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:20,312 INFO spark.SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:20,312 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[142] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:20,313 INFO cluster.YarnScheduler: Adding task set 35.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:20,321 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 35.0 (TID 27) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:20,347 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:20,359 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:20,380 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 35.0 (TID 27) in 61 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:20,380 INFO cluster.YarnScheduler: Removed TaskSet 35.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:20,381 INFO scheduler.DAGScheduler: ResultStage 35 (collect at AnalysisRunner.scala:326) finished in 0.072 s\n",
      "2025-02-01 06:53:20,381 INFO scheduler.DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:20,382 INFO cluster.YarnScheduler: Killing all running tasks in stage 35: Stage finished\n",
      "2025-02-01 06:53:20,382 INFO scheduler.DAGScheduler: Job 24 finished: collect at AnalysisRunner.scala:326, took 0.077735 s\n",
      "2025-02-01 06:53:20,473 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:20,475 INFO scheduler.DAGScheduler: Registering RDD 150 (countByKey at ColumnProfiler.scala:592) as input to shuffle 11\n",
      "2025-02-01 06:53:20,476 INFO scheduler.DAGScheduler: Got job 25 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:20,476 INFO scheduler.DAGScheduler: Final stage: ResultStage 37 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:20,476 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)\n",
      "2025-02-01 06:53:20,476 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 36)\n",
      "2025-02-01 06:53:20,478 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[150] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:20,485 INFO memory.MemoryStore: Block broadcast_30 stored as values in memory (estimated size 47.1 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:20,487 INFO memory.MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:20,487 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.0.119.186:40697 (size: 18.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:20,488 INFO spark.SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:20,488 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[150] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:20,488 INFO cluster.YarnScheduler: Adding task set 36.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:20,491 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 36.0 (TID 28) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:20,502 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on algo-1:34585 (size: 18.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:20,545 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 36.0 (TID 28) in 54 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:20,545 INFO cluster.YarnScheduler: Removed TaskSet 36.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:20,546 INFO scheduler.DAGScheduler: ShuffleMapStage 36 (countByKey at ColumnProfiler.scala:592) finished in 0.067 s\n",
      "2025-02-01 06:53:20,546 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:20,547 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:20,547 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 37)\n",
      "2025-02-01 06:53:20,547 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:20,548 INFO scheduler.DAGScheduler: Submitting ResultStage 37 (ShuffledRDD[151] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:20,549 INFO memory.MemoryStore: Block broadcast_31 stored as values in memory (estimated size 5.1 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:20,551 INFO memory.MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:20,552 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:20,552 INFO spark.SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:20,553 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (ShuffledRDD[151] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:20,553 INFO cluster.YarnScheduler: Adding task set 37.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:20,555 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 37.0 (TID 29) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:20,571 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:20,574 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:20,587 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 37.0 (TID 29) in 32 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:20,587 INFO cluster.YarnScheduler: Removed TaskSet 37.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:20,588 INFO scheduler.DAGScheduler: ResultStage 37 (countByKey at ColumnProfiler.scala:592) finished in 0.040 s\n",
      "2025-02-01 06:53:20,588 INFO scheduler.DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:20,588 INFO cluster.YarnScheduler: Killing all running tasks in stage 37: Stage finished\n",
      "2025-02-01 06:53:20,589 INFO scheduler.DAGScheduler: Job 25 finished: countByKey at ColumnProfiler.scala:592, took 0.115403 s\n",
      "2025-02-01 06:53:20,756 INFO scheduler.DAGScheduler: Registering RDD 156 (collect at AnalysisRunner.scala:326) as input to shuffle 12\n",
      "2025-02-01 06:53:20,757 INFO scheduler.DAGScheduler: Got map stage job 26 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:20,757 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 38 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:20,757 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:20,757 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:20,758 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[156] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:20,761 INFO memory.MemoryStore: Block broadcast_32 stored as values in memory (estimated size 100.0 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:20,762 INFO memory.MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:20,763 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.0.119.186:40697 (size: 32.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:20,763 INFO spark.SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:20,764 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[156] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:20,764 INFO cluster.YarnScheduler: Adding task set 38.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:20,766 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 38.0 (TID 30) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:20,779 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on algo-1:34585 (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:21,227 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 38.0 (TID 30) in 461 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:21,227 INFO cluster.YarnScheduler: Removed TaskSet 38.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:21,228 INFO scheduler.DAGScheduler: ShuffleMapStage 38 (collect at AnalysisRunner.scala:326) finished in 0.469 s\n",
      "2025-02-01 06:53:21,228 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:21,229 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:21,229 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:21,229 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:21,267 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:21,268 INFO scheduler.DAGScheduler: Got job 27 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:21,268 INFO scheduler.DAGScheduler: Final stage: ResultStage 40 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:21,268 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)\n",
      "2025-02-01 06:53:21,268 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:21,270 INFO scheduler.DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[159] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:21,277 INFO memory.MemoryStore: Block broadcast_33 stored as values in memory (estimated size 184.6 KiB, free 1457.0 MiB)\n",
      "2025-02-01 06:53:21,281 INFO memory.MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1456.9 MiB)\n",
      "2025-02-01 06:53:21,284 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.0.119.186:40697 (size: 50.3 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:21,286 INFO spark.SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:21,287 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[159] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:21,287 INFO cluster.YarnScheduler: Adding task set 40.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:21,291 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 40.0 (TID 31) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:21,303 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on algo-1:34585 (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:21,319 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:21,426 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 40.0 (TID 31) in 135 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:21,427 INFO cluster.YarnScheduler: Removed TaskSet 40.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:21,428 INFO scheduler.DAGScheduler: ResultStage 40 (collect at AnalysisRunner.scala:326) finished in 0.157 s\n",
      "2025-02-01 06:53:21,429 INFO scheduler.DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:21,429 INFO cluster.YarnScheduler: Killing all running tasks in stage 40: Stage finished\n",
      "2025-02-01 06:53:21,430 INFO scheduler.DAGScheduler: Job 27 finished: collect at AnalysisRunner.scala:326, took 0.162019 s\n",
      "2025-02-01 06:53:21,582 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on algo-1:34585 in memory (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:21,596 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on 10.0.119.186:40697 in memory (size: 32.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:21,627 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:21,638 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:21,643 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:21,644 INFO scheduler.DAGScheduler: Got job 28 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:21,646 INFO scheduler.DAGScheduler: Final stage: ResultStage 41 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:21,647 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:21,648 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:21,648 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:21,649 INFO scheduler.DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[169] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:21,653 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:21,662 INFO memory.MemoryStore: Block broadcast_34 stored as values in memory (estimated size 54.8 KiB, free 1457.1 MiB)\n",
      "2025-02-01 06:53:21,664 INFO memory.MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.1 MiB)\n",
      "2025-02-01 06:53:21,665 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:21,666 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on algo-1:34585 in memory (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:21,666 INFO spark.SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:21,667 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[169] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:21,667 INFO cluster.YarnScheduler: Adding task set 41.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:21,668 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 41.0 (TID 32) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:21,673 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on 10.0.119.186:40697 in memory (size: 50.3 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:21,686 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:21,698 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:21,699 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:21,724 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on 10.0.119.186:40697 in memory (size: 32.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:21,728 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on algo-1:34585 in memory (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:21,751 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 41.0 (TID 32) in 83 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:21,757 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on 10.0.119.186:40697 in memory (size: 18.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:21,758 INFO cluster.YarnScheduler: Removed TaskSet 41.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:21,759 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on algo-1:34585 in memory (size: 18.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:21,759 INFO scheduler.DAGScheduler: ResultStage 41 (treeReduce at KLLRunner.scala:107) finished in 0.109 s\n",
      "2025-02-01 06:53:21,760 INFO scheduler.DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:21,760 INFO cluster.YarnScheduler: Killing all running tasks in stage 41: Stage finished\n",
      "2025-02-01 06:53:21,760 INFO scheduler.DAGScheduler: Job 28 finished: treeReduce at KLLRunner.scala:107, took 0.116682 s\n",
      "2025-02-01 06:53:21,770 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:21,771 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:21,785 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on algo-1:34585 in memory (size: 28.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:21,794 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on 10.0.119.186:40697 in memory (size: 28.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:21,801 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:21,803 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:21,807 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on 10.0.119.186:40697 in memory (size: 18.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:21,809 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on algo-1:34585 in memory (size: 18.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:21,820 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on 10.0.119.186:40697 in memory (size: 50.3 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:21,820 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on algo-1:34585 in memory (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:21,985 INFO scheduler.DAGScheduler: Registering RDD 174 (collect at AnalysisRunner.scala:326) as input to shuffle 13\n",
      "2025-02-01 06:53:21,985 INFO scheduler.DAGScheduler: Got map stage job 29 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:21,985 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 42 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:21,986 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:21,986 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:21,987 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:21,990 INFO memory.MemoryStore: Block broadcast_35 stored as values in memory (estimated size 90.7 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:21,995 INFO memory.MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:21,996 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.0.119.186:40697 (size: 28.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:22,000 INFO spark.SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:22,001 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:22,001 INFO cluster.YarnScheduler: Adding task set 42.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:22,002 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 42.0 (TID 33) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:22,013 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on algo-1:34585 (size: 28.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:22,033 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 42.0 (TID 33) in 31 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:22,034 INFO scheduler.DAGScheduler: ShuffleMapStage 42 (collect at AnalysisRunner.scala:326) finished in 0.046 s\n",
      "2025-02-01 06:53:22,034 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:22,034 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:22,034 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:22,035 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:22,034 INFO cluster.YarnScheduler: Removed TaskSet 42.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:22,109 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:22,110 INFO scheduler.DAGScheduler: Got job 30 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:22,112 INFO scheduler.DAGScheduler: Final stage: ResultStage 44 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:22,112 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)\n",
      "2025-02-01 06:53:22,113 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:22,113 INFO scheduler.DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[177] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:22,115 INFO memory.MemoryStore: Block broadcast_36 stored as values in memory (estimated size 66.2 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:22,118 INFO memory.MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:22,118 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:22,119 INFO spark.SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:22,119 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[177] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:22,119 INFO cluster.YarnScheduler: Adding task set 44.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:22,121 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 44.0 (TID 34) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:22,133 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:22,146 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:22,158 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 44.0 (TID 34) in 38 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:22,158 INFO cluster.YarnScheduler: Removed TaskSet 44.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:22,159 INFO scheduler.DAGScheduler: ResultStage 44 (collect at AnalysisRunner.scala:326) finished in 0.045 s\n",
      "2025-02-01 06:53:22,160 INFO scheduler.DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:22,160 INFO cluster.YarnScheduler: Killing all running tasks in stage 44: Stage finished\n",
      "2025-02-01 06:53:22,160 INFO scheduler.DAGScheduler: Job 30 finished: collect at AnalysisRunner.scala:326, took 0.050797 s\n",
      "2025-02-01 06:53:22,216 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:22,216 INFO scheduler.DAGScheduler: Registering RDD 185 (countByKey at ColumnProfiler.scala:592) as input to shuffle 14\n",
      "2025-02-01 06:53:22,217 INFO scheduler.DAGScheduler: Got job 31 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:22,217 INFO scheduler.DAGScheduler: Final stage: ResultStage 46 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:22,217 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)\n",
      "2025-02-01 06:53:22,217 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 45)\n",
      "2025-02-01 06:53:22,218 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[185] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:22,226 INFO memory.MemoryStore: Block broadcast_37 stored as values in memory (estimated size 47.1 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:22,227 INFO memory.MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:22,228 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:22,228 INFO spark.SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:22,228 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[185] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:22,228 INFO cluster.YarnScheduler: Adding task set 45.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:22,230 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 45.0 (TID 35) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:22,245 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:22,296 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 45.0 (TID 35) in 67 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:22,296 INFO cluster.YarnScheduler: Removed TaskSet 45.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:22,297 INFO scheduler.DAGScheduler: ShuffleMapStage 45 (countByKey at ColumnProfiler.scala:592) finished in 0.078 s\n",
      "2025-02-01 06:53:22,297 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:22,297 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:22,297 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 46)\n",
      "2025-02-01 06:53:22,297 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:22,298 INFO scheduler.DAGScheduler: Submitting ResultStage 46 (ShuffledRDD[186] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:22,299 INFO memory.MemoryStore: Block broadcast_38 stored as values in memory (estimated size 5.1 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:22,301 INFO memory.MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:22,302 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:22,304 INFO spark.SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:22,304 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (ShuffledRDD[186] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:22,304 INFO cluster.YarnScheduler: Adding task set 46.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:22,305 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 46.0 (TID 36) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:22,321 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:22,325 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:22,348 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 46.0 (TID 36) in 43 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:22,348 INFO cluster.YarnScheduler: Removed TaskSet 46.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:22,349 INFO scheduler.DAGScheduler: ResultStage 46 (countByKey at ColumnProfiler.scala:592) finished in 0.051 s\n",
      "2025-02-01 06:53:22,349 INFO scheduler.DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:22,349 INFO cluster.YarnScheduler: Killing all running tasks in stage 46: Stage finished\n",
      "2025-02-01 06:53:22,350 INFO scheduler.DAGScheduler: Job 31 finished: countByKey at ColumnProfiler.scala:592, took 0.134133 s\n",
      "2025-02-01 06:53:22,608 INFO scheduler.DAGScheduler: Registering RDD 191 (collect at AnalysisRunner.scala:326) as input to shuffle 15\n",
      "2025-02-01 06:53:22,609 INFO scheduler.DAGScheduler: Got map stage job 32 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:22,609 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 47 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:22,609 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:22,610 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:22,610 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[191] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:22,614 INFO memory.MemoryStore: Block broadcast_39 stored as values in memory (estimated size 100.0 KiB, free 1457.7 MiB)\n",
      "2025-02-01 06:53:22,616 INFO memory.MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.7 MiB)\n",
      "2025-02-01 06:53:22,618 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.0.119.186:40697 (size: 32.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:22,618 INFO spark.SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:22,619 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[191] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:22,619 INFO cluster.YarnScheduler: Adding task set 47.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:22,621 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 47.0 (TID 37) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:22,636 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on algo-1:34585 (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:22,878 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 47.0 (TID 37) in 257 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:22,881 INFO cluster.YarnScheduler: Removed TaskSet 47.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:22,881 INFO scheduler.DAGScheduler: ShuffleMapStage 47 (collect at AnalysisRunner.scala:326) finished in 0.270 s\n",
      "2025-02-01 06:53:22,882 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:22,882 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:22,882 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:22,883 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:22,997 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:23,003 INFO scheduler.DAGScheduler: Got job 33 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:23,003 INFO scheduler.DAGScheduler: Final stage: ResultStage 49 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:23,004 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)\n",
      "2025-02-01 06:53:23,004 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:23,004 INFO scheduler.DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[194] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:23,020 INFO memory.MemoryStore: Block broadcast_40 stored as values in memory (estimated size 184.6 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:23,022 INFO memory.MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:23,023 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.0.119.186:40697 (size: 50.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:23,025 INFO spark.SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:23,025 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[194] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:23,025 INFO cluster.YarnScheduler: Adding task set 49.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:23,026 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 49.0 (TID 38) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:23,043 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on algo-1:34585 (size: 50.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:23,068 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:23,222 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 49.0 (TID 38) in 196 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:23,222 INFO cluster.YarnScheduler: Removed TaskSet 49.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:23,223 INFO scheduler.DAGScheduler: ResultStage 49 (collect at AnalysisRunner.scala:326) finished in 0.218 s\n",
      "2025-02-01 06:53:23,224 INFO scheduler.DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:23,228 INFO cluster.YarnScheduler: Killing all running tasks in stage 49: Stage finished\n",
      "2025-02-01 06:53:23,229 INFO scheduler.DAGScheduler: Job 33 finished: collect at AnalysisRunner.scala:326, took 0.226944 s\n",
      "2025-02-01 06:53:23,456 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:23,463 INFO scheduler.DAGScheduler: Got job 34 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:23,463 INFO scheduler.DAGScheduler: Final stage: ResultStage 50 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:23,463 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:23,464 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:23,464 INFO scheduler.DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[204] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:23,472 INFO memory.MemoryStore: Block broadcast_41 stored as values in memory (estimated size 54.8 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:23,474 INFO memory.MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:23,475 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:23,476 INFO spark.SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:23,479 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[204] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:23,479 INFO cluster.YarnScheduler: Adding task set 50.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:23,481 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 50.0 (TID 39) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:23,490 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:23,553 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 50.0 (TID 39) in 72 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:23,557 INFO scheduler.DAGScheduler: ResultStage 50 (treeReduce at KLLRunner.scala:107) finished in 0.090 s\n",
      "2025-02-01 06:53:23,558 INFO scheduler.DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:23,558 INFO cluster.YarnScheduler: Removed TaskSet 50.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:23,558 INFO cluster.YarnScheduler: Killing all running tasks in stage 50: Stage finished\n",
      "2025-02-01 06:53:23,559 INFO scheduler.DAGScheduler: Job 34 finished: treeReduce at KLLRunner.scala:107, took 0.095714 s\n",
      "2025-02-01 06:53:23,846 INFO scheduler.DAGScheduler: Registering RDD 209 (collect at AnalysisRunner.scala:326) as input to shuffle 16\n",
      "2025-02-01 06:53:23,846 INFO scheduler.DAGScheduler: Got map stage job 35 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:23,846 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 51 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:23,846 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:23,848 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:23,848 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[209] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:23,854 INFO memory.MemoryStore: Block broadcast_42 stored as values in memory (estimated size 90.7 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:23,856 INFO memory.MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:23,856 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.0.119.186:40697 (size: 27.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:23,857 INFO spark.SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:23,857 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[209] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:23,857 INFO cluster.YarnScheduler: Adding task set 51.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:23,868 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 51.0 (TID 40) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:23,877 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on algo-1:34585 (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:23,908 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 51.0 (TID 40) in 40 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:23,909 INFO cluster.YarnScheduler: Removed TaskSet 51.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:23,909 INFO scheduler.DAGScheduler: ShuffleMapStage 51 (collect at AnalysisRunner.scala:326) finished in 0.058 s\n",
      "2025-02-01 06:53:23,910 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:23,910 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:23,910 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:23,910 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:24,027 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:24,033 INFO scheduler.DAGScheduler: Got job 36 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:24,033 INFO scheduler.DAGScheduler: Final stage: ResultStage 53 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:24,033 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)\n",
      "2025-02-01 06:53:24,033 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:24,033 INFO scheduler.DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[212] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:24,035 INFO memory.MemoryStore: Block broadcast_43 stored as values in memory (estimated size 66.2 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:24,037 INFO memory.MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:24,037 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:24,040 INFO spark.SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:24,041 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[212] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:24,041 INFO cluster.YarnScheduler: Adding task set 53.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:24,042 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 53.0 (TID 41) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:24,052 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:24,056 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:24,068 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 53.0 (TID 41) in 26 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:24,068 INFO cluster.YarnScheduler: Removed TaskSet 53.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:24,068 INFO scheduler.DAGScheduler: ResultStage 53 (collect at AnalysisRunner.scala:326) finished in 0.034 s\n",
      "2025-02-01 06:53:24,068 INFO scheduler.DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:24,069 INFO cluster.YarnScheduler: Killing all running tasks in stage 53: Stage finished\n",
      "2025-02-01 06:53:24,069 INFO scheduler.DAGScheduler: Job 36 finished: collect at AnalysisRunner.scala:326, took 0.041308 s\n",
      "2025-02-01 06:53:24,195 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:24,196 INFO scheduler.DAGScheduler: Registering RDD 220 (countByKey at ColumnProfiler.scala:592) as input to shuffle 17\n",
      "2025-02-01 06:53:24,196 INFO scheduler.DAGScheduler: Got job 37 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:24,196 INFO scheduler.DAGScheduler: Final stage: ResultStage 55 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:24,196 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)\n",
      "2025-02-01 06:53:24,197 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 54)\n",
      "2025-02-01 06:53:24,197 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[220] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:24,204 INFO memory.MemoryStore: Block broadcast_44 stored as values in memory (estimated size 47.1 KiB, free 1457.1 MiB)\n",
      "2025-02-01 06:53:24,205 INFO memory.MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.1 MiB)\n",
      "2025-02-01 06:53:24,206 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:24,206 INFO spark.SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:24,207 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[220] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:24,207 INFO cluster.YarnScheduler: Adding task set 54.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:24,208 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 54.0 (TID 42) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:24,215 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:24,278 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 54.0 (TID 42) in 71 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:24,281 INFO cluster.YarnScheduler: Removed TaskSet 54.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:24,282 INFO scheduler.DAGScheduler: ShuffleMapStage 54 (countByKey at ColumnProfiler.scala:592) finished in 0.084 s\n",
      "2025-02-01 06:53:24,282 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:24,282 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:24,282 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 55)\n",
      "2025-02-01 06:53:24,282 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:24,283 INFO scheduler.DAGScheduler: Submitting ResultStage 55 (ShuffledRDD[221] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:24,284 INFO memory.MemoryStore: Block broadcast_45 stored as values in memory (estimated size 5.1 KiB, free 1457.1 MiB)\n",
      "2025-02-01 06:53:24,315 INFO memory.MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.1 MiB)\n",
      "2025-02-01 06:53:24,317 INFO storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:24,318 INFO spark.SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:24,318 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (ShuffledRDD[221] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:24,318 INFO storage.BlockManagerInfo: Removed broadcast_38_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:24,318 INFO cluster.YarnScheduler: Adding task set 55.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:24,320 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 55.0 (TID 43) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:24,327 INFO storage.BlockManagerInfo: Removed broadcast_38_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:24,334 INFO storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:24,337 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:24,340 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:24,342 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:24,346 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on algo-1:34585 in memory (size: 50.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:24,347 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on 10.0.119.186:40697 in memory (size: 50.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:24,350 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on 10.0.119.186:40697 in memory (size: 28.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:24,352 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on algo-1:34585 in memory (size: 28.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:24,354 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:24,355 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:24,358 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:24,363 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:24,366 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on 10.0.119.186:40697 in memory (size: 32.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:24,370 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on algo-1:34585 in memory (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:24,376 INFO storage.BlockManagerInfo: Removed broadcast_42_piece0 on 10.0.119.186:40697 in memory (size: 27.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:24,380 INFO storage.BlockManagerInfo: Removed broadcast_42_piece0 on algo-1:34585 in memory (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:24,389 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:24,392 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:24,393 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 55.0 (TID 43) in 73 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:24,394 INFO cluster.YarnScheduler: Removed TaskSet 55.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:24,394 INFO scheduler.DAGScheduler: ResultStage 55 (countByKey at ColumnProfiler.scala:592) finished in 0.111 s\n",
      "2025-02-01 06:53:24,394 INFO scheduler.DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:24,394 INFO cluster.YarnScheduler: Killing all running tasks in stage 55: Stage finished\n",
      "2025-02-01 06:53:24,395 INFO scheduler.DAGScheduler: Job 37 finished: countByKey at ColumnProfiler.scala:592, took 0.199136 s\n",
      "2025-02-01 06:53:24,404 INFO storage.BlockManagerInfo: Removed broadcast_43_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:24,408 INFO storage.BlockManagerInfo: Removed broadcast_43_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:24,662 INFO scheduler.DAGScheduler: Registering RDD 226 (collect at AnalysisRunner.scala:326) as input to shuffle 18\n",
      "2025-02-01 06:53:24,662 INFO scheduler.DAGScheduler: Got map stage job 38 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:24,662 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 56 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:24,662 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:24,663 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:24,663 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[226] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:24,668 INFO memory.MemoryStore: Block broadcast_46 stored as values in memory (estimated size 100.0 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:24,670 INFO memory.MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:24,673 INFO storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on 10.0.119.186:40697 (size: 32.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:24,673 INFO spark.SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:24,674 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[226] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:24,674 INFO cluster.YarnScheduler: Adding task set 56.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:24,675 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 56.0 (TID 44) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:24,686 INFO storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on algo-1:34585 (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:24,816 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 56.0 (TID 44) in 141 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:24,816 INFO cluster.YarnScheduler: Removed TaskSet 56.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:24,818 INFO scheduler.DAGScheduler: ShuffleMapStage 56 (collect at AnalysisRunner.scala:326) finished in 0.153 s\n",
      "2025-02-01 06:53:24,819 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:24,820 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:24,820 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:24,820 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:24,888 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:24,889 INFO scheduler.DAGScheduler: Got job 39 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:24,889 INFO scheduler.DAGScheduler: Final stage: ResultStage 58 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:24,889 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)\n",
      "2025-02-01 06:53:24,890 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:24,890 INFO scheduler.DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[229] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:24,898 INFO memory.MemoryStore: Block broadcast_47 stored as values in memory (estimated size 184.6 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:24,900 INFO memory.MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.7 MiB)\n",
      "2025-02-01 06:53:24,904 INFO storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on 10.0.119.186:40697 (size: 50.3 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:24,904 INFO spark.SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:24,905 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[229] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:24,905 INFO cluster.YarnScheduler: Adding task set 58.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:24,906 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 58.0 (TID 45) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:24,919 INFO storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on algo-1:34585 (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:24,932 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:25,058 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 58.0 (TID 45) in 152 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:25,059 INFO scheduler.DAGScheduler: ResultStage 58 (collect at AnalysisRunner.scala:326) finished in 0.167 s\n",
      "2025-02-01 06:53:25,059 INFO scheduler.DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:25,060 INFO cluster.YarnScheduler: Removed TaskSet 58.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:25,060 INFO cluster.YarnScheduler: Killing all running tasks in stage 58: Stage finished\n",
      "2025-02-01 06:53:25,061 INFO scheduler.DAGScheduler: Job 39 finished: collect at AnalysisRunner.scala:326, took 0.172245 s\n",
      "2025-02-01 06:53:25,258 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:25,260 INFO scheduler.DAGScheduler: Got job 40 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:25,260 INFO scheduler.DAGScheduler: Final stage: ResultStage 59 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:25,260 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:25,263 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:25,264 INFO scheduler.DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[239] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:25,270 INFO memory.MemoryStore: Block broadcast_48 stored as values in memory (estimated size 54.8 KiB, free 1457.7 MiB)\n",
      "2025-02-01 06:53:25,273 INFO memory.MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.6 MiB)\n",
      "2025-02-01 06:53:25,273 INFO storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:25,277 INFO spark.SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:25,278 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[239] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:25,278 INFO cluster.YarnScheduler: Adding task set 59.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:25,279 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 59.0 (TID 46) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:25,289 INFO storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:25,326 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 59.0 (TID 46) in 47 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:25,327 INFO scheduler.DAGScheduler: ResultStage 59 (treeReduce at KLLRunner.scala:107) finished in 0.062 s\n",
      "2025-02-01 06:53:25,328 INFO scheduler.DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:25,329 INFO cluster.YarnScheduler: Removed TaskSet 59.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:25,329 INFO cluster.YarnScheduler: Killing all running tasks in stage 59: Stage finished\n",
      "2025-02-01 06:53:25,329 INFO scheduler.DAGScheduler: Job 40 finished: treeReduce at KLLRunner.scala:107, took 0.069953 s\n",
      "2025-02-01 06:53:25,531 INFO scheduler.DAGScheduler: Registering RDD 244 (collect at AnalysisRunner.scala:326) as input to shuffle 19\n",
      "2025-02-01 06:53:25,532 INFO scheduler.DAGScheduler: Got map stage job 41 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:25,532 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 60 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:25,532 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:25,533 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:25,533 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[244] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:25,537 INFO memory.MemoryStore: Block broadcast_49 stored as values in memory (estimated size 90.7 KiB, free 1457.6 MiB)\n",
      "2025-02-01 06:53:25,539 INFO memory.MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:25,539 INFO storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on 10.0.119.186:40697 (size: 28.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:25,540 INFO spark.SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:25,540 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[244] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:25,540 INFO cluster.YarnScheduler: Adding task set 60.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:25,542 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 60.0 (TID 47) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:25,553 INFO storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on algo-1:34585 (size: 28.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:25,588 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 60.0 (TID 47) in 46 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:25,588 INFO cluster.YarnScheduler: Removed TaskSet 60.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:25,589 INFO scheduler.DAGScheduler: ShuffleMapStage 60 (collect at AnalysisRunner.scala:326) finished in 0.055 s\n",
      "2025-02-01 06:53:25,594 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:25,595 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:25,595 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:25,595 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:25,645 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:25,646 INFO scheduler.DAGScheduler: Got job 42 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:25,646 INFO scheduler.DAGScheduler: Final stage: ResultStage 62 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:25,646 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)\n",
      "2025-02-01 06:53:25,646 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:25,646 INFO scheduler.DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[247] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:25,648 INFO memory.MemoryStore: Block broadcast_50 stored as values in memory (estimated size 66.2 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:25,649 INFO memory.MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:25,650 INFO storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:25,650 INFO spark.SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:25,650 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[247] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:25,650 INFO cluster.YarnScheduler: Adding task set 62.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:25,651 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 62.0 (TID 48) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:25,659 INFO storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:25,663 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:25,675 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 62.0 (TID 48) in 24 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:25,675 INFO cluster.YarnScheduler: Removed TaskSet 62.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:25,676 INFO scheduler.DAGScheduler: ResultStage 62 (collect at AnalysisRunner.scala:326) finished in 0.029 s\n",
      "2025-02-01 06:53:25,676 INFO scheduler.DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:25,676 INFO cluster.YarnScheduler: Killing all running tasks in stage 62: Stage finished\n",
      "2025-02-01 06:53:25,677 INFO scheduler.DAGScheduler: Job 42 finished: collect at AnalysisRunner.scala:326, took 0.031735 s\n",
      "2025-02-01 06:53:25,724 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:25,725 INFO scheduler.DAGScheduler: Registering RDD 255 (countByKey at ColumnProfiler.scala:592) as input to shuffle 20\n",
      "2025-02-01 06:53:25,725 INFO scheduler.DAGScheduler: Got job 43 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:25,726 INFO scheduler.DAGScheduler: Final stage: ResultStage 64 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:25,726 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)\n",
      "2025-02-01 06:53:25,726 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 63)\n",
      "2025-02-01 06:53:25,728 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 63 (MapPartitionsRDD[255] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:25,733 INFO memory.MemoryStore: Block broadcast_51 stored as values in memory (estimated size 47.1 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:25,735 INFO memory.MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:25,735 INFO storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on 10.0.119.186:40697 (size: 18.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:25,736 INFO spark.SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:25,736 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[255] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:25,737 INFO cluster.YarnScheduler: Adding task set 63.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:25,738 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 63.0 (TID 49) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:25,746 INFO storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on algo-1:34585 (size: 18.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:25,801 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 63.0 (TID 49) in 63 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:25,801 INFO cluster.YarnScheduler: Removed TaskSet 63.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:25,804 INFO scheduler.DAGScheduler: ShuffleMapStage 63 (countByKey at ColumnProfiler.scala:592) finished in 0.075 s\n",
      "2025-02-01 06:53:25,805 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:25,805 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:25,805 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 64)\n",
      "2025-02-01 06:53:25,806 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:25,806 INFO scheduler.DAGScheduler: Submitting ResultStage 64 (ShuffledRDD[256] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:25,808 INFO memory.MemoryStore: Block broadcast_52 stored as values in memory (estimated size 5.1 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:25,809 INFO memory.MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:25,810 INFO storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:25,810 INFO spark.SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:25,811 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (ShuffledRDD[256] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:25,811 INFO cluster.YarnScheduler: Adding task set 64.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:25,812 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 64.0 (TID 50) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:25,826 INFO storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:25,833 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:25,842 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 64.0 (TID 50) in 30 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:25,843 INFO scheduler.DAGScheduler: ResultStage 64 (countByKey at ColumnProfiler.scala:592) finished in 0.036 s\n",
      "2025-02-01 06:53:25,844 INFO scheduler.DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:25,843 INFO cluster.YarnScheduler: Removed TaskSet 64.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:25,844 INFO cluster.YarnScheduler: Killing all running tasks in stage 64: Stage finished\n",
      "2025-02-01 06:53:25,845 INFO scheduler.DAGScheduler: Job 43 finished: countByKey at ColumnProfiler.scala:592, took 0.120824 s\n",
      "2025-02-01 06:53:25,973 INFO scheduler.DAGScheduler: Registering RDD 261 (collect at AnalysisRunner.scala:326) as input to shuffle 21\n",
      "2025-02-01 06:53:25,974 INFO scheduler.DAGScheduler: Got map stage job 44 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:25,974 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 65 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:25,975 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:25,975 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:25,976 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[261] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:25,980 INFO memory.MemoryStore: Block broadcast_53 stored as values in memory (estimated size 100.0 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:25,981 INFO memory.MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:25,981 INFO storage.BlockManagerInfo: Added broadcast_53_piece0 in memory on 10.0.119.186:40697 (size: 32.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:25,982 INFO spark.SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:25,982 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[261] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:25,982 INFO cluster.YarnScheduler: Adding task set 65.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:25,983 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 65.0 (TID 51) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:25,992 INFO storage.BlockManagerInfo: Added broadcast_53_piece0 in memory on algo-1:34585 (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,164 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 65.0 (TID 51) in 181 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:26,164 INFO cluster.YarnScheduler: Removed TaskSet 65.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:26,165 INFO scheduler.DAGScheduler: ShuffleMapStage 65 (collect at AnalysisRunner.scala:326) finished in 0.189 s\n",
      "2025-02-01 06:53:26,165 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:26,166 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:26,166 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:26,166 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:26,202 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:26,203 INFO scheduler.DAGScheduler: Got job 45 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:26,203 INFO scheduler.DAGScheduler: Final stage: ResultStage 67 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:26,203 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)\n",
      "2025-02-01 06:53:26,203 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:26,203 INFO scheduler.DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[264] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:26,209 INFO memory.MemoryStore: Block broadcast_54 stored as values in memory (estimated size 184.6 KiB, free 1457.1 MiB)\n",
      "2025-02-01 06:53:26,210 INFO memory.MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.0 MiB)\n",
      "2025-02-01 06:53:26,211 INFO storage.BlockManagerInfo: Added broadcast_54_piece0 in memory on 10.0.119.186:40697 (size: 50.3 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:26,212 INFO spark.SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:26,212 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[264] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:26,212 INFO cluster.YarnScheduler: Adding task set 67.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:26,213 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 67.0 (TID 52) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:26,226 INFO storage.BlockManagerInfo: Added broadcast_54_piece0 in memory on algo-1:34585 (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,244 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:26,344 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 67.0 (TID 52) in 131 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:26,344 INFO cluster.YarnScheduler: Removed TaskSet 67.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:26,345 INFO scheduler.DAGScheduler: ResultStage 67 (collect at AnalysisRunner.scala:326) finished in 0.141 s\n",
      "2025-02-01 06:53:26,345 INFO scheduler.DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:26,345 INFO cluster.YarnScheduler: Killing all running tasks in stage 67: Stage finished\n",
      "2025-02-01 06:53:26,346 INFO scheduler.DAGScheduler: Job 45 finished: collect at AnalysisRunner.scala:326, took 0.143901 s\n",
      "2025-02-01 06:53:26,486 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:26,487 INFO scheduler.DAGScheduler: Got job 46 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:26,487 INFO scheduler.DAGScheduler: Final stage: ResultStage 68 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:26,488 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:26,488 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:26,489 INFO scheduler.DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[274] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:26,501 INFO memory.MemoryStore: Block broadcast_55 stored as values in memory (estimated size 54.8 KiB, free 1457.0 MiB)\n",
      "2025-02-01 06:53:26,503 INFO memory.MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.9 MiB)\n",
      "2025-02-01 06:53:26,504 INFO storage.BlockManagerInfo: Added broadcast_55_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:26,504 INFO spark.SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:26,505 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[274] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:26,507 INFO cluster.YarnScheduler: Adding task set 68.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:26,509 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 68.0 (TID 53) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:26,516 INFO storage.BlockManagerInfo: Added broadcast_55_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,571 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 68.0 (TID 53) in 63 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:26,572 INFO scheduler.DAGScheduler: ResultStage 68 (treeReduce at KLLRunner.scala:107) finished in 0.079 s\n",
      "2025-02-01 06:53:26,573 INFO scheduler.DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:26,573 INFO cluster.YarnScheduler: Removed TaskSet 68.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:26,574 INFO cluster.YarnScheduler: Killing all running tasks in stage 68: Stage finished\n",
      "2025-02-01 06:53:26,574 INFO scheduler.DAGScheduler: Job 46 finished: treeReduce at KLLRunner.scala:107, took 0.087983 s\n",
      "2025-02-01 06:53:26,736 INFO scheduler.DAGScheduler: Registering RDD 279 (collect at AnalysisRunner.scala:326) as input to shuffle 22\n",
      "2025-02-01 06:53:26,736 INFO scheduler.DAGScheduler: Got map stage job 47 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:26,737 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 69 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:26,737 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:26,738 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:26,738 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[279] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:26,745 INFO memory.MemoryStore: Block broadcast_56 stored as values in memory (estimated size 90.7 KiB, free 1456.9 MiB)\n",
      "2025-02-01 06:53:26,747 INFO memory.MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.8 MiB)\n",
      "2025-02-01 06:53:26,748 INFO storage.BlockManagerInfo: Added broadcast_56_piece0 in memory on 10.0.119.186:40697 (size: 27.9 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:26,752 INFO spark.SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:26,752 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[279] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:26,754 INFO cluster.YarnScheduler: Adding task set 69.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:26,757 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 69.0 (TID 54) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:26,764 INFO storage.BlockManagerInfo: Added broadcast_56_piece0 in memory on algo-1:34585 (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,794 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 69.0 (TID 54) in 38 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:26,794 INFO cluster.YarnScheduler: Removed TaskSet 69.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:26,795 INFO scheduler.DAGScheduler: ShuffleMapStage 69 (collect at AnalysisRunner.scala:326) finished in 0.055 s\n",
      "2025-02-01 06:53:26,796 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:26,797 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:26,797 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:26,797 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:26,895 INFO storage.BlockManagerInfo: Removed broadcast_47_piece0 on algo-1:34585 in memory (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,898 INFO storage.BlockManagerInfo: Removed broadcast_47_piece0 on 10.0.119.186:40697 in memory (size: 50.3 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:26,905 INFO storage.BlockManagerInfo: Removed broadcast_44_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:26,907 INFO storage.BlockManagerInfo: Removed broadcast_44_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,909 INFO storage.BlockManagerInfo: Removed broadcast_56_piece0 on 10.0.119.186:40697 in memory (size: 27.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:26,911 INFO storage.BlockManagerInfo: Removed broadcast_56_piece0 on algo-1:34585 in memory (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,916 INFO storage.BlockManagerInfo: Removed broadcast_53_piece0 on 10.0.119.186:40697 in memory (size: 32.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:26,920 INFO storage.BlockManagerInfo: Removed broadcast_53_piece0 on algo-1:34585 in memory (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,924 INFO storage.BlockManagerInfo: Removed broadcast_51_piece0 on 10.0.119.186:40697 in memory (size: 18.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:26,926 INFO storage.BlockManagerInfo: Removed broadcast_51_piece0 on algo-1:34585 in memory (size: 18.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,930 INFO storage.BlockManagerInfo: Removed broadcast_49_piece0 on 10.0.119.186:40697 in memory (size: 28.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:26,932 INFO storage.BlockManagerInfo: Removed broadcast_49_piece0 on algo-1:34585 in memory (size: 28.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,936 INFO storage.BlockManagerInfo: Removed broadcast_55_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:26,937 INFO storage.BlockManagerInfo: Removed broadcast_55_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,939 INFO storage.BlockManagerInfo: Removed broadcast_45_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:26,940 INFO storage.BlockManagerInfo: Removed broadcast_45_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,942 INFO storage.BlockManagerInfo: Removed broadcast_52_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:26,943 INFO storage.BlockManagerInfo: Removed broadcast_52_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,946 INFO storage.BlockManagerInfo: Removed broadcast_48_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:26,947 INFO storage.BlockManagerInfo: Removed broadcast_48_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,951 INFO storage.BlockManagerInfo: Removed broadcast_50_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:26,952 INFO storage.BlockManagerInfo: Removed broadcast_50_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,957 INFO storage.BlockManagerInfo: Removed broadcast_46_piece0 on 10.0.119.186:40697 in memory (size: 32.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:26,958 INFO storage.BlockManagerInfo: Removed broadcast_46_piece0 on algo-1:34585 in memory (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,960 INFO storage.BlockManagerInfo: Removed broadcast_54_piece0 on 10.0.119.186:40697 in memory (size: 50.3 KiB, free: 1458.6 MiB)\n",
      "2025-02-01 06:53:26,968 INFO storage.BlockManagerInfo: Removed broadcast_54_piece0 on algo-1:34585 in memory (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,978 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:26,979 INFO scheduler.DAGScheduler: Got job 48 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:26,979 INFO scheduler.DAGScheduler: Final stage: ResultStage 71 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:26,979 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)\n",
      "2025-02-01 06:53:26,979 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:26,980 INFO scheduler.DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[282] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:26,982 INFO memory.MemoryStore: Block broadcast_57 stored as values in memory (estimated size 66.2 KiB, free 1458.1 MiB)\n",
      "2025-02-01 06:53:26,984 INFO memory.MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1458.1 MiB)\n",
      "2025-02-01 06:53:26,985 INFO storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:26,985 INFO spark.SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:26,986 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[282] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:26,986 INFO cluster.YarnScheduler: Adding task set 71.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:26,987 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 71.0 (TID 55) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:26,995 INFO storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:26,999 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:27,011 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 71.0 (TID 55) in 24 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:27,011 INFO cluster.YarnScheduler: Removed TaskSet 71.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:27,011 INFO scheduler.DAGScheduler: ResultStage 71 (collect at AnalysisRunner.scala:326) finished in 0.030 s\n",
      "2025-02-01 06:53:27,012 INFO scheduler.DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:27,013 INFO cluster.YarnScheduler: Killing all running tasks in stage 71: Stage finished\n",
      "2025-02-01 06:53:27,013 INFO scheduler.DAGScheduler: Job 48 finished: collect at AnalysisRunner.scala:326, took 0.035065 s\n",
      "2025-02-01 06:53:27,111 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:27,112 INFO scheduler.DAGScheduler: Registering RDD 290 (countByKey at ColumnProfiler.scala:592) as input to shuffle 23\n",
      "2025-02-01 06:53:27,113 INFO scheduler.DAGScheduler: Got job 49 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:27,113 INFO scheduler.DAGScheduler: Final stage: ResultStage 73 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:27,113 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)\n",
      "2025-02-01 06:53:27,113 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 72)\n",
      "2025-02-01 06:53:27,114 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[290] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:27,124 INFO memory.MemoryStore: Block broadcast_58 stored as values in memory (estimated size 47.1 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:27,126 INFO memory.MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:27,126 INFO storage.BlockManagerInfo: Added broadcast_58_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:27,127 INFO spark.SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:27,127 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[290] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:27,127 INFO cluster.YarnScheduler: Adding task set 72.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:27,129 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 72.0 (TID 56) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:27,136 INFO storage.BlockManagerInfo: Added broadcast_58_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:27,183 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 72.0 (TID 56) in 55 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:27,184 INFO cluster.YarnScheduler: Removed TaskSet 72.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:27,184 INFO scheduler.DAGScheduler: ShuffleMapStage 72 (countByKey at ColumnProfiler.scala:592) finished in 0.069 s\n",
      "2025-02-01 06:53:27,185 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:27,185 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:27,185 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 73)\n",
      "2025-02-01 06:53:27,185 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:27,186 INFO scheduler.DAGScheduler: Submitting ResultStage 73 (ShuffledRDD[291] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:27,188 INFO memory.MemoryStore: Block broadcast_59 stored as values in memory (estimated size 5.1 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:27,189 INFO memory.MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:27,190 INFO storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:27,190 INFO spark.SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:27,191 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (ShuffledRDD[291] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:27,191 INFO cluster.YarnScheduler: Adding task set 73.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:27,192 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 73.0 (TID 57) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:27,199 INFO storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:27,202 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:27,210 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 73.0 (TID 57) in 18 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:27,210 INFO cluster.YarnScheduler: Removed TaskSet 73.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:27,211 INFO scheduler.DAGScheduler: ResultStage 73 (countByKey at ColumnProfiler.scala:592) finished in 0.024 s\n",
      "2025-02-01 06:53:27,215 INFO scheduler.DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:27,215 INFO cluster.YarnScheduler: Killing all running tasks in stage 73: Stage finished\n",
      "2025-02-01 06:53:27,216 INFO scheduler.DAGScheduler: Job 49 finished: countByKey at ColumnProfiler.scala:592, took 0.104416 s\n",
      "2025-02-01 06:53:27,396 INFO scheduler.DAGScheduler: Registering RDD 296 (collect at AnalysisRunner.scala:326) as input to shuffle 24\n",
      "2025-02-01 06:53:27,397 INFO scheduler.DAGScheduler: Got map stage job 50 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:27,397 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 74 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:27,397 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:27,398 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:27,398 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 74 (MapPartitionsRDD[296] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:27,408 INFO memory.MemoryStore: Block broadcast_60 stored as values in memory (estimated size 100.0 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:27,410 INFO memory.MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:27,410 INFO storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on 10.0.119.186:40697 (size: 32.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:27,411 INFO spark.SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:27,412 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 74 (MapPartitionsRDD[296] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:27,412 INFO cluster.YarnScheduler: Adding task set 74.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:27,414 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 74.0 (TID 58) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:27,422 INFO storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on algo-1:34585 (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:27,589 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 74.0 (TID 58) in 176 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:27,589 INFO cluster.YarnScheduler: Removed TaskSet 74.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:27,590 INFO scheduler.DAGScheduler: ShuffleMapStage 74 (collect at AnalysisRunner.scala:326) finished in 0.190 s\n",
      "2025-02-01 06:53:27,591 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:27,591 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:27,591 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:27,591 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:27,637 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:27,638 INFO scheduler.DAGScheduler: Got job 51 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:27,638 INFO scheduler.DAGScheduler: Final stage: ResultStage 76 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:27,638 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)\n",
      "2025-02-01 06:53:27,638 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:27,640 INFO scheduler.DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[299] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:27,645 INFO memory.MemoryStore: Block broadcast_61 stored as values in memory (estimated size 184.6 KiB, free 1457.7 MiB)\n",
      "2025-02-01 06:53:27,647 INFO memory.MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.6 MiB)\n",
      "2025-02-01 06:53:27,647 INFO storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on 10.0.119.186:40697 (size: 50.3 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:27,648 INFO spark.SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:27,648 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[299] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:27,648 INFO cluster.YarnScheduler: Adding task set 76.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:27,649 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 76.0 (TID 59) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:27,657 INFO storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on algo-1:34585 (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:27,672 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:27,804 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 76.0 (TID 59) in 154 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:27,804 INFO cluster.YarnScheduler: Removed TaskSet 76.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:27,804 INFO scheduler.DAGScheduler: ResultStage 76 (collect at AnalysisRunner.scala:326) finished in 0.164 s\n",
      "2025-02-01 06:53:27,805 INFO scheduler.DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:27,805 INFO cluster.YarnScheduler: Killing all running tasks in stage 76: Stage finished\n",
      "2025-02-01 06:53:27,805 INFO scheduler.DAGScheduler: Job 51 finished: collect at AnalysisRunner.scala:326, took 0.167700 s\n",
      "2025-02-01 06:53:27,956 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:27,957 INFO scheduler.DAGScheduler: Got job 52 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:27,957 INFO scheduler.DAGScheduler: Final stage: ResultStage 77 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:27,957 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:27,958 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:27,958 INFO scheduler.DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[309] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:27,972 INFO memory.MemoryStore: Block broadcast_62 stored as values in memory (estimated size 54.8 KiB, free 1457.6 MiB)\n",
      "2025-02-01 06:53:27,974 INFO memory.MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.6 MiB)\n",
      "2025-02-01 06:53:27,975 INFO storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:27,975 INFO spark.SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:27,975 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[309] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:27,976 INFO cluster.YarnScheduler: Adding task set 77.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:27,983 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 77.0 (TID 60) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:27,991 INFO storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:28,051 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 77.0 (TID 60) in 69 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:28,051 INFO cluster.YarnScheduler: Removed TaskSet 77.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:28,052 INFO scheduler.DAGScheduler: ResultStage 77 (treeReduce at KLLRunner.scala:107) finished in 0.090 s\n",
      "2025-02-01 06:53:28,053 INFO scheduler.DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:28,053 INFO cluster.YarnScheduler: Killing all running tasks in stage 77: Stage finished\n",
      "2025-02-01 06:53:28,053 INFO scheduler.DAGScheduler: Job 52 finished: treeReduce at KLLRunner.scala:107, took 0.097031 s\n",
      "2025-02-01 06:53:28,228 INFO scheduler.DAGScheduler: Registering RDD 314 (collect at AnalysisRunner.scala:326) as input to shuffle 25\n",
      "2025-02-01 06:53:28,229 INFO scheduler.DAGScheduler: Got map stage job 53 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:28,229 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 78 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:28,229 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:28,229 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:28,230 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[314] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:28,234 INFO memory.MemoryStore: Block broadcast_63 stored as values in memory (estimated size 90.7 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:28,236 INFO memory.MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:28,236 INFO storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on 10.0.119.186:40697 (size: 27.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:28,236 INFO spark.SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:28,237 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[314] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:28,237 INFO cluster.YarnScheduler: Adding task set 78.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:28,238 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 78.0 (TID 61) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:28,247 INFO storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on algo-1:34585 (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:28,263 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 78.0 (TID 61) in 25 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:28,263 INFO scheduler.DAGScheduler: ShuffleMapStage 78 (collect at AnalysisRunner.scala:326) finished in 0.031 s\n",
      "2025-02-01 06:53:28,264 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:28,264 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:28,265 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:28,265 INFO cluster.YarnScheduler: Removed TaskSet 78.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:28,265 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:28,311 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:28,312 INFO scheduler.DAGScheduler: Got job 54 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:28,312 INFO scheduler.DAGScheduler: Final stage: ResultStage 80 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:28,312 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)\n",
      "2025-02-01 06:53:28,312 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:28,312 INFO scheduler.DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[317] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:28,314 INFO memory.MemoryStore: Block broadcast_64 stored as values in memory (estimated size 66.2 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:28,316 INFO memory.MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:28,316 INFO storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:28,317 INFO spark.SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:28,317 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[317] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:28,317 INFO cluster.YarnScheduler: Adding task set 80.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:28,318 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 80.0 (TID 62) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:28,332 INFO storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:28,336 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:28,341 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 80.0 (TID 62) in 23 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:28,341 INFO cluster.YarnScheduler: Removed TaskSet 80.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:28,342 INFO scheduler.DAGScheduler: ResultStage 80 (collect at AnalysisRunner.scala:326) finished in 0.029 s\n",
      "2025-02-01 06:53:28,342 INFO scheduler.DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:28,342 INFO cluster.YarnScheduler: Killing all running tasks in stage 80: Stage finished\n",
      "2025-02-01 06:53:28,343 INFO scheduler.DAGScheduler: Job 54 finished: collect at AnalysisRunner.scala:326, took 0.031795 s\n",
      "2025-02-01 06:53:28,412 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:28,413 INFO scheduler.DAGScheduler: Registering RDD 325 (countByKey at ColumnProfiler.scala:592) as input to shuffle 26\n",
      "2025-02-01 06:53:28,413 INFO scheduler.DAGScheduler: Got job 55 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:28,413 INFO scheduler.DAGScheduler: Final stage: ResultStage 82 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:28,413 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)\n",
      "2025-02-01 06:53:28,413 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 81)\n",
      "2025-02-01 06:53:28,414 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[325] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:28,417 INFO memory.MemoryStore: Block broadcast_65 stored as values in memory (estimated size 47.1 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:28,418 INFO memory.MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:28,419 INFO storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:28,419 INFO spark.SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:28,420 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[325] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:28,420 INFO cluster.YarnScheduler: Adding task set 81.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:28,421 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 81.0 (TID 63) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:28,428 INFO storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:28,449 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 81.0 (TID 63) in 28 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:28,449 INFO cluster.YarnScheduler: Removed TaskSet 81.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:28,450 INFO scheduler.DAGScheduler: ShuffleMapStage 81 (countByKey at ColumnProfiler.scala:592) finished in 0.035 s\n",
      "2025-02-01 06:53:28,450 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:28,450 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:28,453 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 82)\n",
      "2025-02-01 06:53:28,453 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:28,453 INFO scheduler.DAGScheduler: Submitting ResultStage 82 (ShuffledRDD[326] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:28,454 INFO memory.MemoryStore: Block broadcast_66 stored as values in memory (estimated size 5.1 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:28,456 INFO memory.MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:28,456 INFO storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:28,461 INFO spark.SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:28,462 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (ShuffledRDD[326] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:28,462 INFO cluster.YarnScheduler: Adding task set 82.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:28,463 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 82.0 (TID 64) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:28,468 INFO storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:28,472 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:28,488 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 82.0 (TID 64) in 26 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:28,488 INFO scheduler.DAGScheduler: ResultStage 82 (countByKey at ColumnProfiler.scala:592) finished in 0.034 s\n",
      "2025-02-01 06:53:28,489 INFO scheduler.DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:28,489 INFO cluster.YarnScheduler: Removed TaskSet 82.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:28,489 INFO cluster.YarnScheduler: Killing all running tasks in stage 82: Stage finished\n",
      "2025-02-01 06:53:28,490 INFO scheduler.DAGScheduler: Job 55 finished: countByKey at ColumnProfiler.scala:592, took 0.077846 s\n",
      "2025-02-01 06:53:28,610 INFO scheduler.DAGScheduler: Registering RDD 331 (collect at AnalysisRunner.scala:326) as input to shuffle 27\n",
      "2025-02-01 06:53:28,610 INFO scheduler.DAGScheduler: Got map stage job 56 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:28,610 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 83 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:28,610 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:28,610 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:28,611 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 83 (MapPartitionsRDD[331] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:28,614 INFO memory.MemoryStore: Block broadcast_67 stored as values in memory (estimated size 100.0 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:28,615 INFO memory.MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:28,615 INFO storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on 10.0.119.186:40697 (size: 32.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:28,616 INFO spark.SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:28,616 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 83 (MapPartitionsRDD[331] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:28,616 INFO cluster.YarnScheduler: Adding task set 83.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:28,617 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 83.0 (TID 65) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:28,628 INFO storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on algo-1:34585 (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:28,739 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 83.0 (TID 65) in 122 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:28,740 INFO cluster.YarnScheduler: Removed TaskSet 83.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:28,740 INFO scheduler.DAGScheduler: ShuffleMapStage 83 (collect at AnalysisRunner.scala:326) finished in 0.129 s\n",
      "2025-02-01 06:53:28,741 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:28,741 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:28,741 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:28,741 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:28,786 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:28,787 INFO scheduler.DAGScheduler: Got job 57 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:28,787 INFO scheduler.DAGScheduler: Final stage: ResultStage 85 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:28,788 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)\n",
      "2025-02-01 06:53:28,788 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:28,788 INFO scheduler.DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[334] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:28,794 INFO memory.MemoryStore: Block broadcast_68 stored as values in memory (estimated size 184.6 KiB, free 1457.0 MiB)\n",
      "2025-02-01 06:53:28,796 INFO memory.MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1456.9 MiB)\n",
      "2025-02-01 06:53:28,797 INFO storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on 10.0.119.186:40697 (size: 50.3 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:28,797 INFO spark.SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:28,798 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[334] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:28,798 INFO cluster.YarnScheduler: Adding task set 85.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:28,799 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 85.0 (TID 66) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:28,812 INFO storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on algo-1:34585 (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:28,833 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:28,939 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 85.0 (TID 66) in 140 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:28,939 INFO cluster.YarnScheduler: Removed TaskSet 85.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:28,940 INFO scheduler.DAGScheduler: ResultStage 85 (collect at AnalysisRunner.scala:326) finished in 0.151 s\n",
      "2025-02-01 06:53:28,940 INFO scheduler.DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:28,941 INFO cluster.YarnScheduler: Killing all running tasks in stage 85: Stage finished\n",
      "2025-02-01 06:53:28,941 INFO scheduler.DAGScheduler: Job 57 finished: collect at AnalysisRunner.scala:326, took 0.154230 s\n",
      "2025-02-01 06:53:29,050 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:29,051 INFO scheduler.DAGScheduler: Got job 58 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:29,051 INFO scheduler.DAGScheduler: Final stage: ResultStage 86 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:29,051 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:29,052 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:29,052 INFO scheduler.DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[344] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:29,057 INFO memory.MemoryStore: Block broadcast_69 stored as values in memory (estimated size 54.8 KiB, free 1456.9 MiB)\n",
      "2025-02-01 06:53:29,059 INFO memory.MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.9 MiB)\n",
      "2025-02-01 06:53:29,062 INFO storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:29,062 INFO spark.SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:29,063 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[344] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:29,063 INFO cluster.YarnScheduler: Adding task set 86.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:29,064 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 86.0 (TID 67) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:29,074 INFO storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,103 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 86.0 (TID 67) in 39 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:29,104 INFO cluster.YarnScheduler: Removed TaskSet 86.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:29,104 INFO scheduler.DAGScheduler: ResultStage 86 (treeReduce at KLLRunner.scala:107) finished in 0.051 s\n",
      "2025-02-01 06:53:29,105 INFO scheduler.DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:29,105 INFO cluster.YarnScheduler: Killing all running tasks in stage 86: Stage finished\n",
      "2025-02-01 06:53:29,105 INFO scheduler.DAGScheduler: Job 58 finished: treeReduce at KLLRunner.scala:107, took 0.055108 s\n",
      "2025-02-01 06:53:29,241 INFO scheduler.DAGScheduler: Registering RDD 349 (collect at AnalysisRunner.scala:326) as input to shuffle 28\n",
      "2025-02-01 06:53:29,241 INFO scheduler.DAGScheduler: Got map stage job 59 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:29,241 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 87 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:29,242 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:29,242 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:29,243 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 87 (MapPartitionsRDD[349] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:29,274 INFO memory.MemoryStore: Block broadcast_70 stored as values in memory (estimated size 90.7 KiB, free 1456.8 MiB)\n",
      "2025-02-01 06:53:29,278 INFO storage.BlockManagerInfo: Removed broadcast_65_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:29,280 INFO storage.BlockManagerInfo: Removed broadcast_65_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,284 INFO storage.BlockManagerInfo: Removed broadcast_67_piece0 on 10.0.119.186:40697 in memory (size: 32.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:29,285 INFO storage.BlockManagerInfo: Removed broadcast_67_piece0 on algo-1:34585 in memory (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,290 INFO memory.MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.9 MiB)\n",
      "2025-02-01 06:53:29,293 INFO storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on 10.0.119.186:40697 (size: 27.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:29,295 INFO storage.BlockManagerInfo: Removed broadcast_62_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:29,295 INFO spark.SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:29,295 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 87 (MapPartitionsRDD[349] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:29,296 INFO cluster.YarnScheduler: Adding task set 87.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:29,296 INFO storage.BlockManagerInfo: Removed broadcast_62_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,300 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 87.0 (TID 68) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:29,305 INFO storage.BlockManagerInfo: Removed broadcast_61_piece0 on 10.0.119.186:40697 in memory (size: 50.3 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:29,308 INFO storage.BlockManagerInfo: Removed broadcast_61_piece0 on algo-1:34585 in memory (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,311 INFO storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on algo-1:34585 (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,321 INFO storage.BlockManagerInfo: Removed broadcast_63_piece0 on 10.0.119.186:40697 in memory (size: 27.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:29,323 INFO storage.BlockManagerInfo: Removed broadcast_63_piece0 on algo-1:34585 in memory (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,326 INFO storage.BlockManagerInfo: Removed broadcast_60_piece0 on 10.0.119.186:40697 in memory (size: 32.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:29,327 INFO storage.BlockManagerInfo: Removed broadcast_60_piece0 on algo-1:34585 in memory (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,332 INFO storage.BlockManagerInfo: Removed broadcast_66_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:29,332 INFO storage.BlockManagerInfo: Removed broadcast_66_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,339 INFO storage.BlockManagerInfo: Removed broadcast_59_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:29,341 INFO storage.BlockManagerInfo: Removed broadcast_59_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,347 INFO storage.BlockManagerInfo: Removed broadcast_64_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:29,351 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 87.0 (TID 68) in 51 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:29,351 INFO cluster.YarnScheduler: Removed TaskSet 87.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:29,352 INFO scheduler.DAGScheduler: ShuffleMapStage 87 (collect at AnalysisRunner.scala:326) finished in 0.109 s\n",
      "2025-02-01 06:53:29,353 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:29,353 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:29,354 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:29,354 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:29,358 INFO storage.BlockManagerInfo: Removed broadcast_64_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,361 INFO storage.BlockManagerInfo: Removed broadcast_69_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:29,365 INFO storage.BlockManagerInfo: Removed broadcast_69_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,368 INFO storage.BlockManagerInfo: Removed broadcast_68_piece0 on 10.0.119.186:40697 in memory (size: 50.3 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:29,368 INFO storage.BlockManagerInfo: Removed broadcast_68_piece0 on algo-1:34585 in memory (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,370 INFO storage.BlockManagerInfo: Removed broadcast_57_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:29,372 INFO storage.BlockManagerInfo: Removed broadcast_57_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,374 INFO storage.BlockManagerInfo: Removed broadcast_58_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:29,376 INFO storage.BlockManagerInfo: Removed broadcast_58_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,410 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:29,411 INFO scheduler.DAGScheduler: Got job 60 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:29,411 INFO scheduler.DAGScheduler: Final stage: ResultStage 89 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:29,411 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)\n",
      "2025-02-01 06:53:29,411 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:29,412 INFO scheduler.DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[352] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:29,414 INFO memory.MemoryStore: Block broadcast_71 stored as values in memory (estimated size 66.2 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:29,416 INFO memory.MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:29,417 INFO storage.BlockManagerInfo: Added broadcast_71_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:29,418 INFO spark.SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:29,418 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[352] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:29,418 INFO cluster.YarnScheduler: Adding task set 89.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:29,419 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 89.0 (TID 69) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:29,431 INFO storage.BlockManagerInfo: Added broadcast_71_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,435 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:29,444 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 89.0 (TID 69) in 25 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:29,447 INFO cluster.YarnScheduler: Removed TaskSet 89.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:29,448 INFO scheduler.DAGScheduler: ResultStage 89 (collect at AnalysisRunner.scala:326) finished in 0.034 s\n",
      "2025-02-01 06:53:29,448 INFO scheduler.DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:29,449 INFO cluster.YarnScheduler: Killing all running tasks in stage 89: Stage finished\n",
      "2025-02-01 06:53:29,449 INFO scheduler.DAGScheduler: Job 60 finished: collect at AnalysisRunner.scala:326, took 0.039225 s\n",
      "2025-02-01 06:53:29,499 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:29,500 INFO scheduler.DAGScheduler: Registering RDD 360 (countByKey at ColumnProfiler.scala:592) as input to shuffle 29\n",
      "2025-02-01 06:53:29,500 INFO scheduler.DAGScheduler: Got job 61 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:29,501 INFO scheduler.DAGScheduler: Final stage: ResultStage 91 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:29,501 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)\n",
      "2025-02-01 06:53:29,501 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 90)\n",
      "2025-02-01 06:53:29,502 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[360] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:29,511 INFO memory.MemoryStore: Block broadcast_72 stored as values in memory (estimated size 47.1 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:29,512 INFO memory.MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:29,514 INFO storage.BlockManagerInfo: Added broadcast_72_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:29,515 INFO spark.SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:29,516 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[360] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:29,516 INFO cluster.YarnScheduler: Adding task set 90.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:29,517 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 90.0 (TID 70) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:29,524 INFO storage.BlockManagerInfo: Added broadcast_72_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,569 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 90.0 (TID 70) in 52 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:29,569 INFO cluster.YarnScheduler: Removed TaskSet 90.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:29,570 INFO scheduler.DAGScheduler: ShuffleMapStage 90 (countByKey at ColumnProfiler.scala:592) finished in 0.067 s\n",
      "2025-02-01 06:53:29,571 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:29,571 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:29,572 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 91)\n",
      "2025-02-01 06:53:29,572 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:29,572 INFO scheduler.DAGScheduler: Submitting ResultStage 91 (ShuffledRDD[361] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:29,575 INFO memory.MemoryStore: Block broadcast_73 stored as values in memory (estimated size 5.1 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:29,576 INFO memory.MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:29,577 INFO storage.BlockManagerInfo: Added broadcast_73_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:29,577 INFO spark.SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:29,578 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (ShuffledRDD[361] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:29,578 INFO cluster.YarnScheduler: Adding task set 91.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:29,579 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 91.0 (TID 71) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:29,585 INFO storage.BlockManagerInfo: Added broadcast_73_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,588 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:29,597 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 91.0 (TID 71) in 18 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:29,598 INFO cluster.YarnScheduler: Removed TaskSet 91.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:29,598 INFO scheduler.DAGScheduler: ResultStage 91 (countByKey at ColumnProfiler.scala:592) finished in 0.024 s\n",
      "2025-02-01 06:53:29,599 INFO scheduler.DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:29,600 INFO cluster.YarnScheduler: Killing all running tasks in stage 91: Stage finished\n",
      "2025-02-01 06:53:29,600 INFO scheduler.DAGScheduler: Job 61 finished: countByKey at ColumnProfiler.scala:592, took 0.100676 s\n",
      "2025-02-01 06:53:29,741 INFO scheduler.DAGScheduler: Registering RDD 366 (collect at AnalysisRunner.scala:326) as input to shuffle 30\n",
      "2025-02-01 06:53:29,742 INFO scheduler.DAGScheduler: Got map stage job 62 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:29,742 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 92 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:29,742 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:29,743 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:29,744 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 92 (MapPartitionsRDD[366] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:29,750 INFO memory.MemoryStore: Block broadcast_74 stored as values in memory (estimated size 100.0 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:29,751 INFO memory.MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:29,752 INFO storage.BlockManagerInfo: Added broadcast_74_piece0 in memory on 10.0.119.186:40697 (size: 32.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:29,752 INFO spark.SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:29,753 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 92 (MapPartitionsRDD[366] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:29,753 INFO cluster.YarnScheduler: Adding task set 92.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:29,755 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 92.0 (TID 72) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:29,761 INFO storage.BlockManagerInfo: Added broadcast_74_piece0 in memory on algo-1:34585 (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:29,916 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 92.0 (TID 72) in 162 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:29,916 INFO cluster.YarnScheduler: Removed TaskSet 92.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:29,917 INFO scheduler.DAGScheduler: ShuffleMapStage 92 (collect at AnalysisRunner.scala:326) finished in 0.171 s\n",
      "2025-02-01 06:53:29,917 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:29,918 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:29,918 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:29,918 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:29,981 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:29,982 INFO scheduler.DAGScheduler: Got job 63 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:29,982 INFO scheduler.DAGScheduler: Final stage: ResultStage 94 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:29,982 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 93)\n",
      "2025-02-01 06:53:29,982 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:29,983 INFO scheduler.DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[369] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:29,991 INFO memory.MemoryStore: Block broadcast_75 stored as values in memory (estimated size 184.6 KiB, free 1457.6 MiB)\n",
      "2025-02-01 06:53:29,993 INFO memory.MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:29,993 INFO storage.BlockManagerInfo: Added broadcast_75_piece0 in memory on 10.0.119.186:40697 (size: 50.3 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:29,994 INFO spark.SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:29,994 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[369] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:29,995 INFO cluster.YarnScheduler: Adding task set 94.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:29,996 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 94.0 (TID 73) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:30,003 INFO storage.BlockManagerInfo: Added broadcast_75_piece0 in memory on algo-1:34585 (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:30,021 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:30,183 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 94.0 (TID 73) in 188 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:30,184 INFO cluster.YarnScheduler: Removed TaskSet 94.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:30,184 INFO scheduler.DAGScheduler: ResultStage 94 (collect at AnalysisRunner.scala:326) finished in 0.199 s\n",
      "2025-02-01 06:53:30,186 INFO scheduler.DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:30,186 INFO cluster.YarnScheduler: Killing all running tasks in stage 94: Stage finished\n",
      "2025-02-01 06:53:30,188 INFO scheduler.DAGScheduler: Job 63 finished: collect at AnalysisRunner.scala:326, took 0.207121 s\n",
      "2025-02-01 06:53:30,317 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:30,317 INFO scheduler.DAGScheduler: Got job 64 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:30,318 INFO scheduler.DAGScheduler: Final stage: ResultStage 95 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:30,318 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:30,318 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:30,319 INFO scheduler.DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[379] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:30,327 INFO memory.MemoryStore: Block broadcast_76 stored as values in memory (estimated size 54.8 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:30,330 INFO memory.MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:30,330 INFO storage.BlockManagerInfo: Added broadcast_76_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:30,330 INFO spark.SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:30,331 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[379] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:30,331 INFO cluster.YarnScheduler: Adding task set 95.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:30,332 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 95.0 (TID 74) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:30,339 INFO storage.BlockManagerInfo: Added broadcast_76_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:30,388 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 95.0 (TID 74) in 56 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:30,388 INFO cluster.YarnScheduler: Removed TaskSet 95.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:30,389 INFO scheduler.DAGScheduler: ResultStage 95 (treeReduce at KLLRunner.scala:107) finished in 0.070 s\n",
      "2025-02-01 06:53:30,390 INFO scheduler.DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:30,390 INFO cluster.YarnScheduler: Killing all running tasks in stage 95: Stage finished\n",
      "2025-02-01 06:53:30,390 INFO scheduler.DAGScheduler: Job 64 finished: treeReduce at KLLRunner.scala:107, took 0.073377 s\n",
      "2025-02-01 06:53:30,486 INFO scheduler.DAGScheduler: Registering RDD 384 (collect at AnalysisRunner.scala:326) as input to shuffle 31\n",
      "2025-02-01 06:53:30,487 INFO scheduler.DAGScheduler: Got map stage job 65 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:30,487 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 96 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:30,487 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:30,488 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:30,488 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 96 (MapPartitionsRDD[384] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:30,490 INFO memory.MemoryStore: Block broadcast_77 stored as values in memory (estimated size 90.7 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:30,492 INFO memory.MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:30,492 INFO storage.BlockManagerInfo: Added broadcast_77_piece0 in memory on 10.0.119.186:40697 (size: 28.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:30,493 INFO spark.SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:30,493 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[384] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:30,494 INFO cluster.YarnScheduler: Adding task set 96.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:30,495 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 96.0 (TID 75) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:30,502 INFO storage.BlockManagerInfo: Added broadcast_77_piece0 in memory on algo-1:34585 (size: 28.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:30,516 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 96.0 (TID 75) in 22 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:30,516 INFO cluster.YarnScheduler: Removed TaskSet 96.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:30,516 INFO scheduler.DAGScheduler: ShuffleMapStage 96 (collect at AnalysisRunner.scala:326) finished in 0.027 s\n",
      "2025-02-01 06:53:30,517 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:30,517 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:30,517 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:30,517 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:30,556 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:30,557 INFO scheduler.DAGScheduler: Got job 66 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:30,557 INFO scheduler.DAGScheduler: Final stage: ResultStage 98 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:30,557 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)\n",
      "2025-02-01 06:53:30,558 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:30,558 INFO scheduler.DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[387] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:30,560 INFO memory.MemoryStore: Block broadcast_78 stored as values in memory (estimated size 66.2 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:30,561 INFO memory.MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:30,562 INFO storage.BlockManagerInfo: Added broadcast_78_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:30,562 INFO spark.SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:30,563 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[387] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:30,563 INFO cluster.YarnScheduler: Adding task set 98.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:30,564 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 98.0 (TID 76) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:30,574 INFO storage.BlockManagerInfo: Added broadcast_78_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:30,579 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:30,584 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 98.0 (TID 76) in 20 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:30,584 INFO cluster.YarnScheduler: Removed TaskSet 98.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:30,585 INFO scheduler.DAGScheduler: ResultStage 98 (collect at AnalysisRunner.scala:326) finished in 0.026 s\n",
      "2025-02-01 06:53:30,585 INFO scheduler.DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:30,585 INFO cluster.YarnScheduler: Killing all running tasks in stage 98: Stage finished\n",
      "2025-02-01 06:53:30,586 INFO scheduler.DAGScheduler: Job 66 finished: collect at AnalysisRunner.scala:326, took 0.029245 s\n",
      "2025-02-01 06:53:30,640 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:30,641 INFO scheduler.DAGScheduler: Registering RDD 395 (countByKey at ColumnProfiler.scala:592) as input to shuffle 32\n",
      "2025-02-01 06:53:30,642 INFO scheduler.DAGScheduler: Got job 67 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:30,642 INFO scheduler.DAGScheduler: Final stage: ResultStage 100 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:30,642 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 99)\n",
      "2025-02-01 06:53:30,643 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 99)\n",
      "2025-02-01 06:53:30,643 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 99 (MapPartitionsRDD[395] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:30,647 INFO memory.MemoryStore: Block broadcast_79 stored as values in memory (estimated size 47.1 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:30,648 INFO memory.MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:30,649 INFO storage.BlockManagerInfo: Added broadcast_79_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:30,649 INFO spark.SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:30,650 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 99 (MapPartitionsRDD[395] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:30,650 INFO cluster.YarnScheduler: Adding task set 99.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:30,651 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 99.0 (TID 77) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:30,658 INFO storage.BlockManagerInfo: Added broadcast_79_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:30,680 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 99.0 (TID 77) in 29 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:30,680 INFO cluster.YarnScheduler: Removed TaskSet 99.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:30,681 INFO scheduler.DAGScheduler: ShuffleMapStage 99 (countByKey at ColumnProfiler.scala:592) finished in 0.037 s\n",
      "2025-02-01 06:53:30,681 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:30,682 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:30,682 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 100)\n",
      "2025-02-01 06:53:30,682 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:30,682 INFO scheduler.DAGScheduler: Submitting ResultStage 100 (ShuffledRDD[396] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:30,684 INFO memory.MemoryStore: Block broadcast_80 stored as values in memory (estimated size 5.1 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:30,685 INFO memory.MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:30,686 INFO storage.BlockManagerInfo: Added broadcast_80_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:30,687 INFO spark.SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:30,687 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (ShuffledRDD[396] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:30,687 INFO cluster.YarnScheduler: Adding task set 100.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:30,688 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 100.0 (TID 78) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:30,694 INFO storage.BlockManagerInfo: Added broadcast_80_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:30,697 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:30,708 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 100.0 (TID 78) in 20 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:30,708 INFO cluster.YarnScheduler: Removed TaskSet 100.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:30,709 INFO scheduler.DAGScheduler: ResultStage 100 (countByKey at ColumnProfiler.scala:592) finished in 0.025 s\n",
      "2025-02-01 06:53:30,709 INFO scheduler.DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:30,710 INFO cluster.YarnScheduler: Killing all running tasks in stage 100: Stage finished\n",
      "2025-02-01 06:53:30,710 INFO scheduler.DAGScheduler: Job 67 finished: countByKey at ColumnProfiler.scala:592, took 0.069161 s\n",
      "2025-02-01 06:53:30,783 INFO scheduler.DAGScheduler: Registering RDD 401 (collect at AnalysisRunner.scala:326) as input to shuffle 33\n",
      "2025-02-01 06:53:30,787 INFO scheduler.DAGScheduler: Got map stage job 68 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:30,787 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 101 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:30,787 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:30,787 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:30,788 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[401] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:30,792 INFO memory.MemoryStore: Block broadcast_81 stored as values in memory (estimated size 100.0 KiB, free 1457.1 MiB)\n",
      "2025-02-01 06:53:30,794 INFO memory.MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 33.0 KiB, free 1457.0 MiB)\n",
      "2025-02-01 06:53:30,794 INFO storage.BlockManagerInfo: Added broadcast_81_piece0 in memory on 10.0.119.186:40697 (size: 33.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:30,795 INFO spark.SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:30,795 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[401] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:30,795 INFO cluster.YarnScheduler: Adding task set 101.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:30,796 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 101.0 (TID 79) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:30,803 INFO storage.BlockManagerInfo: Added broadcast_81_piece0 in memory on algo-1:34585 (size: 33.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:30,906 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 101.0 (TID 79) in 110 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:30,906 INFO cluster.YarnScheduler: Removed TaskSet 101.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:30,907 INFO scheduler.DAGScheduler: ShuffleMapStage 101 (collect at AnalysisRunner.scala:326) finished in 0.117 s\n",
      "2025-02-01 06:53:30,908 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:30,908 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:30,908 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:30,908 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:30,991 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:30,992 INFO scheduler.DAGScheduler: Got job 69 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:30,992 INFO scheduler.DAGScheduler: Final stage: ResultStage 103 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:30,992 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)\n",
      "2025-02-01 06:53:30,993 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:30,993 INFO scheduler.DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[404] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:31,003 INFO memory.MemoryStore: Block broadcast_82 stored as values in memory (estimated size 184.6 KiB, free 1456.9 MiB)\n",
      "2025-02-01 06:53:31,005 INFO memory.MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1456.8 MiB)\n",
      "2025-02-01 06:53:31,006 INFO storage.BlockManagerInfo: Added broadcast_82_piece0 in memory on 10.0.119.186:40697 (size: 50.3 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:31,006 INFO spark.SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:31,007 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[404] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:31,007 INFO cluster.YarnScheduler: Adding task set 103.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:31,008 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 103.0 (TID 80) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:31,016 INFO storage.BlockManagerInfo: Added broadcast_82_piece0 in memory on algo-1:34585 (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,026 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:31,129 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 103.0 (TID 80) in 121 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:31,132 INFO cluster.YarnScheduler: Removed TaskSet 103.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:31,133 INFO scheduler.DAGScheduler: ResultStage 103 (collect at AnalysisRunner.scala:326) finished in 0.137 s\n",
      "2025-02-01 06:53:31,134 INFO scheduler.DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:31,135 INFO cluster.YarnScheduler: Killing all running tasks in stage 103: Stage finished\n",
      "2025-02-01 06:53:31,135 INFO scheduler.DAGScheduler: Job 69 finished: collect at AnalysisRunner.scala:326, took 0.143638 s\n",
      "2025-02-01 06:53:31,253 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:31,253 INFO scheduler.DAGScheduler: Got job 70 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:31,253 INFO scheduler.DAGScheduler: Final stage: ResultStage 104 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:31,253 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:31,254 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:31,254 INFO scheduler.DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[414] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:31,258 INFO memory.MemoryStore: Block broadcast_83 stored as values in memory (estimated size 54.8 KiB, free 1456.8 MiB)\n",
      "2025-02-01 06:53:31,259 INFO memory.MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.7 MiB)\n",
      "2025-02-01 06:53:31,260 INFO storage.BlockManagerInfo: Added broadcast_83_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:31,260 INFO spark.SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:31,260 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[414] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:31,261 INFO cluster.YarnScheduler: Adding task set 104.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:31,261 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 104.0 (TID 81) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:31,269 INFO storage.BlockManagerInfo: Added broadcast_83_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,292 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 104.0 (TID 81) in 31 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:31,292 INFO cluster.YarnScheduler: Removed TaskSet 104.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:31,293 INFO scheduler.DAGScheduler: ResultStage 104 (treeReduce at KLLRunner.scala:107) finished in 0.038 s\n",
      "2025-02-01 06:53:31,293 INFO scheduler.DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:31,293 INFO cluster.YarnScheduler: Killing all running tasks in stage 104: Stage finished\n",
      "2025-02-01 06:53:31,294 INFO scheduler.DAGScheduler: Job 70 finished: treeReduce at KLLRunner.scala:107, took 0.040813 s\n",
      "2025-02-01 06:53:31,420 INFO storage.BlockManagerInfo: Removed broadcast_77_piece0 on algo-1:34585 in memory (size: 28.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,421 INFO storage.BlockManagerInfo: Removed broadcast_77_piece0 on 10.0.119.186:40697 in memory (size: 28.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:31,425 INFO scheduler.DAGScheduler: Registering RDD 419 (collect at AnalysisRunner.scala:326) as input to shuffle 34\n",
      "2025-02-01 06:53:31,426 INFO scheduler.DAGScheduler: Got map stage job 71 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:31,426 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 105 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:31,426 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:31,427 INFO storage.BlockManagerInfo: Removed broadcast_83_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:31,427 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:31,428 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 105 (MapPartitionsRDD[419] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:31,430 INFO memory.MemoryStore: Block broadcast_84 stored as values in memory (estimated size 90.7 KiB, free 1456.8 MiB)\n",
      "2025-02-01 06:53:31,432 INFO storage.BlockManagerInfo: Removed broadcast_83_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,436 INFO storage.BlockManagerInfo: Removed broadcast_72_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:31,437 INFO storage.BlockManagerInfo: Removed broadcast_72_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,439 INFO storage.BlockManagerInfo: Removed broadcast_80_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:31,440 INFO storage.BlockManagerInfo: Removed broadcast_80_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,444 INFO storage.BlockManagerInfo: Removed broadcast_78_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:31,445 INFO storage.BlockManagerInfo: Removed broadcast_78_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,446 INFO memory.MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.0 MiB)\n",
      "2025-02-01 06:53:31,447 INFO storage.BlockManagerInfo: Removed broadcast_82_piece0 on 10.0.119.186:40697 in memory (size: 50.3 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:31,448 INFO storage.BlockManagerInfo: Added broadcast_84_piece0 in memory on 10.0.119.186:40697 (size: 27.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:31,448 INFO storage.BlockManagerInfo: Removed broadcast_82_piece0 on algo-1:34585 in memory (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,449 INFO spark.SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:31,451 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 105 (MapPartitionsRDD[419] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:31,451 INFO storage.BlockManagerInfo: Removed broadcast_81_piece0 on 10.0.119.186:40697 in memory (size: 33.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:31,451 INFO storage.BlockManagerInfo: Removed broadcast_81_piece0 on algo-1:34585 in memory (size: 33.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,454 INFO cluster.YarnScheduler: Adding task set 105.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:31,456 INFO storage.BlockManagerInfo: Removed broadcast_73_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:31,456 INFO storage.BlockManagerInfo: Removed broadcast_73_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,457 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 105.0 (TID 82) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:31,468 INFO storage.BlockManagerInfo: Removed broadcast_79_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:31,468 INFO storage.BlockManagerInfo: Removed broadcast_79_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,471 INFO storage.BlockManagerInfo: Removed broadcast_74_piece0 on 10.0.119.186:40697 in memory (size: 32.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:31,473 INFO storage.BlockManagerInfo: Removed broadcast_74_piece0 on algo-1:34585 in memory (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,473 INFO storage.BlockManagerInfo: Added broadcast_84_piece0 in memory on algo-1:34585 (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,475 INFO storage.BlockManagerInfo: Removed broadcast_75_piece0 on 10.0.119.186:40697 in memory (size: 50.3 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:31,476 INFO storage.BlockManagerInfo: Removed broadcast_75_piece0 on algo-1:34585 in memory (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,479 INFO storage.BlockManagerInfo: Removed broadcast_70_piece0 on 10.0.119.186:40697 in memory (size: 27.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:31,480 INFO storage.BlockManagerInfo: Removed broadcast_70_piece0 on algo-1:34585 in memory (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,481 INFO storage.BlockManagerInfo: Removed broadcast_71_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:31,482 INFO storage.BlockManagerInfo: Removed broadcast_71_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,484 INFO storage.BlockManagerInfo: Removed broadcast_76_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:31,485 INFO storage.BlockManagerInfo: Removed broadcast_76_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,502 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 105.0 (TID 82) in 45 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:31,502 INFO cluster.YarnScheduler: Removed TaskSet 105.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:31,503 INFO scheduler.DAGScheduler: ShuffleMapStage 105 (collect at AnalysisRunner.scala:326) finished in 0.074 s\n",
      "2025-02-01 06:53:31,504 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:31,504 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:31,504 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:31,504 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:31,542 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:31,543 INFO scheduler.DAGScheduler: Got job 72 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:31,543 INFO scheduler.DAGScheduler: Final stage: ResultStage 107 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:31,543 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 106)\n",
      "2025-02-01 06:53:31,543 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:31,543 INFO scheduler.DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[422] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:31,545 INFO memory.MemoryStore: Block broadcast_85 stored as values in memory (estimated size 66.2 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:31,546 INFO memory.MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:31,547 INFO storage.BlockManagerInfo: Added broadcast_85_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:31,547 INFO spark.SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:31,547 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[422] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:31,547 INFO cluster.YarnScheduler: Adding task set 107.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:31,548 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 107.0 (TID 83) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:31,556 INFO storage.BlockManagerInfo: Added broadcast_85_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,563 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:31,571 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 107.0 (TID 83) in 23 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:31,571 INFO cluster.YarnScheduler: Removed TaskSet 107.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:31,571 INFO scheduler.DAGScheduler: ResultStage 107 (collect at AnalysisRunner.scala:326) finished in 0.027 s\n",
      "2025-02-01 06:53:31,572 INFO scheduler.DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:31,572 INFO cluster.YarnScheduler: Killing all running tasks in stage 107: Stage finished\n",
      "2025-02-01 06:53:31,573 INFO scheduler.DAGScheduler: Job 72 finished: collect at AnalysisRunner.scala:326, took 0.030308 s\n",
      "2025-02-01 06:53:31,621 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:31,621 INFO scheduler.DAGScheduler: Registering RDD 430 (countByKey at ColumnProfiler.scala:592) as input to shuffle 35\n",
      "2025-02-01 06:53:31,622 INFO scheduler.DAGScheduler: Got job 73 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:31,622 INFO scheduler.DAGScheduler: Final stage: ResultStage 109 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:31,622 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 108)\n",
      "2025-02-01 06:53:31,623 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 108)\n",
      "2025-02-01 06:53:31,624 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 108 (MapPartitionsRDD[430] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:31,627 INFO memory.MemoryStore: Block broadcast_86 stored as values in memory (estimated size 47.1 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:31,628 INFO memory.MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:31,628 INFO storage.BlockManagerInfo: Added broadcast_86_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:31,629 INFO spark.SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:31,629 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 108 (MapPartitionsRDD[430] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:31,629 INFO cluster.YarnScheduler: Adding task set 108.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:31,630 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 108.0 (TID 84) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:31,642 INFO storage.BlockManagerInfo: Added broadcast_86_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,675 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 108.0 (TID 84) in 45 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:31,675 INFO cluster.YarnScheduler: Removed TaskSet 108.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:31,676 INFO scheduler.DAGScheduler: ShuffleMapStage 108 (countByKey at ColumnProfiler.scala:592) finished in 0.052 s\n",
      "2025-02-01 06:53:31,679 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:31,682 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:31,682 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 109)\n",
      "2025-02-01 06:53:31,682 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:31,683 INFO scheduler.DAGScheduler: Submitting ResultStage 109 (ShuffledRDD[431] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:31,685 INFO memory.MemoryStore: Block broadcast_87 stored as values in memory (estimated size 5.1 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:31,693 INFO memory.MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:31,699 INFO storage.BlockManagerInfo: Added broadcast_87_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:31,700 INFO spark.SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:31,700 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (ShuffledRDD[431] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:31,700 INFO cluster.YarnScheduler: Adding task set 109.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:31,701 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 109.0 (TID 85) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:31,710 INFO storage.BlockManagerInfo: Added broadcast_87_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,712 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:31,727 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 109.0 (TID 85) in 26 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:31,728 INFO cluster.YarnScheduler: Removed TaskSet 109.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:31,729 INFO scheduler.DAGScheduler: ResultStage 109 (countByKey at ColumnProfiler.scala:592) finished in 0.045 s\n",
      "2025-02-01 06:53:31,731 INFO scheduler.DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:31,731 INFO cluster.YarnScheduler: Killing all running tasks in stage 109: Stage finished\n",
      "2025-02-01 06:53:31,731 INFO scheduler.DAGScheduler: Job 73 finished: countByKey at ColumnProfiler.scala:592, took 0.110213 s\n",
      "2025-02-01 06:53:31,866 INFO scheduler.DAGScheduler: Registering RDD 436 (collect at AnalysisRunner.scala:326) as input to shuffle 36\n",
      "2025-02-01 06:53:31,866 INFO scheduler.DAGScheduler: Got map stage job 74 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:31,867 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 110 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:31,867 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:31,867 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:31,868 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 110 (MapPartitionsRDD[436] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:31,872 INFO memory.MemoryStore: Block broadcast_88 stored as values in memory (estimated size 100.0 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:31,874 INFO memory.MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:31,874 INFO storage.BlockManagerInfo: Added broadcast_88_piece0 in memory on 10.0.119.186:40697 (size: 32.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:31,875 INFO spark.SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:31,875 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 110 (MapPartitionsRDD[436] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:31,875 INFO cluster.YarnScheduler: Adding task set 110.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:31,877 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 110.0 (TID 86) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:31,887 INFO storage.BlockManagerInfo: Added broadcast_88_piece0 in memory on algo-1:34585 (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:31,990 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 110.0 (TID 86) in 113 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:31,991 INFO cluster.YarnScheduler: Removed TaskSet 110.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:31,992 INFO scheduler.DAGScheduler: ShuffleMapStage 110 (collect at AnalysisRunner.scala:326) finished in 0.123 s\n",
      "2025-02-01 06:53:31,992 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:31,993 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:31,993 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:31,993 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:32,027 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:32,028 INFO scheduler.DAGScheduler: Got job 75 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:32,028 INFO scheduler.DAGScheduler: Final stage: ResultStage 112 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:32,028 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 111)\n",
      "2025-02-01 06:53:32,029 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:32,029 INFO scheduler.DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[439] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:32,039 INFO memory.MemoryStore: Block broadcast_89 stored as values in memory (estimated size 184.6 KiB, free 1457.6 MiB)\n",
      "2025-02-01 06:53:32,041 INFO memory.MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:32,042 INFO storage.BlockManagerInfo: Added broadcast_89_piece0 in memory on 10.0.119.186:40697 (size: 50.3 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:32,042 INFO spark.SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:32,043 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[439] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:32,043 INFO cluster.YarnScheduler: Adding task set 112.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:32,044 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 112.0 (TID 87) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:32,053 INFO storage.BlockManagerInfo: Added broadcast_89_piece0 in memory on algo-1:34585 (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:32,062 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:32,182 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 112.0 (TID 87) in 138 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:32,182 INFO cluster.YarnScheduler: Removed TaskSet 112.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:32,183 INFO scheduler.DAGScheduler: ResultStage 112 (collect at AnalysisRunner.scala:326) finished in 0.152 s\n",
      "2025-02-01 06:53:32,184 INFO scheduler.DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:32,184 INFO cluster.YarnScheduler: Killing all running tasks in stage 112: Stage finished\n",
      "2025-02-01 06:53:32,185 INFO scheduler.DAGScheduler: Job 75 finished: collect at AnalysisRunner.scala:326, took 0.157522 s\n",
      "2025-02-01 06:53:32,291 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:32,292 INFO scheduler.DAGScheduler: Got job 76 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:32,292 INFO scheduler.DAGScheduler: Final stage: ResultStage 113 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:32,292 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:32,293 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:32,293 INFO scheduler.DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[449] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:32,297 INFO memory.MemoryStore: Block broadcast_90 stored as values in memory (estimated size 54.8 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:32,298 INFO memory.MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:32,298 INFO storage.BlockManagerInfo: Added broadcast_90_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:32,299 INFO spark.SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:32,299 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[449] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:32,299 INFO cluster.YarnScheduler: Adding task set 113.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:32,300 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 113.0 (TID 88) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:32,309 INFO storage.BlockManagerInfo: Added broadcast_90_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:32,336 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 113.0 (TID 88) in 36 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:32,337 INFO cluster.YarnScheduler: Removed TaskSet 113.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:32,337 INFO scheduler.DAGScheduler: ResultStage 113 (treeReduce at KLLRunner.scala:107) finished in 0.043 s\n",
      "2025-02-01 06:53:32,338 INFO scheduler.DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:32,338 INFO cluster.YarnScheduler: Killing all running tasks in stage 113: Stage finished\n",
      "2025-02-01 06:53:32,338 INFO scheduler.DAGScheduler: Job 76 finished: treeReduce at KLLRunner.scala:107, took 0.046380 s\n",
      "2025-02-01 06:53:32,431 INFO scheduler.DAGScheduler: Registering RDD 454 (collect at AnalysisRunner.scala:326) as input to shuffle 37\n",
      "2025-02-01 06:53:32,431 INFO scheduler.DAGScheduler: Got map stage job 77 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:32,432 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 114 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:32,432 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:32,432 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:32,433 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 114 (MapPartitionsRDD[454] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:32,435 INFO memory.MemoryStore: Block broadcast_91 stored as values in memory (estimated size 90.7 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:32,437 INFO memory.MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:32,437 INFO storage.BlockManagerInfo: Added broadcast_91_piece0 in memory on 10.0.119.186:40697 (size: 27.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:32,438 INFO spark.SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:32,438 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[454] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:32,438 INFO cluster.YarnScheduler: Adding task set 114.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:32,439 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 114.0 (TID 89) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:32,444 INFO storage.BlockManagerInfo: Added broadcast_91_piece0 in memory on algo-1:34585 (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:32,455 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 114.0 (TID 89) in 16 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:32,456 INFO scheduler.DAGScheduler: ShuffleMapStage 114 (collect at AnalysisRunner.scala:326) finished in 0.023 s\n",
      "2025-02-01 06:53:32,456 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:32,456 INFO cluster.YarnScheduler: Removed TaskSet 114.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:32,457 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:32,457 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:32,457 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:32,496 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:32,497 INFO scheduler.DAGScheduler: Got job 78 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:32,497 INFO scheduler.DAGScheduler: Final stage: ResultStage 116 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:32,497 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 115)\n",
      "2025-02-01 06:53:32,498 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:32,498 INFO scheduler.DAGScheduler: Submitting ResultStage 116 (MapPartitionsRDD[457] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:32,500 INFO memory.MemoryStore: Block broadcast_92 stored as values in memory (estimated size 66.2 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:32,502 INFO memory.MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:32,502 INFO storage.BlockManagerInfo: Added broadcast_92_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:32,502 INFO spark.SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:32,503 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[457] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:32,503 INFO cluster.YarnScheduler: Adding task set 116.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:32,504 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 116.0 (TID 90) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:32,511 INFO storage.BlockManagerInfo: Added broadcast_92_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:32,515 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:32,523 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 116.0 (TID 90) in 19 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:32,523 INFO cluster.YarnScheduler: Removed TaskSet 116.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:32,526 INFO scheduler.DAGScheduler: ResultStage 116 (collect at AnalysisRunner.scala:326) finished in 0.026 s\n",
      "2025-02-01 06:53:32,526 INFO scheduler.DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:32,526 INFO cluster.YarnScheduler: Killing all running tasks in stage 116: Stage finished\n",
      "2025-02-01 06:53:32,527 INFO scheduler.DAGScheduler: Job 78 finished: collect at AnalysisRunner.scala:326, took 0.030379 s\n",
      "2025-02-01 06:53:32,584 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:32,585 INFO scheduler.DAGScheduler: Registering RDD 465 (countByKey at ColumnProfiler.scala:592) as input to shuffle 38\n",
      "2025-02-01 06:53:32,586 INFO scheduler.DAGScheduler: Got job 79 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:32,586 INFO scheduler.DAGScheduler: Final stage: ResultStage 118 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:32,586 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 117)\n",
      "2025-02-01 06:53:32,586 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 117)\n",
      "2025-02-01 06:53:32,587 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 117 (MapPartitionsRDD[465] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:32,591 INFO memory.MemoryStore: Block broadcast_93 stored as values in memory (estimated size 47.1 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:32,592 INFO memory.MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:32,593 INFO storage.BlockManagerInfo: Added broadcast_93_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:32,595 INFO spark.SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:32,595 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 117 (MapPartitionsRDD[465] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:32,595 INFO cluster.YarnScheduler: Adding task set 117.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:32,599 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 117.0 (TID 91) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:32,607 INFO storage.BlockManagerInfo: Added broadcast_93_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:32,632 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 117.0 (TID 91) in 33 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:32,632 INFO cluster.YarnScheduler: Removed TaskSet 117.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:32,633 INFO scheduler.DAGScheduler: ShuffleMapStage 117 (countByKey at ColumnProfiler.scala:592) finished in 0.045 s\n",
      "2025-02-01 06:53:32,633 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:32,633 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:32,633 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 118)\n",
      "2025-02-01 06:53:32,633 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:32,633 INFO scheduler.DAGScheduler: Submitting ResultStage 118 (ShuffledRDD[466] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:32,634 INFO memory.MemoryStore: Block broadcast_94 stored as values in memory (estimated size 5.1 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:32,636 INFO memory.MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:32,636 INFO storage.BlockManagerInfo: Added broadcast_94_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:32,636 INFO spark.SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:32,637 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (ShuffledRDD[466] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:32,637 INFO cluster.YarnScheduler: Adding task set 118.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:32,638 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 118.0 (TID 92) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:32,656 INFO storage.BlockManagerInfo: Added broadcast_94_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:32,658 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:32,671 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 118.0 (TID 92) in 33 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:32,672 INFO cluster.YarnScheduler: Removed TaskSet 118.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:32,672 INFO scheduler.DAGScheduler: ResultStage 118 (countByKey at ColumnProfiler.scala:592) finished in 0.038 s\n",
      "2025-02-01 06:53:32,673 INFO scheduler.DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:32,673 INFO cluster.YarnScheduler: Killing all running tasks in stage 118: Stage finished\n",
      "2025-02-01 06:53:32,673 INFO scheduler.DAGScheduler: Job 79 finished: countByKey at ColumnProfiler.scala:592, took 0.088437 s\n",
      "2025-02-01 06:53:32,735 INFO scheduler.DAGScheduler: Registering RDD 471 (collect at AnalysisRunner.scala:326) as input to shuffle 39\n",
      "2025-02-01 06:53:32,735 INFO scheduler.DAGScheduler: Got map stage job 80 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:32,735 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 119 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:32,736 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:32,736 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:32,736 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[471] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:32,740 INFO memory.MemoryStore: Block broadcast_95 stored as values in memory (estimated size 100.0 KiB, free 1457.1 MiB)\n",
      "2025-02-01 06:53:32,742 INFO memory.MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 32.8 KiB, free 1457.0 MiB)\n",
      "2025-02-01 06:53:32,742 INFO storage.BlockManagerInfo: Added broadcast_95_piece0 in memory on 10.0.119.186:40697 (size: 32.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:32,742 INFO spark.SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:32,743 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[471] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:32,743 INFO cluster.YarnScheduler: Adding task set 119.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:32,744 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 119.0 (TID 93) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:32,754 INFO storage.BlockManagerInfo: Added broadcast_95_piece0 in memory on algo-1:34585 (size: 32.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:32,869 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 119.0 (TID 93) in 125 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:32,869 INFO cluster.YarnScheduler: Removed TaskSet 119.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:32,870 INFO scheduler.DAGScheduler: ShuffleMapStage 119 (collect at AnalysisRunner.scala:326) finished in 0.133 s\n",
      "2025-02-01 06:53:32,871 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:32,871 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:32,872 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:32,872 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:32,913 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:32,914 INFO scheduler.DAGScheduler: Got job 81 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:32,914 INFO scheduler.DAGScheduler: Final stage: ResultStage 121 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:32,914 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 120)\n",
      "2025-02-01 06:53:32,914 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:32,914 INFO scheduler.DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[474] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:32,927 INFO memory.MemoryStore: Block broadcast_96 stored as values in memory (estimated size 184.6 KiB, free 1456.9 MiB)\n",
      "2025-02-01 06:53:32,929 INFO memory.MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1456.8 MiB)\n",
      "2025-02-01 06:53:32,930 INFO storage.BlockManagerInfo: Added broadcast_96_piece0 in memory on 10.0.119.186:40697 (size: 50.3 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:32,935 INFO spark.SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:32,935 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[474] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:32,935 INFO cluster.YarnScheduler: Adding task set 121.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:32,939 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 121.0 (TID 94) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:32,946 INFO storage.BlockManagerInfo: Added broadcast_96_piece0 in memory on algo-1:34585 (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:32,955 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:33,013 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 121.0 (TID 94) in 74 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:33,014 INFO cluster.YarnScheduler: Removed TaskSet 121.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:33,015 INFO scheduler.DAGScheduler: ResultStage 121 (collect at AnalysisRunner.scala:326) finished in 0.098 s\n",
      "2025-02-01 06:53:33,015 INFO scheduler.DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:33,015 INFO cluster.YarnScheduler: Killing all running tasks in stage 121: Stage finished\n",
      "2025-02-01 06:53:33,015 INFO scheduler.DAGScheduler: Job 81 finished: collect at AnalysisRunner.scala:326, took 0.102126 s\n",
      "2025-02-01 06:53:33,115 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:33,116 INFO scheduler.DAGScheduler: Got job 82 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:33,116 INFO scheduler.DAGScheduler: Final stage: ResultStage 122 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:33,116 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:33,116 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:33,116 INFO scheduler.DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[484] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:33,122 INFO memory.MemoryStore: Block broadcast_97 stored as values in memory (estimated size 54.8 KiB, free 1456.8 MiB)\n",
      "2025-02-01 06:53:33,128 INFO memory.MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.7 MiB)\n",
      "2025-02-01 06:53:33,128 INFO storage.BlockManagerInfo: Added broadcast_97_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:33,129 INFO spark.SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:33,129 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[484] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:33,130 INFO cluster.YarnScheduler: Adding task set 122.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:33,131 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 122.0 (TID 95) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:33,138 INFO storage.BlockManagerInfo: Added broadcast_97_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,169 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 122.0 (TID 95) in 38 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:33,170 INFO cluster.YarnScheduler: Removed TaskSet 122.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:33,171 INFO scheduler.DAGScheduler: ResultStage 122 (treeReduce at KLLRunner.scala:107) finished in 0.054 s\n",
      "2025-02-01 06:53:33,171 INFO scheduler.DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:33,171 INFO cluster.YarnScheduler: Killing all running tasks in stage 122: Stage finished\n",
      "2025-02-01 06:53:33,172 INFO scheduler.DAGScheduler: Job 82 finished: treeReduce at KLLRunner.scala:107, took 0.056510 s\n",
      "2025-02-01 06:53:33,266 INFO scheduler.DAGScheduler: Registering RDD 489 (collect at AnalysisRunner.scala:326) as input to shuffle 40\n",
      "2025-02-01 06:53:33,267 INFO scheduler.DAGScheduler: Got map stage job 83 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:33,267 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 123 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:33,267 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:33,268 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:33,268 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 123 (MapPartitionsRDD[489] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:33,270 INFO memory.MemoryStore: Block broadcast_98 stored as values in memory (estimated size 90.7 KiB, free 1456.7 MiB)\n",
      "2025-02-01 06:53:33,274 INFO memory.MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 1456.6 MiB)\n",
      "2025-02-01 06:53:33,275 INFO storage.BlockManagerInfo: Added broadcast_98_piece0 in memory on 10.0.119.186:40697 (size: 28.0 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:33,275 INFO spark.SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:33,276 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 123 (MapPartitionsRDD[489] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:33,276 INFO cluster.YarnScheduler: Adding task set 123.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:33,277 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 123.0 (TID 96) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:33,284 INFO storage.BlockManagerInfo: Added broadcast_98_piece0 in memory on algo-1:34585 (size: 28.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,298 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 123.0 (TID 96) in 21 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:33,298 INFO cluster.YarnScheduler: Removed TaskSet 123.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:33,299 INFO scheduler.DAGScheduler: ShuffleMapStage 123 (collect at AnalysisRunner.scala:326) finished in 0.031 s\n",
      "2025-02-01 06:53:33,299 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:33,299 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:33,300 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:33,300 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:33,343 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:33,344 INFO scheduler.DAGScheduler: Got job 84 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:33,345 INFO scheduler.DAGScheduler: Final stage: ResultStage 125 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:33,345 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 124)\n",
      "2025-02-01 06:53:33,345 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:33,345 INFO scheduler.DAGScheduler: Submitting ResultStage 125 (MapPartitionsRDD[492] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:33,347 INFO memory.MemoryStore: Block broadcast_99 stored as values in memory (estimated size 66.2 KiB, free 1456.6 MiB)\n",
      "2025-02-01 06:53:33,373 INFO memory.MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.5 MiB)\n",
      "2025-02-01 06:53:33,374 INFO storage.BlockManagerInfo: Added broadcast_99_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:33,377 INFO storage.BlockManagerInfo: Removed broadcast_97_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:33,377 INFO storage.BlockManagerInfo: Removed broadcast_97_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,379 INFO spark.SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:33,382 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 125 (MapPartitionsRDD[492] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:33,382 INFO cluster.YarnScheduler: Adding task set 125.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:33,382 INFO storage.BlockManagerInfo: Removed broadcast_85_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:33,383 INFO storage.BlockManagerInfo: Removed broadcast_85_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,384 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 125.0 (TID 97) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:33,387 INFO storage.BlockManagerInfo: Removed broadcast_95_piece0 on 10.0.119.186:40697 in memory (size: 32.8 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:33,390 INFO storage.BlockManagerInfo: Removed broadcast_95_piece0 on algo-1:34585 in memory (size: 32.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,392 INFO storage.BlockManagerInfo: Added broadcast_99_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,399 INFO storage.BlockManagerInfo: Removed broadcast_89_piece0 on 10.0.119.186:40697 in memory (size: 50.3 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:33,399 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:33,401 INFO storage.BlockManagerInfo: Removed broadcast_89_piece0 on algo-1:34585 in memory (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,409 INFO storage.BlockManagerInfo: Removed broadcast_86_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:33,411 INFO storage.BlockManagerInfo: Removed broadcast_86_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,415 INFO storage.BlockManagerInfo: Removed broadcast_96_piece0 on algo-1:34585 in memory (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,416 INFO storage.BlockManagerInfo: Removed broadcast_96_piece0 on 10.0.119.186:40697 in memory (size: 50.3 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:33,418 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 125.0 (TID 97) in 35 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:33,418 INFO cluster.YarnScheduler: Removed TaskSet 125.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:33,419 INFO scheduler.DAGScheduler: ResultStage 125 (collect at AnalysisRunner.scala:326) finished in 0.073 s\n",
      "2025-02-01 06:53:33,419 INFO scheduler.DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:33,419 INFO cluster.YarnScheduler: Killing all running tasks in stage 125: Stage finished\n",
      "2025-02-01 06:53:33,420 INFO scheduler.DAGScheduler: Job 84 finished: collect at AnalysisRunner.scala:326, took 0.076026 s\n",
      "2025-02-01 06:53:33,425 INFO storage.BlockManagerInfo: Removed broadcast_90_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:33,432 INFO storage.BlockManagerInfo: Removed broadcast_90_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,436 INFO storage.BlockManagerInfo: Removed broadcast_92_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:33,438 INFO storage.BlockManagerInfo: Removed broadcast_92_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,440 INFO storage.BlockManagerInfo: Removed broadcast_91_piece0 on 10.0.119.186:40697 in memory (size: 27.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:33,441 INFO storage.BlockManagerInfo: Removed broadcast_91_piece0 on algo-1:34585 in memory (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,446 INFO storage.BlockManagerInfo: Removed broadcast_84_piece0 on 10.0.119.186:40697 in memory (size: 27.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:33,447 INFO storage.BlockManagerInfo: Removed broadcast_84_piece0 on algo-1:34585 in memory (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,449 INFO storage.BlockManagerInfo: Removed broadcast_87_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:33,450 INFO storage.BlockManagerInfo: Removed broadcast_87_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,457 INFO storage.BlockManagerInfo: Removed broadcast_94_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:33,458 INFO storage.BlockManagerInfo: Removed broadcast_94_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,463 INFO storage.BlockManagerInfo: Removed broadcast_98_piece0 on 10.0.119.186:40697 in memory (size: 28.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:33,464 INFO storage.BlockManagerInfo: Removed broadcast_98_piece0 on algo-1:34585 in memory (size: 28.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,465 INFO storage.BlockManagerInfo: Removed broadcast_93_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:33,466 INFO storage.BlockManagerInfo: Removed broadcast_93_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,469 INFO storage.BlockManagerInfo: Removed broadcast_88_piece0 on 10.0.119.186:40697 in memory (size: 32.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:33,471 INFO storage.BlockManagerInfo: Removed broadcast_88_piece0 on algo-1:34585 in memory (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,498 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:33,499 INFO scheduler.DAGScheduler: Registering RDD 500 (countByKey at ColumnProfiler.scala:592) as input to shuffle 41\n",
      "2025-02-01 06:53:33,500 INFO scheduler.DAGScheduler: Got job 85 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:33,500 INFO scheduler.DAGScheduler: Final stage: ResultStage 127 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:33,500 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 126)\n",
      "2025-02-01 06:53:33,501 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 126)\n",
      "2025-02-01 06:53:33,503 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 126 (MapPartitionsRDD[500] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:33,505 INFO memory.MemoryStore: Block broadcast_100 stored as values in memory (estimated size 47.1 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:33,507 INFO memory.MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:33,507 INFO storage.BlockManagerInfo: Added broadcast_100_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:33,508 INFO spark.SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:33,508 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 126 (MapPartitionsRDD[500] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:33,508 INFO cluster.YarnScheduler: Adding task set 126.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:33,509 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 126.0 (TID 98) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:33,517 INFO storage.BlockManagerInfo: Added broadcast_100_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,541 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 126.0 (TID 98) in 32 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:33,541 INFO cluster.YarnScheduler: Removed TaskSet 126.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:33,542 INFO scheduler.DAGScheduler: ShuffleMapStage 126 (countByKey at ColumnProfiler.scala:592) finished in 0.039 s\n",
      "2025-02-01 06:53:33,542 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:33,542 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:33,542 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 127)\n",
      "2025-02-01 06:53:33,542 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:33,542 INFO scheduler.DAGScheduler: Submitting ResultStage 127 (ShuffledRDD[501] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:33,543 INFO memory.MemoryStore: Block broadcast_101 stored as values in memory (estimated size 5.1 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:33,545 INFO memory.MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:33,545 INFO storage.BlockManagerInfo: Added broadcast_101_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:33,546 INFO spark.SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:33,546 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 127 (ShuffledRDD[501] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:33,546 INFO cluster.YarnScheduler: Adding task set 127.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:33,547 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 127.0 (TID 99) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:33,553 INFO storage.BlockManagerInfo: Added broadcast_101_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,555 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:33,562 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 127.0 (TID 99) in 15 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:33,563 INFO cluster.YarnScheduler: Removed TaskSet 127.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:33,563 INFO scheduler.DAGScheduler: ResultStage 127 (countByKey at ColumnProfiler.scala:592) finished in 0.020 s\n",
      "2025-02-01 06:53:33,564 INFO scheduler.DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:33,564 INFO cluster.YarnScheduler: Killing all running tasks in stage 127: Stage finished\n",
      "2025-02-01 06:53:33,564 INFO scheduler.DAGScheduler: Job 85 finished: countByKey at ColumnProfiler.scala:592, took 0.066285 s\n",
      "2025-02-01 06:53:33,723 INFO scheduler.DAGScheduler: Registering RDD 506 (collect at AnalysisRunner.scala:326) as input to shuffle 42\n",
      "2025-02-01 06:53:33,723 INFO scheduler.DAGScheduler: Got map stage job 86 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:33,723 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 128 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:33,724 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:33,724 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:33,724 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 128 (MapPartitionsRDD[506] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:33,729 INFO memory.MemoryStore: Block broadcast_102 stored as values in memory (estimated size 100.0 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:33,731 INFO memory.MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:33,731 INFO storage.BlockManagerInfo: Added broadcast_102_piece0 in memory on 10.0.119.186:40697 (size: 32.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:33,732 INFO spark.SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:33,732 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 128 (MapPartitionsRDD[506] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:33,732 INFO cluster.YarnScheduler: Adding task set 128.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:33,733 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 128.0 (TID 100) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:33,739 INFO storage.BlockManagerInfo: Added broadcast_102_piece0 in memory on algo-1:34585 (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:33,929 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 128.0 (TID 100) in 196 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:33,929 INFO cluster.YarnScheduler: Removed TaskSet 128.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:33,930 INFO scheduler.DAGScheduler: ShuffleMapStage 128 (collect at AnalysisRunner.scala:326) finished in 0.205 s\n",
      "2025-02-01 06:53:33,931 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:33,932 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:33,932 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:33,932 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:33,990 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:33,991 INFO scheduler.DAGScheduler: Got job 87 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:33,991 INFO scheduler.DAGScheduler: Final stage: ResultStage 130 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:33,991 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 129)\n",
      "2025-02-01 06:53:33,991 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:33,992 INFO scheduler.DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[509] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:33,998 INFO memory.MemoryStore: Block broadcast_103 stored as values in memory (estimated size 184.6 KiB, free 1457.7 MiB)\n",
      "2025-02-01 06:53:34,000 INFO memory.MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.6 MiB)\n",
      "2025-02-01 06:53:34,000 INFO storage.BlockManagerInfo: Added broadcast_103_piece0 in memory on 10.0.119.186:40697 (size: 50.3 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:34,001 INFO spark.SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:34,001 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[509] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:34,001 INFO cluster.YarnScheduler: Adding task set 130.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:34,002 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 130.0 (TID 101) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:34,010 INFO storage.BlockManagerInfo: Added broadcast_103_piece0 in memory on algo-1:34585 (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:34,033 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:34,256 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 130.0 (TID 101) in 254 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:34,256 INFO cluster.YarnScheduler: Removed TaskSet 130.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:34,257 INFO scheduler.DAGScheduler: ResultStage 130 (collect at AnalysisRunner.scala:326) finished in 0.265 s\n",
      "2025-02-01 06:53:34,257 INFO scheduler.DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:34,257 INFO cluster.YarnScheduler: Killing all running tasks in stage 130: Stage finished\n",
      "2025-02-01 06:53:34,258 INFO scheduler.DAGScheduler: Job 87 finished: collect at AnalysisRunner.scala:326, took 0.267463 s\n",
      "2025-02-01 06:53:34,421 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:34,422 INFO scheduler.DAGScheduler: Got job 88 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:34,422 INFO scheduler.DAGScheduler: Final stage: ResultStage 131 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:34,422 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:34,423 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:34,423 INFO scheduler.DAGScheduler: Submitting ResultStage 131 (MapPartitionsRDD[519] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:34,428 INFO memory.MemoryStore: Block broadcast_104 stored as values in memory (estimated size 54.8 KiB, free 1457.6 MiB)\n",
      "2025-02-01 06:53:34,430 INFO memory.MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.6 MiB)\n",
      "2025-02-01 06:53:34,431 INFO storage.BlockManagerInfo: Added broadcast_104_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:34,431 INFO spark.SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:34,432 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 131 (MapPartitionsRDD[519] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:34,432 INFO cluster.YarnScheduler: Adding task set 131.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:34,433 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 131.0 (TID 102) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:34,441 INFO storage.BlockManagerInfo: Added broadcast_104_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:34,493 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 131.0 (TID 102) in 60 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:34,493 INFO cluster.YarnScheduler: Removed TaskSet 131.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:34,493 INFO scheduler.DAGScheduler: ResultStage 131 (treeReduce at KLLRunner.scala:107) finished in 0.069 s\n",
      "2025-02-01 06:53:34,495 INFO scheduler.DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:34,496 INFO cluster.YarnScheduler: Killing all running tasks in stage 131: Stage finished\n",
      "2025-02-01 06:53:34,496 INFO scheduler.DAGScheduler: Job 88 finished: treeReduce at KLLRunner.scala:107, took 0.074772 s\n",
      "2025-02-01 06:53:34,645 INFO scheduler.DAGScheduler: Registering RDD 524 (collect at AnalysisRunner.scala:326) as input to shuffle 43\n",
      "2025-02-01 06:53:34,645 INFO scheduler.DAGScheduler: Got map stage job 89 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:34,645 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 132 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:34,646 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:34,646 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:34,646 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 132 (MapPartitionsRDD[524] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:34,650 INFO memory.MemoryStore: Block broadcast_105 stored as values in memory (estimated size 90.7 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:34,652 INFO memory.MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:34,652 INFO storage.BlockManagerInfo: Added broadcast_105_piece0 in memory on 10.0.119.186:40697 (size: 28.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:34,653 INFO spark.SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:34,653 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 132 (MapPartitionsRDD[524] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:34,653 INFO cluster.YarnScheduler: Adding task set 132.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:34,654 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 132.0 (TID 103) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:34,661 INFO storage.BlockManagerInfo: Added broadcast_105_piece0 in memory on algo-1:34585 (size: 28.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:34,680 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 132.0 (TID 103) in 26 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:34,681 INFO cluster.YarnScheduler: Removed TaskSet 132.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:34,681 INFO scheduler.DAGScheduler: ShuffleMapStage 132 (collect at AnalysisRunner.scala:326) finished in 0.033 s\n",
      "2025-02-01 06:53:34,681 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:34,682 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:34,682 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:34,682 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:34,735 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:34,736 INFO scheduler.DAGScheduler: Got job 90 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:34,736 INFO scheduler.DAGScheduler: Final stage: ResultStage 134 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:34,737 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 133)\n",
      "2025-02-01 06:53:34,737 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:34,737 INFO scheduler.DAGScheduler: Submitting ResultStage 134 (MapPartitionsRDD[527] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:34,739 INFO memory.MemoryStore: Block broadcast_106 stored as values in memory (estimated size 66.2 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:34,743 INFO memory.MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:34,744 INFO storage.BlockManagerInfo: Added broadcast_106_piece0 in memory on 10.0.119.186:40697 (size: 19.1 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:34,745 INFO spark.SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:34,745 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 134 (MapPartitionsRDD[527] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:34,745 INFO cluster.YarnScheduler: Adding task set 134.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:34,746 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 134.0 (TID 104) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:34,757 INFO storage.BlockManagerInfo: Added broadcast_106_piece0 in memory on algo-1:34585 (size: 19.1 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:34,761 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:34,766 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 134.0 (TID 104) in 20 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:34,766 INFO cluster.YarnScheduler: Removed TaskSet 134.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:34,767 INFO scheduler.DAGScheduler: ResultStage 134 (collect at AnalysisRunner.scala:326) finished in 0.029 s\n",
      "2025-02-01 06:53:34,767 INFO scheduler.DAGScheduler: Job 90 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:34,768 INFO cluster.YarnScheduler: Killing all running tasks in stage 134: Stage finished\n",
      "2025-02-01 06:53:34,768 INFO scheduler.DAGScheduler: Job 90 finished: collect at AnalysisRunner.scala:326, took 0.032328 s\n",
      "2025-02-01 06:53:34,808 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:34,809 INFO scheduler.DAGScheduler: Registering RDD 535 (countByKey at ColumnProfiler.scala:592) as input to shuffle 44\n",
      "2025-02-01 06:53:34,809 INFO scheduler.DAGScheduler: Got job 91 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:34,810 INFO scheduler.DAGScheduler: Final stage: ResultStage 136 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:34,810 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 135)\n",
      "2025-02-01 06:53:34,810 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 135)\n",
      "2025-02-01 06:53:34,811 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 135 (MapPartitionsRDD[535] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:34,814 INFO memory.MemoryStore: Block broadcast_107 stored as values in memory (estimated size 47.1 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:34,815 INFO memory.MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:34,816 INFO storage.BlockManagerInfo: Added broadcast_107_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:34,816 INFO spark.SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:34,817 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 135 (MapPartitionsRDD[535] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:34,817 INFO cluster.YarnScheduler: Adding task set 135.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:34,818 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 135.0 (TID 105) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:34,826 INFO storage.BlockManagerInfo: Added broadcast_107_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:34,868 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 135.0 (TID 105) in 50 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:34,868 INFO cluster.YarnScheduler: Removed TaskSet 135.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:34,869 INFO scheduler.DAGScheduler: ShuffleMapStage 135 (countByKey at ColumnProfiler.scala:592) finished in 0.058 s\n",
      "2025-02-01 06:53:34,869 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:34,869 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:34,869 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 136)\n",
      "2025-02-01 06:53:34,869 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:34,870 INFO scheduler.DAGScheduler: Submitting ResultStage 136 (ShuffledRDD[536] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:34,871 INFO memory.MemoryStore: Block broadcast_108 stored as values in memory (estimated size 5.1 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:34,872 INFO memory.MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:34,872 INFO storage.BlockManagerInfo: Added broadcast_108_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:34,873 INFO spark.SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:34,873 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (ShuffledRDD[536] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:34,874 INFO cluster.YarnScheduler: Adding task set 136.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:34,875 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 136.0 (TID 106) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:34,883 INFO storage.BlockManagerInfo: Added broadcast_108_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:34,885 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:34,902 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 136.0 (TID 106) in 27 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:34,902 INFO cluster.YarnScheduler: Removed TaskSet 136.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:34,903 INFO scheduler.DAGScheduler: ResultStage 136 (countByKey at ColumnProfiler.scala:592) finished in 0.032 s\n",
      "2025-02-01 06:53:34,903 INFO scheduler.DAGScheduler: Job 91 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:34,903 INFO cluster.YarnScheduler: Killing all running tasks in stage 136: Stage finished\n",
      "2025-02-01 06:53:34,903 INFO scheduler.DAGScheduler: Job 91 finished: countByKey at ColumnProfiler.scala:592, took 0.094979 s\n",
      "2025-02-01 06:53:34,973 INFO scheduler.DAGScheduler: Registering RDD 541 (collect at AnalysisRunner.scala:326) as input to shuffle 45\n",
      "2025-02-01 06:53:34,973 INFO scheduler.DAGScheduler: Got map stage job 92 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:34,974 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 137 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:34,974 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:34,974 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:34,975 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 137 (MapPartitionsRDD[541] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:34,978 INFO memory.MemoryStore: Block broadcast_109 stored as values in memory (estimated size 100.0 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:34,980 INFO memory.MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 32.8 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:34,980 INFO storage.BlockManagerInfo: Added broadcast_109_piece0 in memory on 10.0.119.186:40697 (size: 32.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:34,981 INFO spark.SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:34,981 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 137 (MapPartitionsRDD[541] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:34,981 INFO cluster.YarnScheduler: Adding task set 137.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:34,983 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 137.0 (TID 107) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:34,992 INFO storage.BlockManagerInfo: Added broadcast_109_piece0 in memory on algo-1:34585 (size: 32.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,083 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 137.0 (TID 107) in 100 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:35,084 INFO scheduler.DAGScheduler: ShuffleMapStage 137 (collect at AnalysisRunner.scala:326) finished in 0.109 s\n",
      "2025-02-01 06:53:35,084 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:35,085 INFO cluster.YarnScheduler: Removed TaskSet 137.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:35,085 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:35,085 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:35,085 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:35,117 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:35,118 INFO scheduler.DAGScheduler: Got job 93 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:35,118 INFO scheduler.DAGScheduler: Final stage: ResultStage 139 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:35,118 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 138)\n",
      "2025-02-01 06:53:35,118 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:35,119 INFO scheduler.DAGScheduler: Submitting ResultStage 139 (MapPartitionsRDD[544] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:35,125 INFO memory.MemoryStore: Block broadcast_110 stored as values in memory (estimated size 184.6 KiB, free 1457.0 MiB)\n",
      "2025-02-01 06:53:35,127 INFO memory.MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1456.9 MiB)\n",
      "2025-02-01 06:53:35,127 INFO storage.BlockManagerInfo: Added broadcast_110_piece0 in memory on 10.0.119.186:40697 (size: 50.3 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:35,128 INFO spark.SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:35,128 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 139 (MapPartitionsRDD[544] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:35,128 INFO cluster.YarnScheduler: Adding task set 139.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:35,130 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 139.0 (TID 108) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:35,139 INFO storage.BlockManagerInfo: Added broadcast_110_piece0 in memory on algo-1:34585 (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,157 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:35,262 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 139.0 (TID 108) in 133 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:35,262 INFO cluster.YarnScheduler: Removed TaskSet 139.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:35,263 INFO scheduler.DAGScheduler: ResultStage 139 (collect at AnalysisRunner.scala:326) finished in 0.144 s\n",
      "2025-02-01 06:53:35,264 INFO scheduler.DAGScheduler: Job 93 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:35,264 INFO cluster.YarnScheduler: Killing all running tasks in stage 139: Stage finished\n",
      "2025-02-01 06:53:35,264 INFO scheduler.DAGScheduler: Job 93 finished: collect at AnalysisRunner.scala:326, took 0.146952 s\n",
      "2025-02-01 06:53:35,348 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:35,349 INFO scheduler.DAGScheduler: Got job 94 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:35,349 INFO scheduler.DAGScheduler: Final stage: ResultStage 140 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:35,350 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:35,350 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:35,350 INFO scheduler.DAGScheduler: Submitting ResultStage 140 (MapPartitionsRDD[554] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:35,354 INFO memory.MemoryStore: Block broadcast_111 stored as values in memory (estimated size 54.8 KiB, free 1456.9 MiB)\n",
      "2025-02-01 06:53:35,355 INFO memory.MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.9 MiB)\n",
      "2025-02-01 06:53:35,356 INFO storage.BlockManagerInfo: Added broadcast_111_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:35,356 INFO spark.SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:35,357 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 140 (MapPartitionsRDD[554] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:35,357 INFO cluster.YarnScheduler: Adding task set 140.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:35,358 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 140.0 (TID 109) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:35,371 INFO storage.BlockManagerInfo: Added broadcast_111_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,405 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 140.0 (TID 109) in 47 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:35,405 INFO cluster.YarnScheduler: Removed TaskSet 140.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:35,406 INFO scheduler.DAGScheduler: ResultStage 140 (treeReduce at KLLRunner.scala:107) finished in 0.055 s\n",
      "2025-02-01 06:53:35,406 INFO scheduler.DAGScheduler: Job 94 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:35,407 INFO cluster.YarnScheduler: Killing all running tasks in stage 140: Stage finished\n",
      "2025-02-01 06:53:35,407 INFO scheduler.DAGScheduler: Job 94 finished: treeReduce at KLLRunner.scala:107, took 0.058238 s\n",
      "2025-02-01 06:53:35,503 INFO scheduler.DAGScheduler: Registering RDD 559 (collect at AnalysisRunner.scala:326) as input to shuffle 46\n",
      "2025-02-01 06:53:35,503 INFO scheduler.DAGScheduler: Got map stage job 95 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:35,503 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 141 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:35,503 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:35,504 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:35,504 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 141 (MapPartitionsRDD[559] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:35,507 INFO memory.MemoryStore: Block broadcast_112 stored as values in memory (estimated size 90.7 KiB, free 1456.8 MiB)\n",
      "2025-02-01 06:53:35,509 INFO memory.MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.7 MiB)\n",
      "2025-02-01 06:53:35,509 INFO storage.BlockManagerInfo: Added broadcast_112_piece0 in memory on 10.0.119.186:40697 (size: 27.9 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:35,509 INFO spark.SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:35,510 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 141 (MapPartitionsRDD[559] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:35,510 INFO cluster.YarnScheduler: Adding task set 141.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:35,511 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 141.0 (TID 110) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:35,519 INFO storage.BlockManagerInfo: Added broadcast_112_piece0 in memory on algo-1:34585 (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,547 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 141.0 (TID 110) in 36 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:35,547 INFO cluster.YarnScheduler: Removed TaskSet 141.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:35,548 INFO scheduler.DAGScheduler: ShuffleMapStage 141 (collect at AnalysisRunner.scala:326) finished in 0.043 s\n",
      "2025-02-01 06:53:35,548 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:35,549 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:35,549 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:35,549 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:35,592 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:35,593 INFO scheduler.DAGScheduler: Got job 96 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:35,593 INFO scheduler.DAGScheduler: Final stage: ResultStage 143 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:35,594 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 142)\n",
      "2025-02-01 06:53:35,594 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:35,594 INFO scheduler.DAGScheduler: Submitting ResultStage 143 (MapPartitionsRDD[562] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:35,596 INFO memory.MemoryStore: Block broadcast_113 stored as values in memory (estimated size 66.2 KiB, free 1456.7 MiB)\n",
      "2025-02-01 06:53:35,601 INFO memory.MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1456.7 MiB)\n",
      "2025-02-01 06:53:35,605 INFO storage.BlockManagerInfo: Added broadcast_113_piece0 in memory on 10.0.119.186:40697 (size: 19.1 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:35,609 INFO spark.SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:35,609 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 143 (MapPartitionsRDD[562] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:35,609 INFO cluster.YarnScheduler: Adding task set 143.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:35,610 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 143.0 (TID 111) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:35,617 INFO storage.BlockManagerInfo: Added broadcast_113_piece0 in memory on algo-1:34585 (size: 19.1 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,622 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:35,636 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 143.0 (TID 111) in 26 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:35,636 INFO cluster.YarnScheduler: Removed TaskSet 143.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:35,637 INFO scheduler.DAGScheduler: ResultStage 143 (collect at AnalysisRunner.scala:326) finished in 0.042 s\n",
      "2025-02-01 06:53:35,637 INFO scheduler.DAGScheduler: Job 96 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:35,638 INFO cluster.YarnScheduler: Killing all running tasks in stage 143: Stage finished\n",
      "2025-02-01 06:53:35,638 INFO scheduler.DAGScheduler: Job 96 finished: collect at AnalysisRunner.scala:326, took 0.045283 s\n",
      "2025-02-01 06:53:35,686 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:35,687 INFO scheduler.DAGScheduler: Registering RDD 570 (countByKey at ColumnProfiler.scala:592) as input to shuffle 47\n",
      "2025-02-01 06:53:35,687 INFO scheduler.DAGScheduler: Got job 97 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:35,687 INFO scheduler.DAGScheduler: Final stage: ResultStage 145 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:35,688 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 144)\n",
      "2025-02-01 06:53:35,688 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 144)\n",
      "2025-02-01 06:53:35,689 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 144 (MapPartitionsRDD[570] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:35,692 INFO memory.MemoryStore: Block broadcast_114 stored as values in memory (estimated size 47.1 KiB, free 1456.6 MiB)\n",
      "2025-02-01 06:53:35,694 INFO memory.MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1456.6 MiB)\n",
      "2025-02-01 06:53:35,694 INFO storage.BlockManagerInfo: Added broadcast_114_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:35,695 INFO spark.SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:35,695 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 144 (MapPartitionsRDD[570] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:35,695 INFO cluster.YarnScheduler: Adding task set 144.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:35,696 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 144.0 (TID 112) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:35,703 INFO storage.BlockManagerInfo: Added broadcast_114_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,732 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 144.0 (TID 112) in 36 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:35,732 INFO cluster.YarnScheduler: Removed TaskSet 144.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:35,732 INFO scheduler.DAGScheduler: ShuffleMapStage 144 (countByKey at ColumnProfiler.scala:592) finished in 0.043 s\n",
      "2025-02-01 06:53:35,733 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:35,733 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:35,734 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 145)\n",
      "2025-02-01 06:53:35,734 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:35,734 INFO scheduler.DAGScheduler: Submitting ResultStage 145 (ShuffledRDD[571] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:35,735 INFO memory.MemoryStore: Block broadcast_115 stored as values in memory (estimated size 5.1 KiB, free 1456.6 MiB)\n",
      "2025-02-01 06:53:35,740 INFO memory.MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.6 MiB)\n",
      "2025-02-01 06:53:35,740 INFO storage.BlockManagerInfo: Added broadcast_115_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:35,740 INFO spark.SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:35,741 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 145 (ShuffledRDD[571] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:35,741 INFO cluster.YarnScheduler: Adding task set 145.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:35,741 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 145.0 (TID 113) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:35,753 INFO storage.BlockManagerInfo: Added broadcast_115_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,757 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:35,770 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 145.0 (TID 113) in 29 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:35,770 INFO cluster.YarnScheduler: Removed TaskSet 145.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:35,771 INFO scheduler.DAGScheduler: ResultStage 145 (countByKey at ColumnProfiler.scala:592) finished in 0.036 s\n",
      "2025-02-01 06:53:35,771 INFO scheduler.DAGScheduler: Job 97 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:35,771 INFO cluster.YarnScheduler: Killing all running tasks in stage 145: Stage finished\n",
      "2025-02-01 06:53:35,772 INFO scheduler.DAGScheduler: Job 97 finished: countByKey at ColumnProfiler.scala:592, took 0.085378 s\n",
      "2025-02-01 06:53:35,852 INFO storage.BlockManagerInfo: Removed broadcast_115_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:35,854 INFO storage.BlockManagerInfo: Removed broadcast_115_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,860 INFO storage.BlockManagerInfo: Removed broadcast_101_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:35,861 INFO storage.BlockManagerInfo: Removed broadcast_101_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,862 INFO storage.BlockManagerInfo: Removed broadcast_108_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:35,863 INFO storage.BlockManagerInfo: Removed broadcast_108_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,865 INFO storage.BlockManagerInfo: Removed broadcast_106_piece0 on 10.0.119.186:40697 in memory (size: 19.1 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:35,866 INFO storage.BlockManagerInfo: Removed broadcast_106_piece0 on algo-1:34585 in memory (size: 19.1 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,871 INFO storage.BlockManagerInfo: Removed broadcast_111_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:35,871 INFO storage.BlockManagerInfo: Removed broadcast_111_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,873 INFO storage.BlockManagerInfo: Removed broadcast_112_piece0 on 10.0.119.186:40697 in memory (size: 27.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:35,874 INFO storage.BlockManagerInfo: Removed broadcast_112_piece0 on algo-1:34585 in memory (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,880 INFO storage.BlockManagerInfo: Removed broadcast_100_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:35,880 INFO storage.BlockManagerInfo: Removed broadcast_100_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,883 INFO storage.BlockManagerInfo: Removed broadcast_99_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:35,883 INFO storage.BlockManagerInfo: Removed broadcast_99_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,886 INFO storage.BlockManagerInfo: Removed broadcast_104_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:35,887 INFO storage.BlockManagerInfo: Removed broadcast_104_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,891 INFO storage.BlockManagerInfo: Removed broadcast_102_piece0 on 10.0.119.186:40697 in memory (size: 32.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:35,891 INFO storage.BlockManagerInfo: Removed broadcast_102_piece0 on algo-1:34585 in memory (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,900 INFO storage.BlockManagerInfo: Removed broadcast_114_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:35,903 INFO storage.BlockManagerInfo: Removed broadcast_114_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,905 INFO storage.BlockManagerInfo: Removed broadcast_107_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:35,905 INFO storage.BlockManagerInfo: Removed broadcast_107_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,907 INFO storage.BlockManagerInfo: Removed broadcast_109_piece0 on 10.0.119.186:40697 in memory (size: 32.8 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:35,915 INFO storage.BlockManagerInfo: Removed broadcast_109_piece0 on algo-1:34585 in memory (size: 32.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,917 INFO storage.BlockManagerInfo: Removed broadcast_105_piece0 on 10.0.119.186:40697 in memory (size: 28.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:35,918 INFO storage.BlockManagerInfo: Removed broadcast_105_piece0 on algo-1:34585 in memory (size: 28.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,919 INFO storage.BlockManagerInfo: Removed broadcast_110_piece0 on 10.0.119.186:40697 in memory (size: 50.3 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:35,920 INFO storage.BlockManagerInfo: Removed broadcast_110_piece0 on algo-1:34585 in memory (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,923 INFO storage.BlockManagerInfo: Removed broadcast_113_piece0 on 10.0.119.186:40697 in memory (size: 19.1 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:35,924 INFO storage.BlockManagerInfo: Removed broadcast_113_piece0 on algo-1:34585 in memory (size: 19.1 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,939 INFO storage.BlockManagerInfo: Removed broadcast_103_piece0 on 10.0.119.186:40697 in memory (size: 50.3 KiB, free: 1458.6 MiB)\n",
      "2025-02-01 06:53:35,939 INFO storage.BlockManagerInfo: Removed broadcast_103_piece0 on algo-1:34585 in memory (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:35,976 INFO scheduler.DAGScheduler: Registering RDD 576 (collect at AnalysisRunner.scala:326) as input to shuffle 48\n",
      "2025-02-01 06:53:35,976 INFO scheduler.DAGScheduler: Got map stage job 98 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:35,976 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 146 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:35,977 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:35,977 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:35,977 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 146 (MapPartitionsRDD[576] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:35,982 INFO memory.MemoryStore: Block broadcast_116 stored as values in memory (estimated size 100.0 KiB, free 1458.1 MiB)\n",
      "2025-02-01 06:53:35,984 INFO memory.MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 32.8 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:35,985 INFO storage.BlockManagerInfo: Added broadcast_116_piece0 in memory on 10.0.119.186:40697 (size: 32.8 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:35,985 INFO spark.SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:35,986 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 146 (MapPartitionsRDD[576] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:35,986 INFO cluster.YarnScheduler: Adding task set 146.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:35,994 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 146.0 (TID 114) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:36,000 INFO storage.BlockManagerInfo: Added broadcast_116_piece0 in memory on algo-1:34585 (size: 32.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:36,184 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 146.0 (TID 114) in 190 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:36,185 INFO cluster.YarnScheduler: Removed TaskSet 146.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:36,185 INFO scheduler.DAGScheduler: ShuffleMapStage 146 (collect at AnalysisRunner.scala:326) finished in 0.207 s\n",
      "2025-02-01 06:53:36,186 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:36,186 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:36,186 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:36,187 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:36,250 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:36,251 INFO scheduler.DAGScheduler: Got job 99 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:36,251 INFO scheduler.DAGScheduler: Final stage: ResultStage 148 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:36,251 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 147)\n",
      "2025-02-01 06:53:36,251 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:36,251 INFO scheduler.DAGScheduler: Submitting ResultStage 148 (MapPartitionsRDD[579] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:36,259 INFO memory.MemoryStore: Block broadcast_117 stored as values in memory (estimated size 184.6 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:36,266 INFO memory.MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:36,266 INFO storage.BlockManagerInfo: Added broadcast_117_piece0 in memory on 10.0.119.186:40697 (size: 50.3 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:36,267 INFO spark.SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:36,267 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[579] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:36,267 INFO cluster.YarnScheduler: Adding task set 148.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:36,268 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 148.0 (TID 115) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:36,274 INFO storage.BlockManagerInfo: Added broadcast_117_piece0 in memory on algo-1:34585 (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:36,292 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:36,450 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 148.0 (TID 115) in 182 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:36,450 INFO cluster.YarnScheduler: Removed TaskSet 148.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:36,450 INFO scheduler.DAGScheduler: ResultStage 148 (collect at AnalysisRunner.scala:326) finished in 0.198 s\n",
      "2025-02-01 06:53:36,451 INFO scheduler.DAGScheduler: Job 99 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:36,452 INFO cluster.YarnScheduler: Killing all running tasks in stage 148: Stage finished\n",
      "2025-02-01 06:53:36,452 INFO scheduler.DAGScheduler: Job 99 finished: collect at AnalysisRunner.scala:326, took 0.202309 s\n",
      "2025-02-01 06:53:36,529 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:36,530 INFO scheduler.DAGScheduler: Got job 100 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:36,531 INFO scheduler.DAGScheduler: Final stage: ResultStage 149 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:36,531 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:36,531 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:36,531 INFO scheduler.DAGScheduler: Submitting ResultStage 149 (MapPartitionsRDD[589] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:36,537 INFO memory.MemoryStore: Block broadcast_118 stored as values in memory (estimated size 54.8 KiB, free 1457.7 MiB)\n",
      "2025-02-01 06:53:36,538 INFO memory.MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.7 MiB)\n",
      "2025-02-01 06:53:36,539 INFO storage.BlockManagerInfo: Added broadcast_118_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:36,539 INFO spark.SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:36,540 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[589] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:36,540 INFO cluster.YarnScheduler: Adding task set 149.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:36,541 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 149.0 (TID 116) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:36,548 INFO storage.BlockManagerInfo: Added broadcast_118_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:36,576 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 149.0 (TID 116) in 35 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:36,576 INFO cluster.YarnScheduler: Removed TaskSet 149.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:36,577 INFO scheduler.DAGScheduler: ResultStage 149 (treeReduce at KLLRunner.scala:107) finished in 0.045 s\n",
      "2025-02-01 06:53:36,577 INFO scheduler.DAGScheduler: Job 100 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:36,578 INFO cluster.YarnScheduler: Killing all running tasks in stage 149: Stage finished\n",
      "2025-02-01 06:53:36,578 INFO scheduler.DAGScheduler: Job 100 finished: treeReduce at KLLRunner.scala:107, took 0.048226 s\n",
      "2025-02-01 06:53:36,707 INFO scheduler.DAGScheduler: Registering RDD 594 (collect at AnalysisRunner.scala:326) as input to shuffle 49\n",
      "2025-02-01 06:53:36,708 INFO scheduler.DAGScheduler: Got map stage job 101 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:36,708 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 150 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:36,708 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:36,708 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:36,709 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 150 (MapPartitionsRDD[594] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:36,711 INFO memory.MemoryStore: Block broadcast_119 stored as values in memory (estimated size 90.7 KiB, free 1457.6 MiB)\n",
      "2025-02-01 06:53:36,713 INFO memory.MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.6 MiB)\n",
      "2025-02-01 06:53:36,713 INFO storage.BlockManagerInfo: Added broadcast_119_piece0 in memory on 10.0.119.186:40697 (size: 27.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:36,714 INFO spark.SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:36,714 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 150 (MapPartitionsRDD[594] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:36,714 INFO cluster.YarnScheduler: Adding task set 150.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:36,715 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 150.0 (TID 117) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:36,721 INFO storage.BlockManagerInfo: Added broadcast_119_piece0 in memory on algo-1:34585 (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:36,751 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 150.0 (TID 117) in 36 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:36,751 INFO cluster.YarnScheduler: Removed TaskSet 150.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:36,752 INFO scheduler.DAGScheduler: ShuffleMapStage 150 (collect at AnalysisRunner.scala:326) finished in 0.042 s\n",
      "2025-02-01 06:53:36,752 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:36,753 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:36,753 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:36,753 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:36,798 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:36,799 INFO scheduler.DAGScheduler: Got job 102 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:36,799 INFO scheduler.DAGScheduler: Final stage: ResultStage 152 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:36,799 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 151)\n",
      "2025-02-01 06:53:36,800 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:36,800 INFO scheduler.DAGScheduler: Submitting ResultStage 152 (MapPartitionsRDD[597] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:36,802 INFO memory.MemoryStore: Block broadcast_120 stored as values in memory (estimated size 66.2 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:36,803 INFO memory.MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:36,804 INFO storage.BlockManagerInfo: Added broadcast_120_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:36,804 INFO spark.SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:36,805 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 152 (MapPartitionsRDD[597] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:36,805 INFO cluster.YarnScheduler: Adding task set 152.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:36,806 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 152.0 (TID 118) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:36,815 INFO storage.BlockManagerInfo: Added broadcast_120_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:36,820 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:36,825 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 152.0 (TID 118) in 19 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:36,825 INFO cluster.YarnScheduler: Removed TaskSet 152.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:36,826 INFO scheduler.DAGScheduler: ResultStage 152 (collect at AnalysisRunner.scala:326) finished in 0.025 s\n",
      "2025-02-01 06:53:36,826 INFO scheduler.DAGScheduler: Job 102 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:36,826 INFO cluster.YarnScheduler: Killing all running tasks in stage 152: Stage finished\n",
      "2025-02-01 06:53:36,827 INFO scheduler.DAGScheduler: Job 102 finished: collect at AnalysisRunner.scala:326, took 0.028490 s\n",
      "2025-02-01 06:53:36,881 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:36,882 INFO scheduler.DAGScheduler: Registering RDD 605 (countByKey at ColumnProfiler.scala:592) as input to shuffle 50\n",
      "2025-02-01 06:53:36,882 INFO scheduler.DAGScheduler: Got job 103 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:36,882 INFO scheduler.DAGScheduler: Final stage: ResultStage 154 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:36,882 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 153)\n",
      "2025-02-01 06:53:36,883 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 153)\n",
      "2025-02-01 06:53:36,884 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 153 (MapPartitionsRDD[605] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:36,887 INFO memory.MemoryStore: Block broadcast_121 stored as values in memory (estimated size 47.1 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:36,889 INFO memory.MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:36,889 INFO storage.BlockManagerInfo: Added broadcast_121_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:36,890 INFO spark.SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:36,890 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 153 (MapPartitionsRDD[605] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:36,891 INFO cluster.YarnScheduler: Adding task set 153.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:36,892 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 153.0 (TID 119) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:36,902 INFO storage.BlockManagerInfo: Added broadcast_121_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:36,924 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 153.0 (TID 119) in 33 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:36,925 INFO cluster.YarnScheduler: Removed TaskSet 153.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:36,925 INFO scheduler.DAGScheduler: ShuffleMapStage 153 (countByKey at ColumnProfiler.scala:592) finished in 0.041 s\n",
      "2025-02-01 06:53:36,925 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:36,926 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:36,926 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 154)\n",
      "2025-02-01 06:53:36,926 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:36,927 INFO scheduler.DAGScheduler: Submitting ResultStage 154 (ShuffledRDD[606] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:36,928 INFO memory.MemoryStore: Block broadcast_122 stored as values in memory (estimated size 5.1 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:36,929 INFO memory.MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:36,930 INFO storage.BlockManagerInfo: Added broadcast_122_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:36,930 INFO spark.SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:36,930 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 154 (ShuffledRDD[606] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:36,930 INFO cluster.YarnScheduler: Adding task set 154.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:36,931 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 154.0 (TID 120) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:36,938 INFO storage.BlockManagerInfo: Added broadcast_122_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:36,941 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:36,960 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 154.0 (TID 120) in 29 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:36,963 INFO cluster.YarnScheduler: Removed TaskSet 154.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:36,963 INFO scheduler.DAGScheduler: ResultStage 154 (countByKey at ColumnProfiler.scala:592) finished in 0.036 s\n",
      "2025-02-01 06:53:36,964 INFO scheduler.DAGScheduler: Job 103 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:36,964 INFO cluster.YarnScheduler: Killing all running tasks in stage 154: Stage finished\n",
      "2025-02-01 06:53:36,964 INFO scheduler.DAGScheduler: Job 103 finished: countByKey at ColumnProfiler.scala:592, took 0.082729 s\n",
      "2025-02-01 06:53:37,178 INFO scheduler.DAGScheduler: Registering RDD 611 (collect at AnalysisRunner.scala:326) as input to shuffle 51\n",
      "2025-02-01 06:53:37,179 INFO scheduler.DAGScheduler: Got map stage job 104 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:37,179 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 155 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:37,179 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:37,180 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:37,180 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 155 (MapPartitionsRDD[611] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:37,184 INFO memory.MemoryStore: Block broadcast_123 stored as values in memory (estimated size 100.0 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:37,186 INFO memory.MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:37,187 INFO storage.BlockManagerInfo: Added broadcast_123_piece0 in memory on 10.0.119.186:40697 (size: 32.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:37,188 INFO spark.SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:37,188 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 155 (MapPartitionsRDD[611] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:37,188 INFO cluster.YarnScheduler: Adding task set 155.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:37,189 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 155.0 (TID 121) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:37,195 INFO storage.BlockManagerInfo: Added broadcast_123_piece0 in memory on algo-1:34585 (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:37,293 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 155.0 (TID 121) in 104 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:37,293 INFO cluster.YarnScheduler: Removed TaskSet 155.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:37,294 INFO scheduler.DAGScheduler: ShuffleMapStage 155 (collect at AnalysisRunner.scala:326) finished in 0.113 s\n",
      "2025-02-01 06:53:37,294 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:37,295 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:37,295 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:37,295 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:37,354 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:37,355 INFO scheduler.DAGScheduler: Got job 105 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:37,355 INFO scheduler.DAGScheduler: Final stage: ResultStage 157 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:37,355 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 156)\n",
      "2025-02-01 06:53:37,355 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:37,356 INFO scheduler.DAGScheduler: Submitting ResultStage 157 (MapPartitionsRDD[614] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:37,363 INFO memory.MemoryStore: Block broadcast_124 stored as values in memory (estimated size 184.6 KiB, free 1457.1 MiB)\n",
      "2025-02-01 06:53:37,366 INFO memory.MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.1 MiB)\n",
      "2025-02-01 06:53:37,369 INFO storage.BlockManagerInfo: Added broadcast_124_piece0 in memory on 10.0.119.186:40697 (size: 50.3 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:37,370 INFO spark.SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:37,370 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 157 (MapPartitionsRDD[614] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:37,370 INFO cluster.YarnScheduler: Adding task set 157.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:37,371 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 157.0 (TID 122) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:37,378 INFO storage.BlockManagerInfo: Added broadcast_124_piece0 in memory on algo-1:34585 (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:37,391 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 51 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:37,470 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 157.0 (TID 122) in 99 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:37,470 INFO cluster.YarnScheduler: Removed TaskSet 157.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:37,471 INFO scheduler.DAGScheduler: ResultStage 157 (collect at AnalysisRunner.scala:326) finished in 0.114 s\n",
      "2025-02-01 06:53:37,471 INFO scheduler.DAGScheduler: Job 105 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:37,472 INFO cluster.YarnScheduler: Killing all running tasks in stage 157: Stage finished\n",
      "2025-02-01 06:53:37,472 INFO scheduler.DAGScheduler: Job 105 finished: collect at AnalysisRunner.scala:326, took 0.118083 s\n",
      "2025-02-01 06:53:37,628 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:37,629 INFO scheduler.DAGScheduler: Got job 106 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:37,631 INFO scheduler.DAGScheduler: Final stage: ResultStage 158 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:37,631 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:37,632 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:37,633 INFO scheduler.DAGScheduler: Submitting ResultStage 158 (MapPartitionsRDD[624] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:37,644 INFO memory.MemoryStore: Block broadcast_125 stored as values in memory (estimated size 54.8 KiB, free 1457.0 MiB)\n",
      "2025-02-01 06:53:37,645 INFO memory.MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.0 MiB)\n",
      "2025-02-01 06:53:37,645 INFO storage.BlockManagerInfo: Added broadcast_125_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:37,646 INFO spark.SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:37,646 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 158 (MapPartitionsRDD[624] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:37,646 INFO cluster.YarnScheduler: Adding task set 158.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:37,647 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 158.0 (TID 123) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:37,654 INFO storage.BlockManagerInfo: Added broadcast_125_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:37,695 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 158.0 (TID 123) in 48 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:37,695 INFO cluster.YarnScheduler: Removed TaskSet 158.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:37,696 INFO scheduler.DAGScheduler: ResultStage 158 (treeReduce at KLLRunner.scala:107) finished in 0.063 s\n",
      "2025-02-01 06:53:37,696 INFO scheduler.DAGScheduler: Job 106 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:37,696 INFO cluster.YarnScheduler: Killing all running tasks in stage 158: Stage finished\n",
      "2025-02-01 06:53:37,698 INFO scheduler.DAGScheduler: Job 106 finished: treeReduce at KLLRunner.scala:107, took 0.069676 s\n",
      "2025-02-01 06:53:37,802 INFO scheduler.DAGScheduler: Registering RDD 629 (collect at AnalysisRunner.scala:326) as input to shuffle 52\n",
      "2025-02-01 06:53:37,802 INFO scheduler.DAGScheduler: Got map stage job 107 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:37,802 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 159 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:37,803 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:37,803 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:37,803 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 159 (MapPartitionsRDD[629] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:37,806 INFO memory.MemoryStore: Block broadcast_126 stored as values in memory (estimated size 90.7 KiB, free 1456.9 MiB)\n",
      "2025-02-01 06:53:37,809 INFO memory.MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.9 MiB)\n",
      "2025-02-01 06:53:37,809 INFO storage.BlockManagerInfo: Added broadcast_126_piece0 in memory on 10.0.119.186:40697 (size: 27.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:37,810 INFO spark.SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:37,810 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 159 (MapPartitionsRDD[629] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:37,810 INFO cluster.YarnScheduler: Adding task set 159.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:37,811 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 159.0 (TID 124) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:37,818 INFO storage.BlockManagerInfo: Added broadcast_126_piece0 in memory on algo-1:34585 (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:37,829 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 159.0 (TID 124) in 18 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:37,829 INFO cluster.YarnScheduler: Removed TaskSet 159.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:37,830 INFO scheduler.DAGScheduler: ShuffleMapStage 159 (collect at AnalysisRunner.scala:326) finished in 0.026 s\n",
      "2025-02-01 06:53:37,831 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:37,831 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:37,831 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:37,831 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:37,867 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:37,867 INFO scheduler.DAGScheduler: Got job 108 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:37,868 INFO scheduler.DAGScheduler: Final stage: ResultStage 161 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:37,868 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 160)\n",
      "2025-02-01 06:53:37,868 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:37,868 INFO scheduler.DAGScheduler: Submitting ResultStage 161 (MapPartitionsRDD[632] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:37,870 INFO memory.MemoryStore: Block broadcast_127 stored as values in memory (estimated size 66.2 KiB, free 1456.8 MiB)\n",
      "2025-02-01 06:53:37,872 INFO memory.MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.8 MiB)\n",
      "2025-02-01 06:53:37,872 INFO storage.BlockManagerInfo: Added broadcast_127_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:37,872 INFO spark.SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:37,873 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 161 (MapPartitionsRDD[632] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:37,873 INFO cluster.YarnScheduler: Adding task set 161.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:37,874 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 161.0 (TID 125) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:37,880 INFO storage.BlockManagerInfo: Added broadcast_127_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:37,883 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 52 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:37,887 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 161.0 (TID 125) in 13 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:37,887 INFO cluster.YarnScheduler: Removed TaskSet 161.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:37,888 INFO scheduler.DAGScheduler: ResultStage 161 (collect at AnalysisRunner.scala:326) finished in 0.019 s\n",
      "2025-02-01 06:53:37,888 INFO scheduler.DAGScheduler: Job 108 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:37,888 INFO cluster.YarnScheduler: Killing all running tasks in stage 161: Stage finished\n",
      "2025-02-01 06:53:37,889 INFO scheduler.DAGScheduler: Job 108 finished: collect at AnalysisRunner.scala:326, took 0.021866 s\n",
      "2025-02-01 06:53:37,951 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:37,951 INFO scheduler.DAGScheduler: Registering RDD 640 (countByKey at ColumnProfiler.scala:592) as input to shuffle 53\n",
      "2025-02-01 06:53:37,952 INFO scheduler.DAGScheduler: Got job 109 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:37,952 INFO scheduler.DAGScheduler: Final stage: ResultStage 163 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:37,952 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 162)\n",
      "2025-02-01 06:53:37,952 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 162)\n",
      "2025-02-01 06:53:37,953 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 162 (MapPartitionsRDD[640] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:37,955 INFO memory.MemoryStore: Block broadcast_128 stored as values in memory (estimated size 47.1 KiB, free 1456.8 MiB)\n",
      "2025-02-01 06:53:37,957 INFO memory.MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1456.8 MiB)\n",
      "2025-02-01 06:53:37,957 INFO storage.BlockManagerInfo: Added broadcast_128_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:37,958 INFO spark.SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:37,958 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 162 (MapPartitionsRDD[640] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:37,958 INFO cluster.YarnScheduler: Adding task set 162.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:37,959 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 162.0 (TID 126) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:37,969 INFO storage.BlockManagerInfo: Added broadcast_128_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:37,989 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 162.0 (TID 126) in 30 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:37,990 INFO cluster.YarnScheduler: Removed TaskSet 162.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:37,991 INFO scheduler.DAGScheduler: ShuffleMapStage 162 (countByKey at ColumnProfiler.scala:592) finished in 0.038 s\n",
      "2025-02-01 06:53:37,991 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:37,991 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:37,992 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 163)\n",
      "2025-02-01 06:53:37,993 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:37,993 INFO scheduler.DAGScheduler: Submitting ResultStage 163 (ShuffledRDD[641] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:37,994 INFO memory.MemoryStore: Block broadcast_129 stored as values in memory (estimated size 5.1 KiB, free 1456.7 MiB)\n",
      "2025-02-01 06:53:37,996 INFO memory.MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.7 MiB)\n",
      "2025-02-01 06:53:37,997 INFO storage.BlockManagerInfo: Added broadcast_129_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:37,997 INFO spark.SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:37,998 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 163 (ShuffledRDD[641] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:37,998 INFO cluster.YarnScheduler: Adding task set 163.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:37,999 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 163.0 (TID 127) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:38,006 INFO storage.BlockManagerInfo: Added broadcast_129_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,009 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:38,023 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 163.0 (TID 127) in 24 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:38,023 INFO cluster.YarnScheduler: Removed TaskSet 163.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:38,024 INFO scheduler.DAGScheduler: ResultStage 163 (countByKey at ColumnProfiler.scala:592) finished in 0.030 s\n",
      "2025-02-01 06:53:38,024 INFO scheduler.DAGScheduler: Job 109 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:38,025 INFO cluster.YarnScheduler: Killing all running tasks in stage 163: Stage finished\n",
      "2025-02-01 06:53:38,025 INFO scheduler.DAGScheduler: Job 109 finished: countByKey at ColumnProfiler.scala:592, took 0.074032 s\n",
      "2025-02-01 06:53:38,167 INFO scheduler.DAGScheduler: Registering RDD 646 (collect at AnalysisRunner.scala:326) as input to shuffle 54\n",
      "2025-02-01 06:53:38,167 INFO scheduler.DAGScheduler: Got map stage job 110 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:38,167 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 164 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:38,168 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:38,168 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:38,168 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 164 (MapPartitionsRDD[646] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:38,172 INFO memory.MemoryStore: Block broadcast_130 stored as values in memory (estimated size 100.0 KiB, free 1456.6 MiB)\n",
      "2025-02-01 06:53:38,174 INFO memory.MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1456.6 MiB)\n",
      "2025-02-01 06:53:38,174 INFO storage.BlockManagerInfo: Added broadcast_130_piece0 in memory on 10.0.119.186:40697 (size: 32.9 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:38,174 INFO spark.SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:38,175 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 164 (MapPartitionsRDD[646] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:38,175 INFO cluster.YarnScheduler: Adding task set 164.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:38,176 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 164.0 (TID 128) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:38,181 INFO storage.BlockManagerInfo: Added broadcast_130_piece0 in memory on algo-1:34585 (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,335 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 164.0 (TID 128) in 159 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:38,335 INFO cluster.YarnScheduler: Removed TaskSet 164.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:38,336 INFO scheduler.DAGScheduler: ShuffleMapStage 164 (collect at AnalysisRunner.scala:326) finished in 0.167 s\n",
      "2025-02-01 06:53:38,336 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:38,337 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:38,337 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:38,337 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:38,374 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:38,374 INFO scheduler.DAGScheduler: Got job 111 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:38,374 INFO scheduler.DAGScheduler: Final stage: ResultStage 166 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:38,374 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 165)\n",
      "2025-02-01 06:53:38,375 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:38,375 INFO scheduler.DAGScheduler: Submitting ResultStage 166 (MapPartitionsRDD[649] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:38,382 INFO memory.MemoryStore: Block broadcast_131 stored as values in memory (estimated size 184.6 KiB, free 1456.4 MiB)\n",
      "2025-02-01 06:53:38,383 INFO memory.MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1456.4 MiB)\n",
      "2025-02-01 06:53:38,385 INFO storage.BlockManagerInfo: Added broadcast_131_piece0 in memory on 10.0.119.186:40697 (size: 50.3 KiB, free: 1458.1 MiB)\n",
      "2025-02-01 06:53:38,386 INFO spark.SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:38,386 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 166 (MapPartitionsRDD[649] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:38,386 INFO cluster.YarnScheduler: Adding task set 166.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:38,388 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 166.0 (TID 129) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:38,394 INFO storage.BlockManagerInfo: Added broadcast_131_piece0 in memory on algo-1:34585 (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,402 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 54 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:38,484 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 166.0 (TID 129) in 96 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:38,487 INFO cluster.YarnScheduler: Removed TaskSet 166.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:38,487 INFO scheduler.DAGScheduler: ResultStage 166 (collect at AnalysisRunner.scala:326) finished in 0.112 s\n",
      "2025-02-01 06:53:38,488 INFO scheduler.DAGScheduler: Job 111 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:38,488 INFO cluster.YarnScheduler: Killing all running tasks in stage 166: Stage finished\n",
      "2025-02-01 06:53:38,488 INFO scheduler.DAGScheduler: Job 111 finished: collect at AnalysisRunner.scala:326, took 0.114625 s\n",
      "2025-02-01 06:53:38,592 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:38,592 INFO scheduler.DAGScheduler: Got job 112 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:38,592 INFO scheduler.DAGScheduler: Final stage: ResultStage 167 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:38,592 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:38,593 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:38,593 INFO scheduler.DAGScheduler: Submitting ResultStage 167 (MapPartitionsRDD[659] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:38,597 INFO memory.MemoryStore: Block broadcast_132 stored as values in memory (estimated size 54.8 KiB, free 1456.3 MiB)\n",
      "2025-02-01 06:53:38,599 INFO memory.MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.3 MiB)\n",
      "2025-02-01 06:53:38,599 INFO storage.BlockManagerInfo: Added broadcast_132_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.1 MiB)\n",
      "2025-02-01 06:53:38,599 INFO spark.SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:38,599 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 167 (MapPartitionsRDD[659] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:38,599 INFO cluster.YarnScheduler: Adding task set 167.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:38,600 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 167.0 (TID 130) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:38,605 INFO storage.BlockManagerInfo: Added broadcast_132_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,634 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 167.0 (TID 130) in 34 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:38,635 INFO scheduler.DAGScheduler: ResultStage 167 (treeReduce at KLLRunner.scala:107) finished in 0.040 s\n",
      "2025-02-01 06:53:38,635 INFO scheduler.DAGScheduler: Job 112 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:38,646 INFO cluster.YarnScheduler: Removed TaskSet 167.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:38,646 INFO cluster.YarnScheduler: Killing all running tasks in stage 167: Stage finished\n",
      "2025-02-01 06:53:38,646 INFO scheduler.DAGScheduler: Job 112 finished: treeReduce at KLLRunner.scala:107, took 0.054389 s\n",
      "2025-02-01 06:53:38,703 INFO storage.BlockManagerInfo: Removed broadcast_125_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.1 MiB)\n",
      "2025-02-01 06:53:38,706 INFO storage.BlockManagerInfo: Removed broadcast_125_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,711 INFO storage.BlockManagerInfo: Removed broadcast_126_piece0 on 10.0.119.186:40697 in memory (size: 27.9 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:38,713 INFO storage.BlockManagerInfo: Removed broadcast_126_piece0 on algo-1:34585 in memory (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,716 INFO storage.BlockManagerInfo: Removed broadcast_117_piece0 on 10.0.119.186:40697 in memory (size: 50.3 KiB, free: 1458.2 MiB)\n",
      "2025-02-01 06:53:38,716 INFO storage.BlockManagerInfo: Removed broadcast_117_piece0 on algo-1:34585 in memory (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,719 INFO storage.BlockManagerInfo: Removed broadcast_123_piece0 on 10.0.119.186:40697 in memory (size: 32.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:38,720 INFO storage.BlockManagerInfo: Removed broadcast_123_piece0 on algo-1:34585 in memory (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,722 INFO storage.BlockManagerInfo: Removed broadcast_128_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:38,722 INFO storage.BlockManagerInfo: Removed broadcast_128_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,724 INFO storage.BlockManagerInfo: Removed broadcast_116_piece0 on 10.0.119.186:40697 in memory (size: 32.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:38,725 INFO storage.BlockManagerInfo: Removed broadcast_116_piece0 on algo-1:34585 in memory (size: 32.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,732 INFO storage.BlockManagerInfo: Removed broadcast_122_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:38,732 INFO storage.BlockManagerInfo: Removed broadcast_122_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,736 INFO storage.BlockManagerInfo: Removed broadcast_118_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:38,736 INFO storage.BlockManagerInfo: Removed broadcast_118_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,738 INFO storage.BlockManagerInfo: Removed broadcast_129_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:38,739 INFO storage.BlockManagerInfo: Removed broadcast_129_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,741 INFO storage.BlockManagerInfo: Removed broadcast_120_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:38,742 INFO storage.BlockManagerInfo: Removed broadcast_120_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,744 INFO storage.BlockManagerInfo: Removed broadcast_124_piece0 on 10.0.119.186:40697 in memory (size: 50.3 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:38,745 INFO storage.BlockManagerInfo: Removed broadcast_124_piece0 on algo-1:34585 in memory (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,748 INFO storage.BlockManagerInfo: Removed broadcast_127_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:38,748 INFO storage.BlockManagerInfo: Removed broadcast_127_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,752 INFO storage.BlockManagerInfo: Removed broadcast_121_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:38,753 INFO storage.BlockManagerInfo: Removed broadcast_121_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,756 INFO storage.BlockManagerInfo: Removed broadcast_130_piece0 on 10.0.119.186:40697 in memory (size: 32.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:38,756 INFO storage.BlockManagerInfo: Removed broadcast_130_piece0 on algo-1:34585 in memory (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,758 INFO storage.BlockManagerInfo: Removed broadcast_119_piece0 on 10.0.119.186:40697 in memory (size: 27.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:38,759 INFO storage.BlockManagerInfo: Removed broadcast_119_piece0 on algo-1:34585 in memory (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,765 INFO storage.BlockManagerInfo: Removed broadcast_131_piece0 on 10.0.119.186:40697 in memory (size: 50.3 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:38,766 INFO storage.BlockManagerInfo: Removed broadcast_131_piece0 on algo-1:34585 in memory (size: 50.3 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,769 INFO storage.BlockManagerInfo: Removed broadcast_132_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.6 MiB)\n",
      "2025-02-01 06:53:38,770 INFO storage.BlockManagerInfo: Removed broadcast_132_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,832 INFO scheduler.DAGScheduler: Registering RDD 664 (collect at AnalysisRunner.scala:326) as input to shuffle 55\n",
      "2025-02-01 06:53:38,832 INFO scheduler.DAGScheduler: Got map stage job 113 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:38,832 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 168 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:38,833 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:38,833 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:38,834 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 168 (MapPartitionsRDD[664] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:38,835 INFO memory.MemoryStore: Block broadcast_133 stored as values in memory (estimated size 90.7 KiB, free 1458.1 MiB)\n",
      "2025-02-01 06:53:38,836 INFO memory.MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:38,837 INFO storage.BlockManagerInfo: Added broadcast_133_piece0 in memory on 10.0.119.186:40697 (size: 27.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:38,837 INFO spark.SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:38,837 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 168 (MapPartitionsRDD[664] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:38,837 INFO cluster.YarnScheduler: Adding task set 168.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:38,838 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 168.0 (TID 131) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:38,844 INFO storage.BlockManagerInfo: Added broadcast_133_piece0 in memory on algo-1:34585 (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,853 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 168.0 (TID 131) in 15 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:38,853 INFO cluster.YarnScheduler: Removed TaskSet 168.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:38,853 INFO scheduler.DAGScheduler: ShuffleMapStage 168 (collect at AnalysisRunner.scala:326) finished in 0.019 s\n",
      "2025-02-01 06:53:38,854 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:38,854 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:38,854 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:38,854 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:38,891 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:38,892 INFO scheduler.DAGScheduler: Got job 114 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:38,892 INFO scheduler.DAGScheduler: Final stage: ResultStage 170 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:38,892 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 169)\n",
      "2025-02-01 06:53:38,893 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:38,893 INFO scheduler.DAGScheduler: Submitting ResultStage 170 (MapPartitionsRDD[667] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:38,894 INFO memory.MemoryStore: Block broadcast_134 stored as values in memory (estimated size 66.2 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:38,896 INFO memory.MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1458.0 MiB)\n",
      "2025-02-01 06:53:38,896 INFO storage.BlockManagerInfo: Added broadcast_134_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:38,897 INFO spark.SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:38,897 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 170 (MapPartitionsRDD[667] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:38,897 INFO cluster.YarnScheduler: Adding task set 170.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:38,898 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 170.0 (TID 132) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:38,903 INFO storage.BlockManagerInfo: Added broadcast_134_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,905 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:38,910 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 170.0 (TID 132) in 12 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:38,910 INFO cluster.YarnScheduler: Removed TaskSet 170.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:38,910 INFO scheduler.DAGScheduler: ResultStage 170 (collect at AnalysisRunner.scala:326) finished in 0.016 s\n",
      "2025-02-01 06:53:38,911 INFO scheduler.DAGScheduler: Job 114 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:38,911 INFO cluster.YarnScheduler: Killing all running tasks in stage 170: Stage finished\n",
      "2025-02-01 06:53:38,911 INFO scheduler.DAGScheduler: Job 114 finished: collect at AnalysisRunner.scala:326, took 0.019699 s\n",
      "2025-02-01 06:53:38,954 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:38,955 INFO scheduler.DAGScheduler: Registering RDD 675 (countByKey at ColumnProfiler.scala:592) as input to shuffle 56\n",
      "2025-02-01 06:53:38,956 INFO scheduler.DAGScheduler: Got job 115 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:38,956 INFO scheduler.DAGScheduler: Final stage: ResultStage 172 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:38,956 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 171)\n",
      "2025-02-01 06:53:38,956 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 171)\n",
      "2025-02-01 06:53:38,957 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 171 (MapPartitionsRDD[675] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:38,960 INFO memory.MemoryStore: Block broadcast_135 stored as values in memory (estimated size 47.1 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:38,961 INFO memory.MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:38,962 INFO storage.BlockManagerInfo: Added broadcast_135_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:38,962 INFO spark.SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:38,963 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 171 (MapPartitionsRDD[675] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:38,963 INFO cluster.YarnScheduler: Adding task set 171.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:38,963 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 171.0 (TID 133) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:38,971 INFO storage.BlockManagerInfo: Added broadcast_135_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:38,988 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 171.0 (TID 133) in 25 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:38,988 INFO cluster.YarnScheduler: Removed TaskSet 171.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:38,989 INFO scheduler.DAGScheduler: ShuffleMapStage 171 (countByKey at ColumnProfiler.scala:592) finished in 0.032 s\n",
      "2025-02-01 06:53:38,989 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:38,989 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:38,989 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 172)\n",
      "2025-02-01 06:53:38,990 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:38,990 INFO scheduler.DAGScheduler: Submitting ResultStage 172 (ShuffledRDD[676] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:38,991 INFO memory.MemoryStore: Block broadcast_136 stored as values in memory (estimated size 5.1 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:38,992 INFO memory.MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.9 MiB)\n",
      "2025-02-01 06:53:38,993 INFO storage.BlockManagerInfo: Added broadcast_136_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:38,993 INFO spark.SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:38,994 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 172 (ShuffledRDD[676] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:38,994 INFO cluster.YarnScheduler: Adding task set 172.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:38,995 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 172.0 (TID 134) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:39,002 INFO storage.BlockManagerInfo: Added broadcast_136_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:39,006 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:39,017 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 172.0 (TID 134) in 22 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:39,018 INFO scheduler.DAGScheduler: ResultStage 172 (countByKey at ColumnProfiler.scala:592) finished in 0.028 s\n",
      "2025-02-01 06:53:39,018 INFO cluster.YarnScheduler: Removed TaskSet 172.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:39,018 INFO scheduler.DAGScheduler: Job 115 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:39,018 INFO cluster.YarnScheduler: Killing all running tasks in stage 172: Stage finished\n",
      "2025-02-01 06:53:39,019 INFO scheduler.DAGScheduler: Job 115 finished: countByKey at ColumnProfiler.scala:592, took 0.064162 s\n",
      "2025-02-01 06:53:39,180 INFO scheduler.DAGScheduler: Registering RDD 681 (collect at AnalysisRunner.scala:326) as input to shuffle 57\n",
      "2025-02-01 06:53:39,180 INFO scheduler.DAGScheduler: Got map stage job 116 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:39,180 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 173 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:39,180 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:39,181 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:39,181 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 173 (MapPartitionsRDD[681] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:39,185 INFO memory.MemoryStore: Block broadcast_137 stored as values in memory (estimated size 100.0 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:39,186 INFO memory.MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.8 MiB)\n",
      "2025-02-01 06:53:39,187 INFO storage.BlockManagerInfo: Added broadcast_137_piece0 in memory on 10.0.119.186:40697 (size: 32.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:39,187 INFO spark.SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:39,187 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 173 (MapPartitionsRDD[681] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:39,188 INFO cluster.YarnScheduler: Adding task set 173.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:39,189 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 173.0 (TID 135) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:39,196 INFO storage.BlockManagerInfo: Added broadcast_137_piece0 in memory on algo-1:34585 (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:39,309 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 173.0 (TID 135) in 121 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:39,310 INFO cluster.YarnScheduler: Removed TaskSet 173.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:39,312 INFO scheduler.DAGScheduler: ShuffleMapStage 173 (collect at AnalysisRunner.scala:326) finished in 0.130 s\n",
      "2025-02-01 06:53:39,313 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:39,313 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:39,313 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:39,313 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:39,379 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:39,380 INFO scheduler.DAGScheduler: Got job 117 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:39,381 INFO scheduler.DAGScheduler: Final stage: ResultStage 175 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:39,381 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 174)\n",
      "2025-02-01 06:53:39,381 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:39,381 INFO scheduler.DAGScheduler: Submitting ResultStage 175 (MapPartitionsRDD[684] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:39,388 INFO memory.MemoryStore: Block broadcast_138 stored as values in memory (estimated size 184.6 KiB, free 1457.6 MiB)\n",
      "2025-02-01 06:53:39,394 INFO memory.MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:39,395 INFO storage.BlockManagerInfo: Added broadcast_138_piece0 in memory on 10.0.119.186:40697 (size: 50.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:39,395 INFO spark.SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:39,396 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 175 (MapPartitionsRDD[684] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:39,396 INFO cluster.YarnScheduler: Adding task set 175.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:39,397 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 175.0 (TID 136) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:39,404 INFO storage.BlockManagerInfo: Added broadcast_138_piece0 in memory on algo-1:34585 (size: 50.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:39,422 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 57 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:39,536 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 175.0 (TID 136) in 139 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:39,536 INFO cluster.YarnScheduler: Removed TaskSet 175.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:39,537 INFO scheduler.DAGScheduler: ResultStage 175 (collect at AnalysisRunner.scala:326) finished in 0.154 s\n",
      "2025-02-01 06:53:39,538 INFO scheduler.DAGScheduler: Job 117 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:39,538 INFO cluster.YarnScheduler: Killing all running tasks in stage 175: Stage finished\n",
      "2025-02-01 06:53:39,539 INFO scheduler.DAGScheduler: Job 117 finished: collect at AnalysisRunner.scala:326, took 0.158779 s\n",
      "2025-02-01 06:53:39,636 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-01 06:53:39,637 INFO scheduler.DAGScheduler: Got job 118 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-01 06:53:39,638 INFO scheduler.DAGScheduler: Final stage: ResultStage 176 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-01 06:53:39,638 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:39,638 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:39,638 INFO scheduler.DAGScheduler: Submitting ResultStage 176 (MapPartitionsRDD[694] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-01 06:53:39,655 INFO memory.MemoryStore: Block broadcast_139 stored as values in memory (estimated size 54.8 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:39,658 INFO memory.MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.5 MiB)\n",
      "2025-02-01 06:53:39,659 INFO storage.BlockManagerInfo: Added broadcast_139_piece0 in memory on 10.0.119.186:40697 (size: 20.7 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:39,659 INFO spark.SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:39,659 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 176 (MapPartitionsRDD[694] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:39,660 INFO cluster.YarnScheduler: Adding task set 176.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:39,661 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 176.0 (TID 137) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:39,675 INFO storage.BlockManagerInfo: Added broadcast_139_piece0 in memory on algo-1:34585 (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:39,718 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 176.0 (TID 137) in 58 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:39,718 INFO cluster.YarnScheduler: Removed TaskSet 176.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:39,719 INFO scheduler.DAGScheduler: ResultStage 176 (treeReduce at KLLRunner.scala:107) finished in 0.079 s\n",
      "2025-02-01 06:53:39,720 INFO scheduler.DAGScheduler: Job 118 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:39,720 INFO cluster.YarnScheduler: Killing all running tasks in stage 176: Stage finished\n",
      "2025-02-01 06:53:39,721 INFO scheduler.DAGScheduler: Job 118 finished: treeReduce at KLLRunner.scala:107, took 0.084380 s\n",
      "2025-02-01 06:53:39,847 INFO scheduler.DAGScheduler: Registering RDD 699 (collect at AnalysisRunner.scala:326) as input to shuffle 58\n",
      "2025-02-01 06:53:39,847 INFO scheduler.DAGScheduler: Got map stage job 119 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:39,847 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 177 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:39,847 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:39,848 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:39,848 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 177 (MapPartitionsRDD[699] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:39,850 INFO memory.MemoryStore: Block broadcast_140 stored as values in memory (estimated size 90.7 KiB, free 1457.4 MiB)\n",
      "2025-02-01 06:53:39,852 INFO memory.MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:39,852 INFO storage.BlockManagerInfo: Added broadcast_140_piece0 in memory on 10.0.119.186:40697 (size: 28.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:39,853 INFO spark.SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:39,853 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 177 (MapPartitionsRDD[699] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:39,853 INFO cluster.YarnScheduler: Adding task set 177.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:39,854 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 177.0 (TID 138) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:39,861 INFO storage.BlockManagerInfo: Added broadcast_140_piece0 in memory on algo-1:34585 (size: 28.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:39,872 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 177.0 (TID 138) in 18 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:39,874 INFO cluster.YarnScheduler: Removed TaskSet 177.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:39,874 INFO scheduler.DAGScheduler: ShuffleMapStage 177 (collect at AnalysisRunner.scala:326) finished in 0.025 s\n",
      "2025-02-01 06:53:39,875 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:39,875 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:39,875 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:39,875 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:39,910 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-01 06:53:39,910 INFO scheduler.DAGScheduler: Got job 120 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-01 06:53:39,910 INFO scheduler.DAGScheduler: Final stage: ResultStage 179 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-01 06:53:39,910 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 178)\n",
      "2025-02-01 06:53:39,910 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:39,911 INFO scheduler.DAGScheduler: Submitting ResultStage 179 (MapPartitionsRDD[702] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-01 06:53:39,912 INFO memory.MemoryStore: Block broadcast_141 stored as values in memory (estimated size 66.2 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:39,914 INFO memory.MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.3 MiB)\n",
      "2025-02-01 06:53:39,914 INFO storage.BlockManagerInfo: Added broadcast_141_piece0 in memory on 10.0.119.186:40697 (size: 19.2 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:39,915 INFO spark.SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:39,915 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 179 (MapPartitionsRDD[702] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:39,915 INFO cluster.YarnScheduler: Adding task set 179.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:39,916 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 179.0 (TID 139) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:39,922 INFO storage.BlockManagerInfo: Added broadcast_141_piece0 in memory on algo-1:34585 (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:39,925 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 58 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:39,930 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 179.0 (TID 139) in 14 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:39,930 INFO cluster.YarnScheduler: Removed TaskSet 179.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:39,931 INFO scheduler.DAGScheduler: ResultStage 179 (collect at AnalysisRunner.scala:326) finished in 0.019 s\n",
      "2025-02-01 06:53:39,932 INFO scheduler.DAGScheduler: Job 120 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:39,932 INFO cluster.YarnScheduler: Killing all running tasks in stage 179: Stage finished\n",
      "2025-02-01 06:53:39,932 INFO scheduler.DAGScheduler: Job 120 finished: collect at AnalysisRunner.scala:326, took 0.022698 s\n",
      "2025-02-01 06:53:39,974 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-01 06:53:39,974 INFO scheduler.DAGScheduler: Registering RDD 710 (countByKey at ColumnProfiler.scala:592) as input to shuffle 59\n",
      "2025-02-01 06:53:39,975 INFO scheduler.DAGScheduler: Got job 121 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-01 06:53:39,975 INFO scheduler.DAGScheduler: Final stage: ResultStage 181 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-01 06:53:39,975 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 180)\n",
      "2025-02-01 06:53:39,975 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 180)\n",
      "2025-02-01 06:53:39,975 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 180 (MapPartitionsRDD[710] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:39,979 INFO memory.MemoryStore: Block broadcast_142 stored as values in memory (estimated size 47.1 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:39,981 INFO memory.MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:39,981 INFO storage.BlockManagerInfo: Added broadcast_142_piece0 in memory on 10.0.119.186:40697 (size: 18.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:39,981 INFO spark.SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:39,982 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 180 (MapPartitionsRDD[710] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:39,982 INFO cluster.YarnScheduler: Adding task set 180.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:39,985 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 180.0 (TID 140) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:39,990 INFO storage.BlockManagerInfo: Added broadcast_142_piece0 in memory on algo-1:34585 (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:40,007 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 180.0 (TID 140) in 22 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:40,007 INFO cluster.YarnScheduler: Removed TaskSet 180.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:40,008 INFO scheduler.DAGScheduler: ShuffleMapStage 180 (countByKey at ColumnProfiler.scala:592) finished in 0.032 s\n",
      "2025-02-01 06:53:40,008 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:40,009 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:40,009 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 181)\n",
      "2025-02-01 06:53:40,009 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:40,009 INFO scheduler.DAGScheduler: Submitting ResultStage 181 (ShuffledRDD[711] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-01 06:53:40,010 INFO memory.MemoryStore: Block broadcast_143 stored as values in memory (estimated size 5.1 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:40,011 INFO memory.MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.2 MiB)\n",
      "2025-02-01 06:53:40,012 INFO storage.BlockManagerInfo: Added broadcast_143_piece0 in memory on 10.0.119.186:40697 (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:40,012 INFO spark.SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:40,012 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 181 (ShuffledRDD[711] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:40,015 INFO cluster.YarnScheduler: Adding task set 181.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:40,016 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 181.0 (TID 141) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:40,023 INFO storage.BlockManagerInfo: Added broadcast_143_piece0 in memory on algo-1:34585 (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:40,025 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 59 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:40,033 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 181.0 (TID 141) in 17 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:40,033 INFO cluster.YarnScheduler: Removed TaskSet 181.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:40,034 INFO scheduler.DAGScheduler: ResultStage 181 (countByKey at ColumnProfiler.scala:592) finished in 0.025 s\n",
      "2025-02-01 06:53:40,034 INFO scheduler.DAGScheduler: Job 121 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:40,034 INFO cluster.YarnScheduler: Killing all running tasks in stage 181: Stage finished\n",
      "2025-02-01 06:53:40,034 INFO scheduler.DAGScheduler: Job 121 finished: countByKey at ColumnProfiler.scala:592, took 0.060488 s\n",
      "2025-02-01 06:53:40,403 INFO FileUtil: Write to file constraints.json at path /opt/ml/processing/output.\n",
      "2025-02-01 06:53:40,490 INFO codegen.CodeGenerator: Code generated in 32.583611 ms\n",
      "2025-02-01 06:53:40,496 INFO scheduler.DAGScheduler: Registering RDD 716 (count at StatsGenerator.scala:66) as input to shuffle 60\n",
      "2025-02-01 06:53:40,496 INFO scheduler.DAGScheduler: Got map stage job 122 (count at StatsGenerator.scala:66) with 1 output partitions\n",
      "2025-02-01 06:53:40,496 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 182 (count at StatsGenerator.scala:66)\n",
      "2025-02-01 06:53:40,496 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-01 06:53:40,497 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:40,497 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 182 (MapPartitionsRDD[716] at count at StatsGenerator.scala:66), which has no missing parents\n",
      "2025-02-01 06:53:40,499 INFO memory.MemoryStore: Block broadcast_144 stored as values in memory (estimated size 39.6 KiB, free 1457.1 MiB)\n",
      "2025-02-01 06:53:40,501 INFO memory.MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 1457.1 MiB)\n",
      "2025-02-01 06:53:40,501 INFO storage.BlockManagerInfo: Added broadcast_144_piece0 in memory on 10.0.119.186:40697 (size: 15.1 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:40,502 INFO spark.SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:40,502 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 182 (MapPartitionsRDD[716] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:40,502 INFO cluster.YarnScheduler: Adding task set 182.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:40,503 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 182.0 (TID 142) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:40,508 INFO storage.BlockManagerInfo: Added broadcast_144_piece0 in memory on algo-1:34585 (size: 15.1 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:40,561 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 182.0 (TID 142) in 58 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:40,561 INFO cluster.YarnScheduler: Removed TaskSet 182.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:40,562 INFO scheduler.DAGScheduler: ShuffleMapStage 182 (count at StatsGenerator.scala:66) finished in 0.063 s\n",
      "2025-02-01 06:53:40,562 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-01 06:53:40,563 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-01 06:53:40,563 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-01 06:53:40,563 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-01 06:53:40,599 INFO codegen.CodeGenerator: Code generated in 30.98272 ms\n",
      "2025-02-01 06:53:40,611 INFO spark.SparkContext: Starting job: count at StatsGenerator.scala:66\n",
      "2025-02-01 06:53:40,612 INFO scheduler.DAGScheduler: Got job 123 (count at StatsGenerator.scala:66) with 1 output partitions\n",
      "2025-02-01 06:53:40,612 INFO scheduler.DAGScheduler: Final stage: ResultStage 184 (count at StatsGenerator.scala:66)\n",
      "2025-02-01 06:53:40,612 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 183)\n",
      "2025-02-01 06:53:40,612 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-01 06:53:40,612 INFO scheduler.DAGScheduler: Submitting ResultStage 184 (MapPartitionsRDD[719] at count at StatsGenerator.scala:66), which has no missing parents\n",
      "2025-02-01 06:53:40,614 INFO memory.MemoryStore: Block broadcast_145 stored as values in memory (estimated size 11.1 KiB, free 1457.1 MiB)\n",
      "2025-02-01 06:53:40,615 INFO memory.MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 1457.1 MiB)\n",
      "2025-02-01 06:53:40,615 INFO storage.BlockManagerInfo: Added broadcast_145_piece0 in memory on 10.0.119.186:40697 (size: 5.5 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:40,616 INFO spark.SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-01 06:53:40,619 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 184 (MapPartitionsRDD[719] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-01 06:53:40,620 INFO cluster.YarnScheduler: Adding task set 184.0 with 1 tasks resource profile 0\n",
      "2025-02-01 06:53:40,624 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 184.0 (TID 143) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-01 06:53:40,630 INFO storage.BlockManagerInfo: Added broadcast_145_piece0 in memory on algo-1:34585 (size: 5.5 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:40,633 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 60 to 10.0.119.186:36018\n",
      "2025-02-01 06:53:40,647 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 184.0 (TID 143) in 23 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-01 06:53:40,647 INFO cluster.YarnScheduler: Removed TaskSet 184.0, whose tasks have all completed, from pool \n",
      "2025-02-01 06:53:40,648 INFO scheduler.DAGScheduler: ResultStage 184 (count at StatsGenerator.scala:66) finished in 0.035 s\n",
      "2025-02-01 06:53:40,648 INFO scheduler.DAGScheduler: Job 123 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-01 06:53:40,648 INFO cluster.YarnScheduler: Killing all running tasks in stage 184: Stage finished\n",
      "2025-02-01 06:53:40,648 INFO scheduler.DAGScheduler: Job 123 finished: count at StatsGenerator.scala:66, took 0.037306 s\n",
      "2025-02-01 06:53:41,613 INFO storage.BlockManagerInfo: Removed broadcast_139_piece0 on 10.0.119.186:40697 in memory (size: 20.7 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:41,616 INFO storage.BlockManagerInfo: Removed broadcast_139_piece0 on algo-1:34585 in memory (size: 20.7 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:41,618 INFO storage.BlockManagerInfo: Removed broadcast_141_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:41,618 INFO storage.BlockManagerInfo: Removed broadcast_141_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:41,620 INFO storage.BlockManagerInfo: Removed broadcast_143_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-01 06:53:41,620 INFO storage.BlockManagerInfo: Removed broadcast_143_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:41,623 INFO storage.BlockManagerInfo: Removed broadcast_142_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:41,623 INFO storage.BlockManagerInfo: Removed broadcast_142_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:41,625 INFO storage.BlockManagerInfo: Removed broadcast_144_piece0 on 10.0.119.186:40697 in memory (size: 15.1 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:41,626 INFO storage.BlockManagerInfo: Removed broadcast_144_piece0 on algo-1:34585 in memory (size: 15.1 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:41,629 INFO storage.BlockManagerInfo: Removed broadcast_134_piece0 on 10.0.119.186:40697 in memory (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:41,629 INFO storage.BlockManagerInfo: Removed broadcast_134_piece0 on algo-1:34585 in memory (size: 19.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:41,631 INFO storage.BlockManagerInfo: Removed broadcast_135_piece0 on 10.0.119.186:40697 in memory (size: 18.8 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:41,632 INFO storage.BlockManagerInfo: Removed broadcast_135_piece0 on algo-1:34585 in memory (size: 18.8 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:41,634 INFO storage.BlockManagerInfo: Removed broadcast_133_piece0 on 10.0.119.186:40697 in memory (size: 27.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-01 06:53:41,634 INFO storage.BlockManagerInfo: Removed broadcast_133_piece0 on algo-1:34585 in memory (size: 27.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:41,637 INFO storage.BlockManagerInfo: Removed broadcast_140_piece0 on 10.0.119.186:40697 in memory (size: 28.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:41,637 INFO storage.BlockManagerInfo: Removed broadcast_140_piece0 on algo-1:34585 in memory (size: 28.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:41,639 INFO storage.BlockManagerInfo: Removed broadcast_145_piece0 on 10.0.119.186:40697 in memory (size: 5.5 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:41,639 INFO storage.BlockManagerInfo: Removed broadcast_145_piece0 on algo-1:34585 in memory (size: 5.5 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:41,644 INFO storage.BlockManagerInfo: Removed broadcast_138_piece0 on 10.0.119.186:40697 in memory (size: 50.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-01 06:53:41,644 INFO storage.BlockManagerInfo: Removed broadcast_138_piece0 on algo-1:34585 in memory (size: 50.2 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:41,646 INFO storage.BlockManagerInfo: Removed broadcast_137_piece0 on 10.0.119.186:40697 in memory (size: 32.9 KiB, free: 1458.6 MiB)\n",
      "2025-02-01 06:53:41,647 INFO storage.BlockManagerInfo: Removed broadcast_137_piece0 on algo-1:34585 in memory (size: 32.9 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:41,649 INFO storage.BlockManagerInfo: Removed broadcast_136_piece0 on 10.0.119.186:40697 in memory (size: 3.0 KiB, free: 1458.6 MiB)\n",
      "2025-02-01 06:53:41,649 INFO storage.BlockManagerInfo: Removed broadcast_136_piece0 on algo-1:34585 in memory (size: 3.0 KiB, free: 2.7 GiB)\n",
      "2025-02-01 06:53:41,774 INFO FileUtil: Write to file statistics.json at path /opt/ml/processing/output.\n",
      "2025-02-01 06:53:41,789 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\n",
      "2025-02-01 06:53:41,839 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\n",
      "2025-02-01 06:53:41,846 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\n",
      "2025-02-01 06:53:41,859 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped\n",
      "2025-02-01 06:53:41,887 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "2025-02-01 06:53:41,970 INFO memory.MemoryStore: MemoryStore cleared\n",
      "2025-02-01 06:53:41,971 INFO storage.BlockManager: BlockManager stopped\n",
      "2025-02-01 06:53:41,975 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\n",
      "2025-02-01 06:53:41,990 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "2025-02-01 06:53:42,030 INFO spark.SparkContext: Successfully stopped SparkContext\n",
      "2025-02-01 06:53:42,030 INFO Main: Completed: Job completed successfully with no violations.\n",
      "2025-02-01 06:53:42,030 INFO Main: Write to file /opt/ml/output/message.\n",
      "2025-02-01 06:53:42,061 INFO util.ShutdownHookManager: Shutdown hook called\n",
      "2025-02-01 06:53:42,062 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-f51e9410-0146-45b2-a1a9-5fe5dfdf08d7\n",
      "2025-02-01 06:53:42,077 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-fceccba1-e7d4-42c1-856d-250590d5aaca\n",
      "2025-02-01 06:53:42,229 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\n",
      "2025-02-01 06:53:42,229 - DefaultDataAnalyzer - INFO - Spark job completed.\n",
      "\n",
      "CPU times: user 2.59 s, sys: 507 ms, total: 3.1 s\n",
      "Wall time: 5min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "monitor_baseline = my_default_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_data_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    job_name=f\"{prefix}-monitor-baseline-{datetime_stamp}\",\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ddf619a-a4c7-4f09-a789-2e38f1d45a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "import boto3\n",
    "\n",
    "client = boto3.client(\"sagemaker\")\n",
    "\n",
    "\n",
    "def get_last_processing_job():\n",
    "    response = client.list_processing_jobs(\n",
    "        NameContains=f\"{prefix}-monitor-baseline-{datetime_stamp}\",\n",
    "        StatusEquals=\"Completed\",\n",
    "        SortBy=\"CreationTime\",\n",
    "        SortOrder=\"Descending\",\n",
    "        MaxResults=20,\n",
    "    )\n",
    "    pprint.pprint(response[\"ProcessingJobSummaries\"][0])\n",
    "    return response[\"ProcessingJobSummaries\"][0][\"ProcessingJobName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bb1aa8a-aee0-48df-8698-a50f2039fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2025, 1, 31, 22, 49, 42, 925000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2025, 1, 31, 22, 54, 44, 432000, tzinfo=tzlocal()),\n",
      " 'ProcessingEndTime': datetime.datetime(2025, 1, 31, 22, 54, 2, tzinfo=tzlocal()),\n",
      " 'ProcessingJobArn': 'arn:aws:sagemaker:us-west-1:798223350085:processing-job/customerchurn-monitor-baseline-2025-01-31-224929',\n",
      " 'ProcessingJobName': 'customerchurn-monitor-baseline-2025-01-31-224929',\n",
      " 'ProcessingJobStatus': 'Completed'}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingJob\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.model_monitor.model_monitoring import ModelMonitor\n",
    "import pprint\n",
    "my_default_monitor_name = get_last_processing_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ffae739-0057-455d-a279-7ac1b4547bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AppSpecification': {'ImageUri': '159807026194.dkr.ecr.us-west-2.amazonaws.com/sagemaker-model-monitor-analyzer'},\n",
      " 'CreationTime': datetime.datetime(2024, 3, 30, 23, 11, 34, 579000, tzinfo=tzlocal()),\n",
      " 'Environment': {'dataset_format': '{\"csv\": {\"header\": false, '\n",
      "                                   '\"output_columns_position\": \"START\"}}',\n",
      "                 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input',\n",
      "                 'output_path': '/opt/ml/processing/output',\n",
      "                 'publish_cloudwatch_metrics': 'Disabled'},\n",
      " 'ExitMessage': 'Completed: Job completed successfully with no violations.',\n",
      " 'LastModifiedTime': datetime.datetime(2024, 3, 30, 23, 18, 25, 774000, tzinfo=tzlocal()),\n",
      " 'ProcessingEndTime': datetime.datetime(2024, 3, 30, 23, 18, 25, 171000, tzinfo=tzlocal()),\n",
      " 'ProcessingInputs': [{'AppManaged': False,\n",
      "                       'InputName': 'baseline_dataset_input',\n",
      "                       'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input',\n",
      "                                   'S3CompressionType': 'None',\n",
      "                                   'S3DataDistributionType': 'FullyReplicated',\n",
      "                                   'S3DataType': 'S3Prefix',\n",
      "                                   'S3InputMode': 'File',\n",
      "                                   'S3Uri': 's3://sagemaker-us-west-2-846634201516/ml_deploy/validation'}}],\n",
      " 'ProcessingJobArn': 'arn:aws:sagemaker:us-west-2:846634201516:processing-job/customerchurn-monitor-baseline-2024-03-30-231131',\n",
      " 'ProcessingJobName': 'customerchurn-monitor-baseline-2024-03-30-231131',\n",
      " 'ProcessingJobStatus': 'Completed',\n",
      " 'ProcessingOutputConfig': {'Outputs': [{'AppManaged': False,\n",
      "                                         'OutputName': 'monitoring_output',\n",
      "                                         'S3Output': {'LocalPath': '/opt/ml/processing/output',\n",
      "                                                      'S3UploadMode': 'EndOfJob',\n",
      "                                                      'S3Uri': 's3://sagemaker-us-west-2-846634201516/monitoring/baseline/results'}}]},\n",
      " 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1,\n",
      "                                           'InstanceType': 'ml.m5.large',\n",
      "                                           'VolumeSizeInGB': 20}},\n",
      " 'ProcessingStartTime': datetime.datetime(2024, 3, 30, 23, 16, 8, 100000, tzinfo=tzlocal()),\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '1858',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Sat, 30 Mar 2024 23:23:26 GMT',\n",
      "                                      'x-amzn-requestid': '50a01413-6351-4e35-a769-9cb7e49e8034'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '50a01413-6351-4e35-a769-9cb7e49e8034',\n",
      "                      'RetryAttempts': 0},\n",
      " 'RoleArn': 'arn:aws:iam::846634201516:role/service-role/AmazonSageMaker-ExecutionRole-20240122T185424',\n",
      " 'StoppingCondition': {'MaxRuntimeInSeconds': 1800}}\n"
     ]
    }
   ],
   "source": [
    "my_default_monitor_reload = ProcessingJob.from_processing_name(sess, my_default_monitor_name)\n",
    "\n",
    "response = client.describe_processing_job(ProcessingJobName=my_default_monitor_name)\n",
    "pprint.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0386037b-1a0b-4398-a0f1-8528b4c8fe97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>numerical_statistics.common.num_present</th>\n",
       "      <th>numerical_statistics.common.num_missing</th>\n",
       "      <th>numerical_statistics.mean</th>\n",
       "      <th>numerical_statistics.sum</th>\n",
       "      <th>numerical_statistics.std_dev</th>\n",
       "      <th>numerical_statistics.min</th>\n",
       "      <th>numerical_statistics.max</th>\n",
       "      <th>numerical_statistics.approximate_num_distinct_values</th>\n",
       "      <th>numerical_statistics.completeness</th>\n",
       "      <th>numerical_statistics.distribution.kll.buckets</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.c</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.k</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_c0</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508187</td>\n",
       "      <td>869.000000</td>\n",
       "      <td>0.499933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_c1</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>103.608772</td>\n",
       "      <td>177171.000000</td>\n",
       "      <td>58.049159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>201</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 1.0, 'upper_bound': 20.9, 'co...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_c2</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>229.941520</td>\n",
       "      <td>393200.000000</td>\n",
       "      <td>275.157578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 110.0, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 500.0, 0.0, 0.0, 400.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_c3</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>5.503563</td>\n",
       "      <td>9411.093407</td>\n",
       "      <td>3.316031</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>16.504147</td>\n",
       "      <td>1723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0002148017674441505, 'upper...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[1.0526538076293468, 1.442509561551946, 7.035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_c4</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>3.498830</td>\n",
       "      <td>5983.000000</td>\n",
       "      <td>1.697865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.9, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[2.0, 3.0, 5.0, 3.0, 5.0, 5.0, 4.0, 7.0, 4.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_c5</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>5.031373</td>\n",
       "      <td>8603.647048</td>\n",
       "      <td>2.086657</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>11.112419</td>\n",
       "      <td>1671</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.005548397942751747, 'upper_...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.6993549113167711, 2.2467101421396123, 3.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_c6</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>3.170760</td>\n",
       "      <td>5422.000000</td>\n",
       "      <td>2.529607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 1.2, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[2.0, 1.0, 5.0, 5.0, 7.0, 7.0, 8.0, 3.0, 5.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_c7</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>4.049233</td>\n",
       "      <td>6924.188944</td>\n",
       "      <td>1.666557</td>\n",
       "      <td>0.024479</td>\n",
       "      <td>10.183378</td>\n",
       "      <td>1748</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.024479438937142103, 'upper_...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[5.073754840111169, 5.052209883015463, 5.1068...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_c8</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>222.017544</td>\n",
       "      <td>379650.000000</td>\n",
       "      <td>95.951802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 55.0, 'co...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[200.0, 150.0, 200.0, 400.0, 300.0, 300.0, 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>_c9</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>5.037326</td>\n",
       "      <td>8613.827033</td>\n",
       "      <td>1.012575</td>\n",
       "      <td>2.024237</td>\n",
       "      <td>8.405644</td>\n",
       "      <td>1566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 2.02423709801934, 'upper_boun...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[5.823936374928548, 4.227688847116808, 5.5186...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name inferred_type  numerical_statistics.common.num_present  \\\n",
       "0  _c0    Fractional                                     1710   \n",
       "1  _c1    Fractional                                     1710   \n",
       "2  _c2    Fractional                                     1710   \n",
       "3  _c3    Fractional                                     1710   \n",
       "4  _c4    Fractional                                     1710   \n",
       "5  _c5    Fractional                                     1710   \n",
       "6  _c6    Fractional                                     1710   \n",
       "7  _c7    Fractional                                     1710   \n",
       "8  _c8    Fractional                                     1710   \n",
       "9  _c9    Fractional                                     1710   \n",
       "\n",
       "   numerical_statistics.common.num_missing  numerical_statistics.mean  \\\n",
       "0                                        0                   0.508187   \n",
       "1                                        0                 103.608772   \n",
       "2                                        0                 229.941520   \n",
       "3                                        0                   5.503563   \n",
       "4                                        0                   3.498830   \n",
       "5                                        0                   5.031373   \n",
       "6                                        0                   3.170760   \n",
       "7                                        0                   4.049233   \n",
       "8                                        0                 222.017544   \n",
       "9                                        0                   5.037326   \n",
       "\n",
       "   numerical_statistics.sum  numerical_statistics.std_dev  \\\n",
       "0                869.000000                      0.499933   \n",
       "1             177171.000000                     58.049159   \n",
       "2             393200.000000                    275.157578   \n",
       "3               9411.093407                      3.316031   \n",
       "4               5983.000000                      1.697865   \n",
       "5               8603.647048                      2.086657   \n",
       "6               5422.000000                      2.529607   \n",
       "7               6924.188944                      1.666557   \n",
       "8             379650.000000                     95.951802   \n",
       "9               8613.827033                      1.012575   \n",
       "\n",
       "   numerical_statistics.min  numerical_statistics.max  \\\n",
       "0                  0.000000                  1.000000   \n",
       "1                  1.000000                200.000000   \n",
       "2                  0.000000               1100.000000   \n",
       "3                  0.000215                 16.504147   \n",
       "4                  0.000000                  9.000000   \n",
       "5                  0.005548                 11.112419   \n",
       "6                  0.000000                 12.000000   \n",
       "7                  0.024479                 10.183378   \n",
       "8                  0.000000                550.000000   \n",
       "9                  2.024237                  8.405644   \n",
       "\n",
       "   numerical_statistics.approximate_num_distinct_values  \\\n",
       "0                                                  2      \n",
       "1                                                201      \n",
       "2                                                 12      \n",
       "3                                               1723      \n",
       "4                                                 10      \n",
       "5                                               1671      \n",
       "6                                                 13      \n",
       "7                                               1748      \n",
       "8                                                 12      \n",
       "9                                               1566      \n",
       "\n",
       "   numerical_statistics.completeness  \\\n",
       "0                                1.0   \n",
       "1                                1.0   \n",
       "2                                1.0   \n",
       "3                                1.0   \n",
       "4                                1.0   \n",
       "5                                1.0   \n",
       "6                                1.0   \n",
       "7                                1.0   \n",
       "8                                1.0   \n",
       "9                                1.0   \n",
       "\n",
       "       numerical_statistics.distribution.kll.buckets  \\\n",
       "0  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "1  [{'lower_bound': 1.0, 'upper_bound': 20.9, 'co...   \n",
       "2  [{'lower_bound': 0.0, 'upper_bound': 110.0, 'c...   \n",
       "3  [{'lower_bound': 0.0002148017674441505, 'upper...   \n",
       "4  [{'lower_bound': 0.0, 'upper_bound': 0.9, 'cou...   \n",
       "5  [{'lower_bound': 0.005548397942751747, 'upper_...   \n",
       "6  [{'lower_bound': 0.0, 'upper_bound': 1.2, 'cou...   \n",
       "7  [{'lower_bound': 0.024479438937142103, 'upper_...   \n",
       "8  [{'lower_bound': 0.0, 'upper_bound': 55.0, 'co...   \n",
       "9  [{'lower_bound': 2.02423709801934, 'upper_boun...   \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.c  \\\n",
       "0                                               0.64           \n",
       "1                                               0.64           \n",
       "2                                               0.64           \n",
       "3                                               0.64           \n",
       "4                                               0.64           \n",
       "5                                               0.64           \n",
       "6                                               0.64           \n",
       "7                                               0.64           \n",
       "8                                               0.64           \n",
       "9                                               0.64           \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.k  \\\n",
       "0                                             2048.0           \n",
       "1                                             2048.0           \n",
       "2                                             2048.0           \n",
       "3                                             2048.0           \n",
       "4                                             2048.0           \n",
       "5                                             2048.0           \n",
       "6                                             2048.0           \n",
       "7                                             2048.0           \n",
       "8                                             2048.0           \n",
       "9                                             2048.0           \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.data  \n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "1  [[1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0,...  \n",
       "2  [[0.0, 0.0, 500.0, 0.0, 0.0, 400.0, 0.0, 0.0, ...  \n",
       "3  [[1.0526538076293468, 1.442509561551946, 7.035...  \n",
       "4  [[2.0, 3.0, 5.0, 3.0, 5.0, 5.0, 4.0, 7.0, 4.0,...  \n",
       "5  [[0.6993549113167711, 2.2467101421396123, 3.13...  \n",
       "6  [[2.0, 1.0, 5.0, 5.0, 7.0, 7.0, 8.0, 3.0, 5.0,...  \n",
       "7  [[5.073754840111169, 5.052209883015463, 5.1068...  \n",
       "8  [[200.0, 150.0, 200.0, 400.0, 300.0, 300.0, 40...  \n",
       "9  [[5.823936374928548, 4.227688847116808, 5.5186...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "baseline_job = my_default_monitor.latest_baselining_job\n",
    "schema_df = pd.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fada03d-1e20-4281-bc8e-ba5e49475c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>completeness</th>\n",
       "      <th>num_constraints.is_non_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_c0</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_c1</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_c2</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_c3</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_c4</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_c5</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_c6</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_c7</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_c8</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>_c9</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name inferred_type  completeness  num_constraints.is_non_negative\n",
       "0  _c0    Fractional           1.0                             True\n",
       "1  _c1    Fractional           1.0                             True\n",
       "2  _c2    Fractional           1.0                             True\n",
       "3  _c3    Fractional           1.0                             True\n",
       "4  _c4    Fractional           1.0                             True\n",
       "5  _c5    Fractional           1.0                             True\n",
       "6  _c6    Fractional           1.0                             True\n",
       "7  _c7    Fractional           1.0                             True\n",
       "8  _c8    Fractional           1.0                             True\n",
       "9  _c9    Fractional           1.0                             True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraints_df = pd.json_normalize(baseline_job.suggested_constraints().body_dict[\"features\"])\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e57b2a2-d61e-4218-8d22-4dc462a62e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.702198326587677\n"
     ]
    }
   ],
   "source": [
    "sagemaker_runtime = boto3.client(\n",
    "    \"sagemaker-runtime\", region_name='us-west-1')\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType='text/csv',\n",
    "    Body = \"2.0,400.0,0.38571846040122537,2.0,4.177940384158745,0.0,3.745462710628048,250.0,3.699591756294294,1.0,11.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,1.0\"\n",
    ")\n",
    "print(response['Body'].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bee9d3b9-0bdc-4c87-aa24-ea5980a22593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n",
      "0.702198326587677\n"
     ]
    }
   ],
   "source": [
    "for x in range(20):\n",
    "    response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType='text/csv',\n",
    "    Body = \"2.0,400.0,0.38571846040122537,2.0,4.177940384158745,0.0,3.745462710628048,250.0,3.699591756294294,1.0,11.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,1.0\"\n",
    ")\n",
    "    print(response['Body'].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32b803a7-9de5-4116-9b6f-9aadcceff05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─────────────────────────────── </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">16</span>                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Waiting for the data drift model monitoring processing job to start...\"</span>)         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Pause for 60 seconds</span>                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>16 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>time.sleep(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">60</span>)                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Get the first monitoring execution details</span>                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>monitoring_executions = sm_client.list_monitoring_executions(                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;0;0m╭─\u001b[0m\u001b[38;2;255;0;0m──────────────────────────────\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m───────────────────────────────\u001b[0m\u001b[38;2;255;0;0m─╮\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m16\u001b[0m                                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mWaiting for the data drift model monitoring processing job to start...\u001b[0m\u001b[33m\"\u001b[0m)         \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Pause for 60 seconds\u001b[0m                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m16 \u001b[2m│   \u001b[0mtime.sleep(\u001b[94m60\u001b[0m)                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Get the first monitoring execution details\u001b[0m                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m19 \u001b[0m\u001b[2m│   \u001b[0mmonitoring_executions = sm_client.list_monitoring_executions(                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "MODEL_MONITOR_SCHEDULE_NAME = \"mlops-data-quality-schedule\"\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "monitoring_executions = sm_client.list_monitoring_executions(\n",
    "    MonitoringScheduleName=MODEL_MONITOR_SCHEDULE_NAME\n",
    ")\n",
    "\n",
    "# Check if monitoring job has started\n",
    "while not (monitoring_executions.get(\"MonitoringExecutionSummaries\")):\n",
    "\n",
    "    # Progress update\n",
    "    print(\"Waiting for the data drift model monitoring processing job to start...\")\n",
    "\n",
    "    # Pause for 60 seconds\n",
    "    time.sleep(60)\n",
    "\n",
    "    # Get the first monitoring execution details\n",
    "    monitoring_executions = sm_client.list_monitoring_executions(\n",
    "        MonitoringScheduleName=MODEL_MONITOR_SCHEDULE_NAME\n",
    "    )\n",
    "\n",
    "print(\"The data drift model monitoring processing job has started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33900936-c850-417f-8246-fd9bd3a5fc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We created a hourly schedule above and it will kick off executions ON the hour (plus 0 - 20 min buffer.\n",
      "We will have to wait till we hit the hour...\n"
     ]
    }
   ],
   "source": [
    "mon_executions = my_default_monitor.list_executions()\n",
    "print(\"We created a hourly schedule above and it will kick off executions ON the hour (plus 0 - 20 min buffer.\\nWe will have to wait till we hit the hour...\")\n",
    "\n",
    "while len(mon_executions) == 0:\n",
    "    print(\"Waiting for the 1st execution to happen...\")\n",
    "    time.sleep(60)\n",
    "    mon_executions = my_default_monitor.list_executions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "232c1316-fa58-45c2-802e-12f0e56bdcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest execution status: Completed\n",
      "Latest execution result: Completed: Job completed successfully with no violations.\n"
     ]
    }
   ],
   "source": [
    "latest_execution = mon_executions[-1] # latest execution's index is -1, previous is -2 and so on..\n",
    "\n",
    "\n",
    "print(\"Latest execution status: {}\".format(latest_execution.describe()['ProcessingJobStatus']))\n",
    "print(\"Latest execution result: {}\".format(latest_execution.describe()['ExitMessage']))\n",
    "\n",
    "latest_job = latest_execution.describe()\n",
    "if (latest_job['ProcessingJobStatus'] != 'Completed'):\n",
    "        print(\"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36937906-80c8-4fd0-bfa9-ab2a7df5b9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Uri: s3://sagemaker-us-west-2-846634201516/reports//CustomerChurn/mlops-data-quality-schedule/2024/03/31/00\n"
     ]
    }
   ],
   "source": [
    "report_uri=latest_execution.output.destination\n",
    "print('Report Uri: {}'.format(report_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c24ad999-a7aa-40ac-98de-551af8f1a3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report bucket: sagemaker-us-west-2-846634201516\n",
      "Report key: reports//CustomerChurn/mlops-data-quality-schedule/2024/03/31/00\n",
      "Found Report Files:\n",
      "reports//CustomerChurn/mlops-data-quality-schedule/2024/03/31/00/constraint_violations.json\n",
      " reports//CustomerChurn/mlops-data-quality-schedule/2024/03/31/00/constraints.json\n",
      " reports//CustomerChurn/mlops-data-quality-schedule/2024/03/31/00/statistics.json\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "s3uri = urlparse(report_uri)\n",
    "report_bucket = s3uri.netloc\n",
    "report_key = s3uri.path.lstrip('/')\n",
    "print('Report bucket: {}'.format(report_bucket))\n",
    "print('Report key: {}'.format(report_key))\n",
    "\n",
    "s3_client = boto3.Session().client('s3')\n",
    "result = s3_client.list_objects(Bucket=report_bucket, Prefix=report_key)\n",
    "report_files = [report_file.get(\"Key\") for report_file in result.get('Contents')]\n",
    "print(\"Found Report Files:\")\n",
    "print(\"\\n \".join(report_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cd185d2-90c7-4563-9692-4a0ed296c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "MODEL_MONITOR_SCHEDULE_NAME = \"mlops-data-quality-schedule\"\n",
    "\n",
    "response = sm_client.delete_monitoring_schedule(\n",
    "    MonitoringScheduleName=MODEL_MONITOR_SCHEDULE_NAME\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b1a2bf7-1776-4d58-8ec7-fa97fff4edfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'c9939153-4670-4f91-a482-bdafbe4886e1',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'c9939153-4670-4f91-a482-bdafbe4886e1',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Sun, 31 Mar 2024 03:29:38 GMT',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name = \"CustomerChurn\"\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388ab7d-5332-4b91-aadc-2da9d83af515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
